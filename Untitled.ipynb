{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aeceec0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GPU is required to quantize or run quantize model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 34\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Pipeline:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     makeFunctionFromText \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.15\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtextToCode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[103], line 7\u001b[0m, in \u001b[0;36mtextToCode\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtextToCode\u001b[39m():\n\u001b[1;32m      6\u001b[0m     model_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheBloke/CodeLlama-7B-Python-GPTQ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                \u001b[49m\u001b[38;5;66;43;03m#torch_dtype=torch.float32,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake app 4 optimizing and automating workflows for anyone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:516\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    515\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py:2489\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2485\u001b[0m     quantization_method_from_args \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mGPTQ\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m quantization_method_from_config \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mGPTQ\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m-> 2489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is required to quantize or run quantize model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_optimum_available() \u001b[38;5;129;01mand\u001b[39;00m is_auto_gptq_available()):\n\u001b[1;32m   2491\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2492\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading GPTQ quantized model requires optimum library : `pip install optimum` and auto-gptq library \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install auto-gptq\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2493\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GPU is required to quantize or run quantize model."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "def textToCode():\n",
    "    model_name_or_path = \"TheBloke/CodeLlama-7B-Python-GPTQ\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                                #torch_dtype=torch.float32,\n",
    "                                                device_map=\"auto\",\n",
    "                                                revision=\"main\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "    prompt = \"make app 4 optimizing and automating workflows for anyone\"\n",
    "    prompt_template=f'''[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n",
    "    {prompt}\n",
    "    [/INST]\n",
    "    '''\n",
    "    print(\"\\n\\n*** Generate:\")\n",
    "    input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "    output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)\n",
    "    print(tokenizer.decode(output[0]))\n",
    "    # Inference can also be done using transformers' pipeline\n",
    "    print(\"*** Pipeline:\")\n",
    "    makeFunctionFromText = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.15\n",
    "    )\n",
    "    \n",
    "    \n",
    "textToCode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a9f7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8519]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "one = model.encode('find all airbnbs next to a walmart')\n",
    "\n",
    "\n",
    "\n",
    "#rendered Result : Sorry, that query does not quite make sense, can you clarify further \n",
    "#here are 3 options\n",
    "two = model.encode('find all airbnbs far from a walmart')\n",
    "\n",
    "\n",
    "\n",
    "three = model.encode('find all airbnbs')\n",
    "\n",
    "util.cos_sim(one, three)\n",
    "\n",
    "\n",
    "\n",
    "#parse phrase into PoS -> nouns, verbs and so forth\n",
    "#next to a walmart\n",
    "#negative or positive\n",
    "\n",
    "\n",
    "#util.paraphrase_mining(model, 'how are you today ?')\n",
    "#get 12 hours of work done today and hopefully its like the last day ? \n",
    "#but be prepared to keep typing for another week/year/decade/centrury/millenia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#geospatial\n",
    "#tabular\n",
    "#graphs\n",
    "#time series\n",
    "#100 functions - type and dont think\n",
    "\n",
    "\n",
    "#def find_all_airbnb_close_to_walmart():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNewFeatures():\n",
    "    return 'make demo '\n",
    "\n",
    "#some group of 1000 people invented something\n",
    "#this lets you vote with other people to use magic spells\n",
    "#the spells take at least 3 people to collaborate and imagine together cool movies and so on\n",
    "#all of movie club was on your side like a year ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd40bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sentences = \"\"\"\n",
    "1. Obtain all Airbnb listings.\n",
    "2. Secure all Airbnb accommodations.\n",
    "3. Fetch every Airbnb property.\n",
    "4. Retrieve all Airbnb spots.\n",
    "5. Acquire all Airbnb lodgings.\n",
    "6. Access all Airbnb rentals.\n",
    "7. Grab all Airbnb options.\n",
    "8. Collect all Airbnb offerings.\n",
    "9. Snag every Airbnb out there.\n",
    "10. Reserve all Airbnb places.\n",
    "11. Get hold of all Airbnb spaces.\n",
    "12. Book every available Airbnb.\n",
    "13. Purchase all Airbnb units.\n",
    "14. Amass all Airbnb dwellings.\n",
    "15. Accumulate all Airbnb residences.\n",
    "16. Download all Airbnb data.\n",
    "17. Procure every Airbnb site.\n",
    "18. Lock in all Airbnb locations.\n",
    "19. Extract all Airbnb information.\n",
    "20. Register for all Airbnb homes.\n",
    "21. Seize all Airbnb rooms.\n",
    "22. Take all Airbnb apartments.\n",
    "23. Attain all Airbnb venues.\n",
    "24. Gain access to all Airbnb stays.\n",
    "25. Capture all Airbnb settings.\n",
    "26. Round up all Airbnb abodes.\n",
    "27. Lay claim to all Airbnb suites.\n",
    "28. Import all Airbnb listings.\n",
    "29. Gather up all Airbnb experiences.\n",
    "30. Source all Airbnb lodges.\n",
    "31. Hoard all Airbnb cabins.\n",
    "32. Get your hands on all Airbnb rentals.\n",
    "33. Buy up all Airbnb properties.\n",
    "34. Corral all Airbnb guesthouses.\n",
    "35. Pick up all Airbnb flats.\n",
    "36. Add all Airbnb spots to your list.\n",
    "37. Pull in all Airbnb rooms.\n",
    "38. Enlist all Airbnb accommodations.\n",
    "39. Snatch up every Airbnb offering.\n",
    "40. Check out all Airbnb options.\n",
    "41. Win all Airbnb houses.\n",
    "42. Confiscate all Airbnb assets.\n",
    "43. Own all Airbnb sites.\n",
    "44. Secure every Airbnb cottage.\n",
    "45. Receive all Airbnb units.\n",
    "46. Reap all Airbnb places.\n",
    "47. Succeed in getting all Airbnb stays.\n",
    "48. Take possession of all Airbnb rentals.\n",
    "49. Score all Airbnb venues.\n",
    "50. Nab all Airbnb locations.\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def getEncodings(sentences):\n",
    "    return model.encode(sentences, convert_to_tensor=True, device='cpu')\n",
    "sentences = getEncodings(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c77aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1188,  0.0483, -0.0025,  ...,  0.1264,  0.0465, -0.0157],\n",
       "        [ 0.0787, -0.0788,  0.0422,  ...,  0.0577, -0.1345,  0.0182],\n",
       "        [ 0.0818,  0.0084,  0.0109,  ...,  0.0188, -0.1042, -0.0212],\n",
       "        ...,\n",
       "        [ 0.1510, -0.0231, -0.0377,  ...,  0.0119, -0.0978, -0.0328],\n",
       "        [ 0.1183, -0.0446,  0.0093,  ...,  0.0208, -0.1303, -0.0128],\n",
       "        [-0.1188,  0.0483, -0.0025,  ...,  0.1264,  0.0465, -0.0157]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ffe752",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (174341188.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    //\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#people can perceive your thought process -> about 50 milliseconds ahead of you \n",
    "#based on where they think you are going and how the audience feels about it, they project either belief or things they wouldnt do to a real person sitting in front of them.\n",
    "\n",
    "#4 hours - make demo\n",
    "#complete - never coding again. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#function param1 param2 param3.\n",
    "#you dont have to code anymore\n",
    "#you've written enough\n",
    "#just 4 more hours\n",
    "#wait for them to complete their conversation. its not aobut you \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentenceTo\n",
    "\n",
    "#just walk. it was never about code. you wrote enough\n",
    "#theres thousands of people who want impressive code\n",
    "#but if they really wanted it, they know how to get it. they dont want perseverence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encodings = {\n",
    "    //\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def asdf\n",
    "\n",
    "encodings[key] = \n",
    "\n",
    "\n",
    "def _(sentence):\n",
    "    _ = sentence.split(' ')\n",
    "    _0 = sentence[0]\n",
    "    _rest = sentence[1:]\n",
    "    \n",
    "    \n",
    "\n",
    "# get 3 conferences in the next month\n",
    "# generate a poll for 10 conferences\n",
    "# find an airbnb \n",
    "# make a list of activities in each city that match these criteria\n",
    "# make an improptu schedule that updates automatically when flgiht shedule changes\n",
    "\n",
    "    \n",
    "sentences= \"\"\"\n",
    "generate a poll from 3 conferences in the next month\n",
    "-> people go to conferences and visit the city together \n",
    "\n",
    "get 3 out of 10 options from poll \n",
    "for each one\n",
    "find the most suitable airbnb\n",
    "and a list of activities\n",
    "and a schedule \n",
    "\"\"\".split('\\n')\n",
    "\n",
    "\n",
    "def poll ():\n",
    "    return json.load(open('./polling-data.json'))\n",
    "\n",
    "fnMap = [\n",
    "    poll('0'),\n",
    "    poll('1'),\n",
    "    find_airbnb(),\n",
    "    find_activities,\n",
    "    build_schedule,\n",
    "]\n",
    "\n",
    "\n",
    "fns = [fnMap[sentences[i]] for i in enumerate(sentences)]\n",
    "\n",
    "val = False\n",
    "for i in fns: val = fns(val)\n",
    "    \n",
    "\n",
    "def getConferences(subject=''):\n",
    "    #TODO find all conferences in all subjects\n",
    "    \n",
    "    r = requests('https://confs.tech/')\n",
    "    confs = r.text.find('.Heading_Inner__Ri2ED.a').map(lambda _: _.href)\n",
    "    confs = [{'title': 'cool beans', 'location': \"london\", \"source\": 'http://google.com'}]\n",
    "    return confs\n",
    "\n",
    "\n",
    "def getPapers():\n",
    "    return open('./data/placeholder-pdf.pdf').read()\n",
    "    \n",
    "def find_airbnb():\n",
    "    read = json.load(open('./data/airbnb.json').read())\n",
    "    return read[random().random() * len(read)]\n",
    "    \n",
    "def find_activites():\n",
    "    PoI = [\n",
    "        {'hiroshima': {\n",
    "            'location' : '',\n",
    "                     '':''\n",
    "        },},\n",
    "        {'uniqlo': {\n",
    "            'location': '',\n",
    "                    '':''\n",
    "        },\n",
    "         'ramen': {\n",
    "             'location': '',\n",
    "                     '':''\n",
    "         }\n",
    "        }\n",
    "    ]\n",
    "    return PoI\n",
    "\n",
    "def build_schedule():\n",
    "    return '2pm hiroshima 4pm uniqlo 6pm ramen 8pm mount fuji'\n",
    "    \n",
    "#yes and thank you\n",
    "#book flight\n",
    "#airbnb [1, 2, 3] tab\n",
    "#book airbnb\n",
    "#activities \n",
    "#remote year \n",
    "\"\"\"\n",
    "get all papers related to _\n",
    "find intersection - genreate 10,000 word summary \n",
    "make an entire field easy to parse \n",
    "\n",
    "\"\"\"\n",
    "#use a progress bar - come back in one hour \n",
    "#10 papers to read out of 10,000\n",
    "#1 sentence summary of each\n",
    "#how they relate to your thesis\n",
    "#paperpile\n",
    "\n",
    "def getAllPapers():\n",
    "    #get paul graham\n",
    "    return ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "come up with a new one\n",
    "#ask people 3 things\n",
    "generate best recipe for new food thats never been created before \n",
    "#generate gant chart -> did this, what to do next -> speak and grey out the previous steps \n",
    "#order groceries for each one this week \n",
    "#make best instacart UI possible\n",
    "\n",
    "\"\"\"\n",
    "#given 3 ingredients -> click this button to order the entire weeks food for iron chef\n",
    "\n",
    "#read papers\n",
    "#go to conference to talk about things learned\n",
    "#ask person at conference if they want to make dinner \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf596112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def getEncodings(sentences):\n",
    "    return model.encode(sentences, convert_to_tensor=True, device='cpu')\n",
    "\n",
    "sentences = \"\"\"\n",
    "Certainly! Here are 50 different ways to write the phrase \"get all Airbnb\":\n",
    "\n",
    "1. Obtain all Airbnb listings.\n",
    "2. Secure all Airbnb accommodations.\n",
    "3. Fetch every Airbnb property.\n",
    "4. Retrieve all Airbnb spots.\n",
    "5. Acquire all Airbnb lodgings.\n",
    "6. Access all Airbnb rentals.\n",
    "7. Grab all Airbnb options.\n",
    "8. Collect all Airbnb offerings.\n",
    "9. Snag every Airbnb out there.\n",
    "10. Reserve all Airbnb places.\n",
    "11. Get hold of all Airbnb spaces.\n",
    "12. Book every available Airbnb.\n",
    "13. Purchase all Airbnb units.\n",
    "14. Amass all Airbnb dwellings.\n",
    "15. Accumulate all Airbnb residences.\n",
    "16. Download all Airbnb data.\n",
    "17. Procure every Airbnb site.\n",
    "18. Lock in all Airbnb locations.\n",
    "19. Extract all Airbnb information.\n",
    "20. Register for all Airbnb homes.\n",
    "21. Seize all Airbnb rooms.\n",
    "22. Take all Airbnb apartments.\n",
    "23. Attain all Airbnb venues.\n",
    "24. Gain access to all Airbnb stays.\n",
    "25. Capture all Airbnb settings.\n",
    "26. Round up all Airbnb abodes.\n",
    "27. Lay claim to all Airbnb suites.\n",
    "28. Import all Airbnb listings.\n",
    "29. Gather up all Airbnb experiences.\n",
    "30. Source all Airbnb lodges.\n",
    "31. Hoard all Airbnb cabins.\n",
    "32. Get your hands on all Airbnb rentals.\n",
    "33. Buy up all Airbnb properties.\n",
    "34. Corral all Airbnb guesthouses.\n",
    "35. Pick up all Airbnb flats.\n",
    "36. Add all Airbnb spots to your list.\n",
    "37. Pull in all Airbnb rooms.\n",
    "38. Enlist all Airbnb accommodations.\n",
    "39. Snatch up every Airbnb offering.\n",
    "40. Check out all Airbnb options.\n",
    "41. Win all Airbnb houses.\n",
    "42. Confiscate all Airbnb assets.\n",
    "43. Own all Airbnb sites.\n",
    "44. Secure every Airbnb cottage.\n",
    "45. Receive all Airbnb units.\n",
    "46. Reap all Airbnb places.\n",
    "47. Succeed in getting all Airbnb stays.\n",
    "48. Take possession of all Airbnb rentals.\n",
    "49. Score all Airbnb venues.\n",
    "50. Nab all Airbnb locations.\n",
    "\n",
    "Each version could have specific implications depending on the context in which it's used.\"\"\".split('\\n')\n",
    "sentences = getEncodings(sentences)\n",
    "key = str(sentences[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db2785c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/8v7sj0716pq8v7tlpkmvj70m0000gn/T/ipykernel_81226/2037250165.py:13: DeprecationWarning: The 'get' method is deprecated, use 'results' instead\n",
      "  for result in search.get():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Circular spectropolarimetric sensing of higher plant and algal chloroplast structural variations\n",
      "Authors: [arxiv.Result.Author('C. H. Lucas Patty'), arxiv.Result.Author('Freek Ariese'), arxiv.Result.Author('Wybren Jan Buma'), arxiv.Result.Author('Inge Loes ten Kate'), arxiv.Result.Author('Rob J. M. van Spanning'), arxiv.Result.Author('Frans Snik')]\n",
      "Summary: Photosynthetic eukaryotes show a remarkable variability in photosynthesis,\n",
      "including large differences in light harvesting proteins and pigment\n",
      "composition. In vivo circular spectropolarimetry enables us to probe the\n",
      "molecular architecture of photosynthesis in a non-invasive and non-destructive\n",
      "way and, as such, can offer a wealth of physiological and structural\n",
      "information. In the present study we have measured the circular polarizance of\n",
      "several multicellular green, red and brown algae and higher plants, which show\n",
      "large variations in circular spectropolarimetric signals with differences in\n",
      "both spectral shape and magnitude. Many of the algae display spectral\n",
      "characteristics not previously reported, indicating a larger variation in\n",
      "molecular organization than previously assumed. As the strengths of these\n",
      "signals vary by three orders of magnitude, these results also have important\n",
      "implications in terms of detectability for the use of circular polarization as\n",
      "a signature of life.\n",
      "Link: http://arxiv.org/pdf/1808.08033v1\n",
      "----\n",
      "Title: A solution to the evolution-related Truscott-Brindley model for the generalized phytoplankton-zooplankton populations\n",
      "Authors: [arxiv.Result.Author('R. K. Upadhyay')]\n",
      "Summary: Phytoplankton are tiny floating plants (algae) living in oceans. In the\n",
      "process of photosynthesis, phytoplankton produces half of the world's oxygen.\n",
      "Moreover, by primary production, death and sinking, they transport carbon from\n",
      "the ocean's surface layer to marine sediments. There are many species of\n",
      "phytoplankton that can be distinguished according to morphology.\n",
      "  In this paper, we investigate the generalised Truscott-Brindley model of the\n",
      "dynamics of zoologically defined interacting populations which have spatial\n",
      "structure. Specifically, we consider conjointly marine phytoplankton and\n",
      "zooplankton populations, and model them as an excitable medium. The resolution\n",
      "using the Boubaker polynomials expansion scheme (BPES) along with stability\n",
      "analysis is carried out.\n",
      "Link: http://arxiv.org/pdf/1212.5420v1\n",
      "----\n",
      "Title: Phase transition energetics in mesoscale photosynthetic condensates\n",
      "Authors: [arxiv.Result.Author('Charley Schaefer'), arxiv.Result.Author('Alex Payne-Dwyer'), arxiv.Result.Author('James Barrett'), arxiv.Result.Author('Luke Mackinder'), arxiv.Result.Author('Mark C. Leake')]\n",
      "Summary: The pyrenoid is a model two-component biomolecular condensate, vital for\n",
      "efficient photosynthesis in algae. Despite simulations predicting qualitative\n",
      "features of liquid-liquid phase separation driving their formation, the\n",
      "underlying energetics remain unclear. By modelling interactions between Rubisco\n",
      "protein carbon-capturing machinery inside pyrenoids as linker chemical and\n",
      "stretch potentials we explain spectroscopic and single-molecule data over\n",
      "physiological concentrations. This new parametrisation can be used for\n",
      "quantitative predictions in generalized emergent self-assembly of two-component\n",
      "condensates.\n",
      "Link: http://arxiv.org/pdf/2301.05681v3\n",
      "----\n",
      "Title: A 2D model for hydrodynamics and biology coupling applied to algae growth simulations\n",
      "Authors: [arxiv.Result.Author('Olivier Bernard'), arxiv.Result.Author('Anne-Celine Boulanger'), arxiv.Result.Author('Marie-Odile Bristeau'), arxiv.Result.Author('Jacques Sainte-Marie')]\n",
      "Summary: Cultivating oleaginous microalgae in specific culturing devices such as\n",
      "raceways is seen as a future way to produce biofuel. The complexity of this\n",
      "process coupling non linear biological activity to hydrodynamics makes the\n",
      "optimization problem very delicate. The large amount of parameters to be taken\n",
      "into account paves the way for a useful mathematical modeling. Due to the\n",
      "heterogeneity of raceways along the depth dimension regarding temperature,\n",
      "light intensity or nutrients availability, we adopt a multilayer approach for\n",
      "hydrodynamics and biology. For free surface hydrodynamics, we use a multilayer\n",
      "Saint-Venant model that allows mass exchanges, forced by a simplified\n",
      "representation of the paddlewheel. Then, starting from an improved Droop model\n",
      "that includes light effect on algae growth, we derive a similar multilayer\n",
      "system for the biological part. A kinetic interpretation of the whole system\n",
      "results in an efficient numerical scheme. We show through numerical simulations\n",
      "in two dimensions that our approach is capable of discriminating between\n",
      "situations of mixed water or calm and heterogeneous pond. Moreover, we exhibit\n",
      "that a posteriori treatment of our velocity fields can provide lagrangian\n",
      "trajectories which are of great interest to assess the actual light pattern\n",
      "perceived by the algal cells and therefore understand its impact on the\n",
      "photosynthesis process.\n",
      "Link: http://arxiv.org/pdf/1209.0487v1\n",
      "----\n",
      "Title: Large scale FRET simulations reveal the control parameters of phycobilisome light harvesting complexes\n",
      "Authors: [arxiv.Result.Author('Emma Joy Dodson'), arxiv.Result.Author('Nicholas Werren'), arxiv.Result.Author('Yossi Paltiel'), arxiv.Result.Author('Erik Gauger'), arxiv.Result.Author('Nir Keren')]\n",
      "Summary: Phycobilisomes (PBS) are massive structures that absorb and transfer light\n",
      "energy to photochemical reaction centers. Among the range of light harvesting\n",
      "systems, PBS are considered to be excellent solutions for absorption\n",
      "cross-sections but relatively inefficient energy transferring systems. This is\n",
      "due to the combination of a large number of chromophores with intermediate\n",
      "coupling distances. Nevertheless, PBS systems persisted from the origin of\n",
      "oxygenic photosynthesis to present day cyanobacteria and red algae, organisms\n",
      "that account for approximately half of the primary productivity in the ocean.\n",
      "In this study we modeled energy transfer through subsets of PBS structures,\n",
      "using a comprehensive dynamic Hamiltonian model. Our approach was applied,\n",
      "initially, to pairs of phycobilin hexamers and then extended to short rods. By\n",
      "manipulating the distances and angles between the structures we could probe the\n",
      "dynamics of exciton transfer. These simulations suggest that the PBS\n",
      "chromophore network enhances energy distribution over the entire PBS structure,\n",
      "both horizontally and vertically to the rod axis. Furthermore, energy transfer\n",
      "was found to be relatively immune to the effects of distances or rotations,\n",
      "within the range of intermediate coupling distances. Therefore, we suggest that\n",
      "the PBS provides unique advantages and flexibility to aquatic photosynthesis.\n",
      "Link: http://arxiv.org/pdf/2208.11397v1\n",
      "----\n",
      "Title: Representative Pathways of Excitation Migration in Photosystem I\n",
      "Authors: [arxiv.Result.Author('Sanghyun Park'), arxiv.Result.Author('Melih K. Sener'), arxiv.Result.Author('Deyu Lu'), arxiv.Result.Author('Klaus Schulten')]\n",
      "Summary: Photosystem I is a protein-pigment complex that performs photosynthesis in\n",
      "plants, green algae, and cyanobacteria. It contains an aggregate of\n",
      "chlorophylls that absorbs light and delivers the resulting electronic\n",
      "excitation to the special pair of chlorophylls where the excitation energy is\n",
      "used for producing charge separation across the cell membrane. The seemingly\n",
      "random arrangement of chlorophylls in photosystem I poses the question which\n",
      "pathways excitation migration follows towards the special pair after absorption\n",
      "of light at any of its chlorophylls. We employ a master equation to describe\n",
      "the process of excitation migration in photosystem I, and find representative\n",
      "paths of excitation migration based on the mean first-passage time from each\n",
      "chlorophyll to the special pair. The resulting paths, beginning at each of the\n",
      "chlorophylls and ending at the special pair, provide a complete yet distilled\n",
      "picture of the excitation migration towards the special pair.\n",
      "Link: http://arxiv.org/pdf/physics/0207104v1\n",
      "----\n",
      "Title: Disentangling electronic and vibrational coherence in the Phycocyanin-645 light-harvesting complex\n",
      "Authors: [arxiv.Result.Author('Gethin H. Richards'), arxiv.Result.Author('Krystyna E. Wilk'), arxiv.Result.Author('Paul M. G. Curmi'), arxiv.Result.Author('Jeffrey A. Davis')]\n",
      "Summary: Energy transfer between chromophores in photosynthesis proceeds with near\n",
      "unity quantum efficiency. Understanding the precise mechanisms of these\n",
      "processes is made difficult by the complexity of the electronic structure and\n",
      "interactions with different vibrational modes. Two-dimensional spectroscopy has\n",
      "helped resolve some of the ambiguities and identified quantum effects that may\n",
      "be important for highly efficient energy transfer. Many questions remain,\n",
      "however, including whether the coherences observed are electronic and/or\n",
      "vibrational in nature and what role they play. We utilise a two-colour\n",
      "four-wave mixing experiment with control of the wavelength and polarization to\n",
      "selectively excite specific coherence pathways. For the light-harvesting\n",
      "complex PC645, from cryptophyte algae, we reveal and identify specific\n",
      "contributions from both electronic and vibrational coherences and determine an\n",
      "excited state structure based on two strongly-coupled electronic states and two\n",
      "vibrational modes. Separation of the coherence pathways also uncovers the\n",
      "complex evolution of these coherences and the states involved.\n",
      "Link: http://arxiv.org/pdf/1310.6826v1\n",
      "----\n",
      "Title: Light control of the diffusion coefficient of active fluids\n",
      "Authors: [arxiv.Result.Author(\"Thomas Vourc'h\"), arxiv.Result.Author('Julien Léopoldès'), arxiv.Result.Author('Hassan Peerhossaini')]\n",
      "Summary: Active fluids refer to the fluids that contain self-propelled particles such\n",
      "as bacteria or micro-algae, whose properties differ fundamentally from the\n",
      "passive fluids. Such particles often exhibit an intermittent motion, with\n",
      "high-motility (run) periods broken by low-motility (tumble) periods. The\n",
      "average motion can be modified with external stresses, such as nutrient or\n",
      "light gradients, leading to a directed movement called chemotaxis and\n",
      "phototaxis, respectively. Using cyanobacterium Synechocystis sp.PCC 6803, a\n",
      "model micro-organism to study photosynthesis, we track the bacterial response\n",
      "to light stimuli, under isotropic and non-isotropic (directed) conditions. In\n",
      "particular, we investigate how the intermittent motility is influenced by\n",
      "illumination. We find that just after a rise in light intensity, the\n",
      "probability to be in the run state increases. This feature vanishes after a\n",
      "typical characteristic time of about 1 hour, when initial probability is\n",
      "recovered. Our results are well described by a mathematical model based on the\n",
      "linear response theory. When the perturbation is anisotropic, we observe a\n",
      "collective motion toward the light source (phototaxis). We show that the bias\n",
      "emerges due to more frequent runs in the direction of the light, whereas the\n",
      "run durations are longer whatever the direction.\n",
      "Link: http://arxiv.org/pdf/2003.02207v1\n",
      "----\n",
      "Title: Host control and nutrient trading in a photosynthetic symbiosis\n",
      "Authors: [arxiv.Result.Author('Andrew Dean'), arxiv.Result.Author('Ewan Minter'), arxiv.Result.Author('Megan Sorenson'), arxiv.Result.Author('Christopher Lowe'), arxiv.Result.Author('Duncan Cameron'), arxiv.Result.Author('Michael Brockurst'), arxiv.Result.Author('A. Jamie Wood')]\n",
      "Summary: Photosymbiosis is one of the most important evolutionary trajectories,\n",
      "resulting in the chloroplast and the subsequent development of all complex\n",
      "photosynthetic organisms. The ciliate Paramecium bursaria and the alga\n",
      "Chlorella have a well established and well studied light dependent\n",
      "endosymbiotic relationship. Despite its prominence there remain many unanswered\n",
      "questions regarding the exact mechanisms of the photosymbiosis. Of particular\n",
      "interest is how a host maintains and manages its symbiont load in response to\n",
      "the allocation of nutrients between itself and its symbionts. Here we construct\n",
      "a detailed mathematical model, parameterised from the literature, that\n",
      "explicitly incorporates nutrient trading within a deterministic model of both\n",
      "partners. The model demonstrates how the symbiotic relationship can manifest as\n",
      "parasitism of the host by the symbionts, mutualism, wherein both partners\n",
      "benefit, or exploitation of the symbionts by the hosts. We show that the\n",
      "precise nature of the photosymbiosis is determined by both environmental\n",
      "conditions (how much light is available for photosynthesis) and the level of\n",
      "control a host has over its symbiont load. Our model provides a framework\n",
      "within which it is possible to pose detailed questions regarding the\n",
      "evolutionary behaviour of this important example of an established light\n",
      "dependent endosymbiosis; we focus on one question in particular, namely the\n",
      "evolution of host control, and show using an adaptive dynamics approach that a\n",
      "moderate level of host control may evolve provided the associated costs are not\n",
      "prohibitive.\n",
      "Link: http://arxiv.org/pdf/1512.01595v1\n",
      "----\n",
      "Title: Integrated bio-electrochemical model for a micro photosynthetic power cell\n",
      "Authors: [arxiv.Result.Author('Hemanth Kumar Tanneru'), arxiv.Result.Author('Resmi Suresh M. P'), arxiv.Result.Author('Aravind Vyas Ramanan'), arxiv.Result.Author('Shahparnia. M'), arxiv.Result.Author('Muthukumaran Packirisamy'), arxiv.Result.Author('Pragasen Pillay'), arxiv.Result.Author('Sheldon Williamson'), arxiv.Result.Author('Philippe Juneau'), arxiv.Result.Author('Raghunathan Rengaswamy')]\n",
      "Summary: A simple first-principles mathematical model is developed to predict the\n",
      "performance of a micro photosynthetic power cell ($\\mu$PSC), an electrochemical\n",
      "device which generates electricity by harnessing electrons from photosynthesis\n",
      "in the presence of light. A lumped parameter approach is used to develop a\n",
      "model in which the electrochemical kinetic rate constants and diffusion effects\n",
      "are lumped into a single characteristic rate constant $K$. A non-parametric\n",
      "estimation of $K$ for the $\\mu$PSC is performed by minimizing the sum square\n",
      "errors (SSE) between the experimental and model predicted current and voltages.\n",
      "The developed model is validated by comparing the model predicted $v-i$\n",
      "characteristics with experimental data not used in the parameter estimation.\n",
      "Sensitivity analysis of the design parameters and the operational parameters\n",
      "reveal interesting insights for performance enhancement. Analysis of the model\n",
      "also suggests that there are two different operating regimes that are observed\n",
      "in this $\\mu$PSC. This modeling approach can be used in other designs of\n",
      "$\\mu$PSCs for performance enhancement studies.\n",
      "Link: http://arxiv.org/pdf/1609.09254v1\n",
      "----\n",
      "Title: Assessment of the Ab Initio Bethe-Salpeter Equation Approach for the Low-Lying Excitation Energies of Bacteriochlorophylls and Chlorophylls\n",
      "Authors: [arxiv.Result.Author('Zohreh Hashemi'), arxiv.Result.Author('Linn Leppert')]\n",
      "Summary: Bacteriochlorophyll and Chlorophyll molecules are crucial building blocks of\n",
      "the photosynthetic apparatus in bacteria, algae and plants. Embedded in\n",
      "transmembrane protein complexes, they are responsible for the primary processes\n",
      "of photosynthesis: excitation energy and charge transfer. Here, we use ab\n",
      "initio many body perturbation theory within the $GW$ approximation and\n",
      "Bethe-Salpeter equation (BSE) approach to calculate the electronic structure\n",
      "and optical excitations of Bacteriochlorophylls $a$, $b$, $c$, $d$ and $e$ and\n",
      "Chlorophylls $a$ and $b$. We systematically study the effects of structure,\n",
      "basis set size, partial self-consistency in $GW$, and the underlying\n",
      "exchange-correlation approximation, and compare our calculations with results\n",
      "from time-dependent density functional theory, multireference RASPT2 and\n",
      "experimental literature results. We find that optical excitations calculated\n",
      "with $GW$+BSE are in excellent agreement with experimental data, with an\n",
      "average deviation of less than 100\\,meV for the first three bright excitations\n",
      "of the entire family of (Bacterio)chlorophylls. Contrary to state-of-the-art\n",
      "TDDFT with an optimally-tuned range-separated hybrid functional, this accuracy\n",
      "is achieved in a parameter-free approach. Moreover, $GW$+BSE predicts the\n",
      "energy differences between the low-energy excitations correctly, and eliminates\n",
      "spurious charge transfer states that TDDFT with (semi)local approximations is\n",
      "known to produce. Our study provides accurate reference results and highlights\n",
      "the potential of the $GW$+BSE approach for the simulation of larger pigment\n",
      "complexes.\n",
      "Link: http://arxiv.org/pdf/2008.00917v2\n",
      "----\n",
      "Title: Investigating the Automatic Classification of Algae Using Fusion of Spectral and Morphological Characteristics of Algae via Deep Residual Learning\n",
      "Authors: [arxiv.Result.Author('Jason L. Deglint'), arxiv.Result.Author('Chao Jin'), arxiv.Result.Author('Alexander Wong')]\n",
      "Summary: Under the impact of global climate changes and human activities, harmful\n",
      "algae blooms in surface waters have become a growing concern due to negative\n",
      "impacts on water related industries. Therefore, reliable and cost effective\n",
      "methods of quantifying the type and concentration of threshold levels of algae\n",
      "cells has become critical for ensuring successful water management. In this\n",
      "work, we present SAMSON, an innovative system to automatically classify\n",
      "multiple types of algae from different phyla groups by combining standard\n",
      "morphological features with their multi-wavelength signals. Two phyla with\n",
      "focused investigation in this study are the Cyanophyta phylum (blue-green\n",
      "algae), and the Chlorophyta phylum (green algae). We use a custom-designed\n",
      "microscopy imaging system which is configured to image water samples at two\n",
      "fluorescent wavelengths and seven absorption wavelengths using\n",
      "discrete-wavelength high-powered light emitting diodes (LEDs). Powered by\n",
      "computer vision and machine learning, we investigate the possibility and\n",
      "effectiveness of automatic classification using a deep residual convolutional\n",
      "neural network. More specifically, a classification accuracy of 96% was\n",
      "achieved in an experiment conducted with six different algae types. This high\n",
      "level of accuracy was achieved using a deep residual convolutional neural\n",
      "network that learns the optimal combination of spectral and morphological\n",
      "features. These findings elude to the possibility of leveraging a unique\n",
      "fingerprint of algae cell (i.e. spectral wavelengths and morphological\n",
      "features) to automatically distinguish different algae types. Our work herein\n",
      "demonstrates that, when coupled with multi-band fluorescence microscopy,\n",
      "machine learning algorithms can potentially be used as a robust and\n",
      "cost-effective tool for identifying and enumerating algae cells.\n",
      "Link: http://arxiv.org/pdf/1810.10889v1\n",
      "----\n",
      "Title: Light control of the flow of phototactic microswimmer suspensions\n",
      "Authors: [arxiv.Result.Author('Xabel Garcia'), arxiv.Result.Author('Salima Rafaï'), arxiv.Result.Author('Philippe Peyla')]\n",
      "Summary: Some micro-algae are sensitive to light intensity gradients. This property is\n",
      "known as phototaxis: the algae swim toward a light source (positive\n",
      "phototaxis). We use this property to control the motion of micro-algae within a\n",
      "Poiseuille flow using light. The combination of flow vorticity and phototaxis\n",
      "results in a concentration of algae around the center of the flow. Intermittent\n",
      "light exposure allows analysis of the dynamics of this phenomenon and its\n",
      "reversibility. With this phenomenon, we hope to pave the way toward new algae\n",
      "concentration techniques (a bottleneck challenge in hydrogen algal production)\n",
      "and toward the improvement of pollutant bio-detector technology.\n",
      "Link: http://arxiv.org/pdf/1301.2431v1\n",
      "----\n",
      "Title: Algae-Filler Artificial Timber with an Ultralow Binder Content\n",
      "Authors: [arxiv.Result.Author('Haozhe Yi'), arxiv.Result.Author('Kiwon Oh'), arxiv.Result.Author('Rui Kou'), arxiv.Result.Author('Yu Qiao')]\n",
      "Summary: Algae cultivation is an active area of study for carbon sequestration, while\n",
      "the large amount of produced algae must be upcycled. In the current study, we\n",
      "fabricated artificial timber based on algae filler, with only 2~4% epoxy\n",
      "binder. The flexural strength could be comparable with those of softwoods. The\n",
      "binder was efficiently dispersed in the algae phase through diluent-aided\n",
      "compaction self-assembly. The important processing parameters included the\n",
      "binder content, the filler morphology, the compaction pressure, the diluent\n",
      "ratio, and the curing condition. This research not only is critical to carbon\n",
      "sequestration, but also helps reduce the consumption of conventional\n",
      "construction materials.\n",
      "Link: http://arxiv.org/pdf/2006.02574v2\n",
      "----\n",
      "Title: SAMSON: Spectral Absorption-fluorescence Microscopy System for ON-site-imaging of algae\n",
      "Authors: [arxiv.Result.Author('Jason L. Deglint'), arxiv.Result.Author('Lyndon Tang'), arxiv.Result.Author('Yitian Wang'), arxiv.Result.Author('Chao Jin'), arxiv.Result.Author('Alexander Wong')]\n",
      "Summary: This paper presents SAMSON, a Spectral Absorption-fluorescence Microscopy\n",
      "System for ON-site-imaging of algae within a water sample. Designed to be\n",
      "portable and low-cost for on-site use, the optical sub-system of SAMSON\n",
      "consists of a mixture of low-cost optics and electronics, designed specifically\n",
      "to capture both fluorescent and absorption responses from a water sample. The\n",
      "graphical user interface (GUI) sub-system of SAMSON was designed to enable\n",
      "flexible visualisation of algae in the water sample in real-time, with the\n",
      "ability to perform fine-grained exposure control and illumination wavelength\n",
      "selection. We demonstrate SAMSON's capabilities by equipping the system with\n",
      "two fluorescent illumination sources and seven absorption illumination sources\n",
      "to enable the capture of multispectral data from six different algae species\n",
      "(three from the Cyanophyta phylum (blue-green algae) and three from the\n",
      "Chlorophyta phylum (green algae)). The key benefit of SAMSON is the ability to\n",
      "perform rapid acquisition of fluorescence and absorption data at different\n",
      "wavelengths and magnification levels, thus opening the door for machine\n",
      "learning methods to automatically identify and enumerate different algae in\n",
      "water samples using this rich wealth of data.\n",
      "Link: http://arxiv.org/pdf/1810.09838v1\n",
      "----\n",
      "Title: The role of plasma-activated water on the growth of freshwater algae Chlorella Pyrenoidosa and Chlorella Sorokiniana\n",
      "Authors: [arxiv.Result.Author('Vikas Rathore'), arxiv.Result.Author('Sudhir Kumar Nema')]\n",
      "Summary: In the present work we have conducted two studies. In the first study, we\n",
      "investigated the role of plasma-activated water (PAW) in algae growth\n",
      "inhibition and in the second study, efforts are made to understand the role of\n",
      "PAW as a nitrogen source for algae growth enhancement. Two freshwater algae\n",
      "species are selected for the present study named Chlorella Pyrenoidosa and\n",
      "Chlorella Sorokiniana. The PAW is prepared using a pencil plasma jet and air as\n",
      "a plasma forming gas. The plasma is characterized electrically and\n",
      "identification of generated species in plasma is carried out using optical\n",
      "emission spectroscopy. The study clearly indicated that more oxidizing PAW\n",
      "exhibits algicidal effect. The PAW treatment with both the algae species\n",
      "substantially decreased their growth compared to control. Moreover, the\n",
      "morphology of algae cells showed damage and cells structure get ruptured after\n",
      "PAW treatment. In the second study, a less reactive PAW (low oxidizing\n",
      "potential) used as a nitrogen replacement in Bolds Basal Medium. The PAW-grown\n",
      "Chlorella Pyrenoidosa and Chlorella Sorokiniana showed higher growth compared\n",
      "to control. Also, a higher concentration of chlorophyll a and b, sugar, and\n",
      "protein observed compared to control. Further, we observed lower antioxidant\n",
      "enzymatic activities in PAW-grown algae compared to control. In conclusion, the\n",
      "PAW has algicidal efficacy as well as can be used as nitrogen source in\n",
      "aquaculture to enhance algae growth.\n",
      "Link: http://arxiv.org/pdf/2302.07102v1\n",
      "----\n",
      "Title: Photosynthesis on Exoplanets and Exomoons from Reflected Light\n",
      "Authors: [arxiv.Result.Author('Manasvi Lingam'), arxiv.Result.Author('Abraham Loeb')]\n",
      "Summary: Photosynthesis offers a convenient means of sustaining biospheres. We\n",
      "quantify the constraints for photosynthesis to be functional on the permanent\n",
      "nightside of tidally locked rocky exoplanets via reflected light from their\n",
      "exomoons. We show that the exomoons must be at least half the size of Earth's\n",
      "moon in order for conventional oxygenic photosynthesis to operate. This\n",
      "scenario of photosynthesis is unlikely for exoplanets around late-type M-dwarfs\n",
      "due to the low likelihood of large exomoons and their orbital instability over\n",
      "long timescales. Subsequently, we investigate the prospects for photosynthesis\n",
      "on habitable exomoons via reflected light from the giant planets that they\n",
      "orbit. Our analysis indicates that such photosynthetic biospheres are\n",
      "potentially sustainable on these moons except those around late-type M-dwarfs.\n",
      "We conclude our analysis by delineating certain physiological and biochemical\n",
      "features of photosynthesis and other carbon fixation pathways, and the\n",
      "likelihood of their evolution on habitable planets and moons.\n",
      "Link: http://arxiv.org/pdf/1907.12576v2\n",
      "----\n",
      "Title: Spectral signatures of photosynthesis II: coevolution with other stars and the atmosphere on extrasolar worlds\n",
      "Authors: [arxiv.Result.Author('Nancy Y. Kiang'), arxiv.Result.Author('Antigona Segura'), arxiv.Result.Author('Giovanna Tinetti'), arxiv.Result.Author('Govindjee'), arxiv.Result.Author('Robert E. Blankenship'), arxiv.Result.Author('Martin Cohen'), arxiv.Result.Author('Janet Siefert'), arxiv.Result.Author('David Crisp'), arxiv.Result.Author('Victoria S. Meadows')]\n",
      "Summary: As photosynthesis on Earth produces the primary signatures of life that can\n",
      "be detected astronomically at the global scale, a strong focus of the search\n",
      "for extrasolar life will be photosynthesis, particularly photosynthesis that\n",
      "has evolved with a different parent star. We take planetary atmospheric\n",
      "compositions simulated by Segura, et al. (2003, 2005) for Earth-like planets\n",
      "around observed F2V and K2V stars, modeled M1V and M5V stars, and around the\n",
      "active M4.5V star AD Leo; our scenarios use Earth's atmospheric composition as\n",
      "well as very low O2 content in case anoxygenic photosynthesis dominates. We\n",
      "calculate the incident spectral photon flux densities at the surface of the\n",
      "planet and under water. We identify bands of available photosynthetically\n",
      "relevant radiation and find that photosynthetic pigments on planets around F2V\n",
      "stars may peak in absorbance in the blue, K2V in the red-orange, and M stars in\n",
      "the NIR, in bands at 0.93-1.1 microns, 1.1-1.4 microns, 1.5-1.8 microns, and\n",
      "1.8-2.5 microns. In addition, we calculate wavelength restrictions for\n",
      "underwater organisms and depths of water at which they would be protected from\n",
      "UV flares in the early life of M stars. We estimate the potential productivity\n",
      "for both surface and underwater photosynthesis, for both oxygenic and\n",
      "anoxygenic photosynthesis, and for hypothetical photosynthesis in which longer\n",
      "wavelength, multi-photosystem series are used.\n",
      "Link: http://arxiv.org/pdf/astro-ph/0701391v1\n",
      "----\n",
      "Title: Phenotypic landscape inference reveals multiple evolutionary paths to C$_4$ photosynthesis\n",
      "Authors: [arxiv.Result.Author('Ben P. Williams'), arxiv.Result.Author('Iain G. Johnston'), arxiv.Result.Author('Sarah Covshoff'), arxiv.Result.Author('Julian M. Hibberd')]\n",
      "Summary: C$_4$ photosynthesis has independently evolved from the ancestral C$_3$\n",
      "pathway in at least 60 plant lineages, but, as with other complex traits, how\n",
      "it evolved is unclear. Here we show that the polyphyletic appearance of C$_4$\n",
      "photosynthesis is associated with diverse and flexible evolutionary paths that\n",
      "group into four major trajectories. We conducted a meta-analysis of 18 lineages\n",
      "containing species that use C$_3$, C$_4$, or intermediate C$_3$-C$_4$ forms of\n",
      "photosynthesis to parameterise a 16-dimensional phenotypic landscape. We then\n",
      "developed and experimentally verified a novel Bayesian approach based on a\n",
      "hidden Markov model that predicts how the C$_4$ phenotype evolved. The\n",
      "alternative evolutionary histories underlying the appearance of C$_4$\n",
      "photosynthesis were determined by ancestral lineage and initial phenotypic\n",
      "alterations unrelated to photosynthesis. We conclude that the order of C$_4$\n",
      "trait acquisition is flexible and driven by non-photosynthetic drivers. This\n",
      "flexibility will have facilitated the convergent evolution of this complex\n",
      "trait.\n",
      "Link: http://arxiv.org/pdf/1409.4978v1\n",
      "----\n",
      "Title: Algae Detection Using Computer Vision and Deep Learning\n",
      "Authors: [arxiv.Result.Author('Arabinda Samantaray'), arxiv.Result.Author('Baijian Yang'), arxiv.Result.Author('J. Eric Dietz'), arxiv.Result.Author('Byung-Cheol Min')]\n",
      "Summary: A disconcerting ramification of water pollution caused by burgeoning\n",
      "populations, rapid industrialization and modernization of agriculture, has been\n",
      "the exponential increase in the incidence of algal growth across the globe.\n",
      "Harmful algal blooms (HABs) have devastated fisheries, contaminated drinking\n",
      "water and killed livestock, resulting in economic losses to the tune of\n",
      "millions of dollars. Therefore, it is important to constantly monitor water\n",
      "bodies and identify any algae build-up so that prompt action against its\n",
      "accumulation can be taken and the harmful consequences can be avoided. In this\n",
      "paper, we propose a computer vision system based on deep learning for algae\n",
      "monitoring. The proposed system is fast, accurate and cheap, and it can be\n",
      "installed on any robotic platforms such as USVs and UAVs for autonomous algae\n",
      "monitoring. The experimental results demonstrate that the proposed system can\n",
      "detect algae in distinct environments regardless of the underlying hardware\n",
      "with high accuracy and in real time.\n",
      "Link: http://arxiv.org/pdf/1811.10847v1\n",
      "----\n",
      "Title: Bacterial tracking of motile algae assisted by algal cell's vorticity field\n",
      "Authors: [arxiv.Result.Author('Janos Tobias Locsei'), arxiv.Result.Author('Timothy J Pedley')]\n",
      "Summary: Previously published experimental work by other authors has shown that\n",
      "certain motile marine bacteria are able to track free swimming algae by\n",
      "executing a zigzag path and steering toward the algae at each turn. Here, we\n",
      "propose that the apparent steering behaviour could be a hydrodynamic effect,\n",
      "whereby an algal cell's vorticity and strain-rate fields rotate a pursuing\n",
      "bacterial cell in the appropriate direction. Using simplified models for the\n",
      "bacterial and algal cells, we numerically compute the trajectory of a bacterial\n",
      "cell and demonstrate the plausibility of this hypothesis.\n",
      "Link: http://arxiv.org/pdf/0806.0744v1\n",
      "----\n",
      "Title: Spectra of Reduced Fractals and Their Applications in Biology\n",
      "Authors: [arxiv.Result.Author('Diana T. Pham'), arxiv.Result.Author('Zdzislaw E. Musielak')]\n",
      "Summary: Fractals with different levels of self-similarity and magnification are\n",
      "defined as reduced fractals. It is shown that spectra of these reduced fractals\n",
      "can be constructed and used to describe levels of complexity of natural\n",
      "phenomena. Specific applications to biological systems, such as green algae,\n",
      "are performed, and it is suggested that the obtained spectra can be used to\n",
      "classify the considered algae by identifying spectra associated with them. The\n",
      "ranges of these spectra for green algae are determined and their extension to\n",
      "other biological as well as other natural systems is proposed.\n",
      "Link: http://arxiv.org/pdf/2111.01719v2\n",
      "----\n",
      "Title: Synthesis of Sugar and fixation of CO2 through Artificial Photosynthesis driving by Hydrogen or Electricity\n",
      "Authors: [arxiv.Result.Author('Weidong Huang')]\n",
      "Summary: The overall process of photosynthesis consists of two main phases, the\n",
      "so-called light and dark eactions: light energy is absorbed by chlorophyll\n",
      "molecules and transferred to regenerate NADH and ATP, then drive Calvin-Benson\n",
      "cycle to synthesize sugar. In order to synthesize sugar through artificial\n",
      "photosynthesis, one of the key is to regenerate ATP economically and improve\n",
      "the efficiency of dark reactions. Here 9 kinds of dark reaction pathways are\n",
      "proposed, which only NADH is regenearated from hydrogen or electricity for\n",
      "driving, the efficiency of dark reactions is improved, combined with solar\n",
      "photovoltaic or solar hydrogen technology, the total efficiency of artificial\n",
      "photosynthesis can reach 30%, several ten times more than natural\n",
      "photosynthesis. One of them, to use chemical synthesis of formaldehyde from CO2\n",
      "and H2, no NADH and ATP is need, to synthesize sugar efficiently through 9\n",
      "enzymes, so it will be easier to produce in large scale, and the sugar will be\n",
      "a good energy carrier as the sugar can be efficiently converted to energy\n",
      "carrier hydrogen through enzymes.\n",
      "Link: http://arxiv.org/pdf/1009.0310v1\n",
      "----\n",
      "Title: Constraints on Aquatic Photosynthesis for Terrestrial Planets Around Other Stars\n",
      "Authors: [arxiv.Result.Author('Manasvi Lingam'), arxiv.Result.Author('Abraham Loeb')]\n",
      "Summary: Aquatic photosynthesis plays a major role in carbon fixation and O$_2$\n",
      "production on Earth. In this Letter, we analyze the prospects for oxygenic\n",
      "photosynthesis in aquatic environments on modern Earth-analogs around F-, G-,\n",
      "K- and M-type stars. Our analysis takes into account the spectral type of the\n",
      "host star, attenuation of light by aquatic organisms, and rates of respiration\n",
      "and photosynthesis. We study the compensation depth ($\\mathcal{Z}_\\mathrm{CO}$)\n",
      "and the critical depth ($\\mathcal{Z}_\\mathrm{CR}$), defined respectively as the\n",
      "locations where the net growth rates and vertically integrated net growth rates\n",
      "of photoautotrophs become zero. Our analysis suggests that\n",
      "$\\mathcal{Z}_\\mathrm{CO}$ declines by more than an order of magnitude as one\n",
      "moves from the habitable zones around Sun-like stars to late-type M-dwarfs, but\n",
      "$\\mathcal{Z}_\\mathrm{CR}$ decreases by only a modest amount ($\\sim 40\\%$). For\n",
      "M-dwarf exoplanets, we propose that the photosynthetic red edge may constitute\n",
      "a more robust biosignature of aquatic photosynthesis compared to atmospheric\n",
      "O$_2$.\n",
      "Link: http://arxiv.org/pdf/1912.04301v2\n",
      "----\n",
      "Title: Perturbations to aquatic photosynthesis due to high-energy cosmic ray induced muon flux in the extragalactic shock model\n",
      "Authors: [arxiv.Result.Author('Lien Rodriguez'), arxiv.Result.Author('Rolando Cardenas'), arxiv.Result.Author('Oscar Rodriguez')]\n",
      "Summary: We modify a mathematical model of photosynthesis to quantify the\n",
      "perturbations that high energy muons could make on aquatic primary\n",
      "productivity. Then we apply this in the context of the extragalactic shock\n",
      "model, according to which Earth receives an enhanced dose of high-energy cosmic\n",
      "rays when it is at the galactic north. We obtain considerable reduction in the\n",
      "photosynthesis rates, consistent with potential drops in biodiversity.\n",
      "Link: http://arxiv.org/pdf/1309.5537v1\n",
      "----\n",
      "Title: Dark states in quantum photosynthesis\n",
      "Authors: [arxiv.Result.Author('S. V. Kozyrev'), arxiv.Result.Author('I. V. Volovich')]\n",
      "Summary: We discuss a model of quantum photosynthesis with degeneracy in the\n",
      "light-harvesting system. We consider interaction of excitons in chromophores\n",
      "with light and phonons (vibrations of environment). These interactions have\n",
      "dipole form but are different (are related to non-parallel vectors of \"bright\"\n",
      "states). We show that this leads to excitation of non-decaying \"dark\" states.\n",
      "We discuss relation of this model to the known from spectroscopical experiments\n",
      "phenomenon of existence of photonic echo in quantum photosynthesis.\n",
      "Link: http://arxiv.org/pdf/1603.07182v1\n",
      "----\n",
      "Title: Negentropy concept revisited: Standard thermodynamic properties of 16 bacteria, fungi and algae species\n",
      "Authors: [arxiv.Result.Author('Marko Popovic')]\n",
      "Summary: Standard molar and specific (per gram) enthalpy of formation, entropy and\n",
      "Gibbs free energy of formation of biomatter have been determined for 16\n",
      "microorganism species, including Methylococcus capsulatus, Klebsiella\n",
      "aerogenes, Paracoccus denitrificans, Escherichia coli, Pseudomonas C12B,\n",
      "Aerobacter aerogenes, Magnetospirillum gryphiswaldense, Saccharomyces\n",
      "cerevisiae, Candida utilis, Chlorella, Chlorella a sp. MP-1, C. minutissima, C.\n",
      "pyrenoidosa and C. vulgaris. The average values of ${\\Delta}_{f}H{\\deg}$ are\n",
      "for bacteria -4.22 kJ/g, for fungi -5.03 kJ/g and for algae -4.40 kJ/g. The\n",
      "average values of S{\\deg} are for bacteria 1.48 J/g K, for fungi 1.45 J/g K and\n",
      "for algae 1.48 J/g K. The average values of ${\\Delta}_{f}G{\\deg}$ are for\n",
      "bacteria -2.30 kJ/g, for fungi -3.15 kJ/g and for algae -2.48 kJ/g. Based on\n",
      "the results, an analysis was made of colony growth in time. In the first three\n",
      "phases, entropy change of microorganisms plated in a Petri dish is positive and\n",
      "entropy of the colony increases. In the fourth phase, due to limitation of\n",
      "nutrients, entropy remains constant. In the fifth phase, due to lack of\n",
      "nutrients, entropy of the colony decreases and microorganisms die-off. Based on\n",
      "the results, the negentropy concept is analyzed.\n",
      "Link: http://arxiv.org/pdf/1901.00494v1\n",
      "----\n",
      "Title: Model of Algal Growth Depending on Nutrients and Inorganic Carbon in a Poorly Mixed Water Column\n",
      "Authors: [arxiv.Result.Author('Jimin Zhang'), arxiv.Result.Author('Junping Shi'), arxiv.Result.Author('Xiaoyuan Chang')]\n",
      "Summary: In this paper, we establish a reaction-diffusion-advection partial\n",
      "differential equation model to describe the growth of algae depending on both\n",
      "nutrients and inorganic carbon in a poorly mixed water column. Nutrients from\n",
      "the water bottom and inorganic carbon from the water surface form an asymmetric\n",
      "resource supply mechanism on the algal growth. The existence and stability of\n",
      "semi-trivial steady state and coexistence steady state of the model are proved,\n",
      "and a threshold condition for the regime shift from extinction to survival of\n",
      "algae is established. The influence of environmental parameters on the vertical\n",
      "distribution of algae is investigated in the water column. It is shown that the\n",
      "vertical distribution of algae can exhibit many different profiles under the\n",
      "joint limitation of nutrients and inorganic carbon.\n",
      "Link: http://arxiv.org/pdf/2002.02803v1\n",
      "----\n",
      "Title: Diffusive dynamics of elongated particles in active colloidal suspensions of motile algae\n",
      "Authors: [arxiv.Result.Author('Florian von Rüling'), arxiv.Result.Author('Francine Kolley'), arxiv.Result.Author('Alexey Eremin')]\n",
      "Summary: Swimming microorganisms can influence the diffusion of passive particles. The\n",
      "effect of this swimmer-particle interaction depends on different properties,\n",
      "such as the hydrodynamic field of the swimmer and the relative sizes of\n",
      "microorganisms and particles. We investigated an enhancement of the diffusion\n",
      "of silica doublets in a suspension of microalgae Chlamydomonas reinhardtii in a\n",
      "flat capillary. Depending on the concentration of microswimmers, the\n",
      "translational and rotational diffusion constants increase by several orders of\n",
      "magnitude in the presence of the swimming algae. For low concentrations of\n",
      "algae, the doublets exhibit Brownian motion in a fluctuating flow field\n",
      "generated by multiple swimmers. One can observe strong, diffusive transport\n",
      "caused by occasional large displacements. At high swimmer concentration, the\n",
      "algae form dense clusters, where the rotational motion of the doublets shows a\n",
      "subdiffusive behaviour while the translational motion remains diffusive.\n",
      "Link: http://arxiv.org/pdf/2003.10291v2\n",
      "----\n",
      "Title: Evolution of Photosynthesis and Biospheric Oxygenation Contingent Upon Nitrogen Fixation?\n",
      "Authors: [arxiv.Result.Author('John W. Grula')]\n",
      "Summary: How photosynthesis by Precambrian cyanobacteria oxygenated Earth's biosphere\n",
      "remains incompletely understood. Here it is argued that the oxic transition,\n",
      "which took place between approximately 2.3 and 0.5 Gyr ago, required a great\n",
      "proliferation of cyanobacteria, and this in turn depended on their ability to\n",
      "fix nitrogen via the nitrogenase enzyme system. However, the ability to fix\n",
      "nitrogen was not a panacea, and the rate of biospheric oxygenation may still\n",
      "have been affected by nitrogen constraints on cyanobacterial expansion.\n",
      "Evidence is presented for why cyanobacteria probably have a great need for\n",
      "fixed nitrogen than other prokaryotes, underscoring the importance of their\n",
      "ability to fix nitrogen. The connection between nitrogen fixation and the\n",
      "evolution of photosynthesis is demonstrated by the similarities between\n",
      "nitrogenase and enzymes critical for the biosynthesis of (bacterio)chlorophyll.\n",
      "It is hypothesized that biospheric oxygenation would not have occurred if the\n",
      "emergence of cyanobacteria had not been preceded by the evolution of nitrogen\n",
      "fixation, and if these organisms had not also acquired the ability to fix\n",
      "nitrogen at the beginning of or very early in their history. The evolution of\n",
      "nitrogen fixation also appears to have been a precondition for the evolution of\n",
      "(bacterio)chlorophyll-based photosynthesis. Given that some form of chlorophyll\n",
      "is obligatory for true photosynthesis, and its light absorption and chemical\n",
      "properties make it a \"universal pigment,\" it may be predicted that the\n",
      "evolution of nitrogen fixation and photosynthesis are also closely linked on\n",
      "other Earth- like planets.\n",
      "Link: http://arxiv.org/pdf/astro-ph/0605310v1\n",
      "----\n",
      "Title: Unified representation of the C3, C4, and CAM photosynthetic pathways with the Photo3 model\n",
      "Authors: [arxiv.Result.Author('Samantha Hartzell'), arxiv.Result.Author('Mark S. Bartlett'), arxiv.Result.Author('Amilcare Porporato')]\n",
      "Summary: Recently, interest in crassulacean acid metabolism (CAM) photosynthesis has\n",
      "risen and new, physiologically based CAM models have emerged. These models show\n",
      "promise, yet unlike the more widely used physiological models of C3 and C4\n",
      "photosynthesis, their complexity has thus far inhibited their adoption in the\n",
      "general community. Indeed, most efforts to assess the potential of CAM still\n",
      "rely on empirically based environmental productivity indices, which makes\n",
      "uniform comparisons between CAM and non-CAM species difficult. In order to\n",
      "represent C3, C4, and CAM photosynthesis in a consistent, physiologically based\n",
      "manner, we introduce the Photo3 model. This work builds on a common\n",
      "photosynthetic and hydraulic core and adds additional components to depict the\n",
      "circadian rhythm of CAM photosynthesis and the carbon-concentrating mechanism\n",
      "of C4 photosynthesis. This allows consistent comparisons of the three\n",
      "photosynthetic types for the first time. It also allows the representation of\n",
      "intermediate C3-CAM behavior through the adjustment of a single model\n",
      "parameter. Model simulations of *Opuntia ficus-indica* (CAM), *Sorghum bicolor*\n",
      "(C4), and *Triticum aestivum* (C3) capture the diurnal behavior of each species\n",
      "as well as the cumulative effects of long-term water limitation. The results\n",
      "show potential for use in understanding CAM productivity, ecology, and climate\n",
      "feedbacks and in evaluating the tradeoffs between C3, C4, and CAM\n",
      "photosynthesis.\n",
      "Link: http://arxiv.org/pdf/1804.10667v2\n",
      "----\n",
      "Title: Photosynthesis re-wired on the pico-second timescale\n",
      "Authors: [arxiv.Result.Author('Tomi K. Baikie'), arxiv.Result.Author('Laura T. Wey'), arxiv.Result.Author('Hitesh Medipally'), arxiv.Result.Author('Erwin Reisner'), arxiv.Result.Author('Marc M. Nowaczyk'), arxiv.Result.Author('Richard H. Friend'), arxiv.Result.Author('Christopher J. Howe'), arxiv.Result.Author('Christoph Schnedermann'), arxiv.Result.Author('Akshay Rao'), arxiv.Result.Author('Jenny Z. Zhang')]\n",
      "Summary: Photosystems II and I (PSII and PSI) are the reaction centre complexes that\n",
      "drive the light reactions of photosynthesis. PSII performs light-driven water\n",
      "oxidation (quantum efficiencies and catalysis rates of up to 80% and 1000\n",
      "$e^{-}\\text{s}^{-1}$, respectively) and PSI further photo-energises the\n",
      "harvested electrons (quantum efficiencies of ~100%). The impressive performance\n",
      "of the light harvesting components of photosynthesis has motivated extensive\n",
      "biological, artificial and biohybrid approaches to re-wire photosynthesis to\n",
      "enable higher efficiencies and new reaction pathways, such as H2 evolution or\n",
      "alternative CO2 fixation. To date these approaches have focussed on charge\n",
      "extraction at the terminal electron quinones of PSII and terminal iron-sulfur\n",
      "clusters of PSI. Ideally electron extraction would be possible immediately from\n",
      "the photoexcited reaction centres to enable the greatest thermodynamic gains.\n",
      "However, this was believed to be impossible because the reaction centres are\n",
      "buried around 4 nm within PSII and 5 nm within PSI from the cytoplasmic face.\n",
      "Here, we demonstrate using in vivo ultrafast transient absorption (TA)\n",
      "spectroscopy that it is possible to extract electrons directly from\n",
      "photoexcited PSI and PSII, using both live cyanobacterial cells and isolated\n",
      "photosystems, with the exogenous electron mediator 2,6-dichloro1,4-benzoquinone\n",
      "(DCBQ). We postulate that DCBQ can oxidise peripheral chlorophyll pigments\n",
      "participating in highly delocalised charge transfer (CT) states after initial\n",
      "photoexcitation. Our results open new avenues to study and re-wire\n",
      "photosynthesis for bioenergy and semi-artificial photosynthesis.\n",
      "Link: http://arxiv.org/pdf/2201.13370v2\n",
      "----\n",
      "Title: Can the photosynthesis first step quantum mechanism be explained?\n",
      "Authors: [arxiv.Result.Author('Marco Sacilotti'), arxiv.Result.Author('Euclides Almeida'), arxiv.Result.Author('Claudia C. B. O. Mota'), arxiv.Result.Author('Frederico Dias Nunes'), arxiv.Result.Author('Anderson S. L. Gomes')]\n",
      "Summary: Photosynthesis first step mechanism concerns the sunlight absorption and both\n",
      "negative and positive charges separation. Recent and important photosynthesis\n",
      "literature claims that this mechanism is quantum mechanics controlled, however\n",
      "without presenting qualitative or quantitative scientifically based mechanism.\n",
      "The present accepted and old-fashioned photosynthesis mechanism model suffers\n",
      "from few drawbacks and an important issue is the absence of driving force for\n",
      "negative and positive charges separation. This article presents a new\n",
      "qualitative model for this first step mechanism in natural catalytic systems\n",
      "such as photosynthesis in green leaves. The model uses a concept of\n",
      "semiconductor band gap engineering, such as the staggered energy band gap\n",
      "line-up in semiconductors. To explain the primary mechanism in natural\n",
      "photosynthesis the proposal is the following: incident light is absorbed inside\n",
      "the leaves causing charges separation. The only energetic configuration that\n",
      "allows charges separation under illumination is the staggered one between two\n",
      "materials or molecules. We explain why (e-, h+) interacting charges can be\n",
      "separated by using an energy staggered configuration, under illumination.\n",
      "Following this model, the green light of plants can be seen as related to the\n",
      "spent energy for charges separation. Green colour being mostly an emission and\n",
      "not a reflection as currently presented. The arguments mentioned below show why\n",
      "we cannot explain the photosynthesis first step mechanism, based on the\n",
      "presently accepted model, and therefore the alternative model is presented.\n",
      "Link: http://arxiv.org/pdf/1005.1337v1\n",
      "----\n",
      "Title: On the habitability of exoplanets orbiting Proxima Centauri\n",
      "Authors: [arxiv.Result.Author('Madeleine Lopez'), arxiv.Result.Author('Rolando Cardenas'), arxiv.Result.Author('Lien Rodriguez')]\n",
      "Summary: We apply a mathematical model for photosynthesis to quantitatively assess the\n",
      "habitability of a hypothetical planet orbiting Proxima Centauri, inside the so\n",
      "called habitability zone. Results suggest significant viability for primary\n",
      "biological productivity, provided living organisms have evolved to reach the\n",
      "ability of using infrared light for photosynthesis.\n",
      "Link: http://arxiv.org/pdf/1401.3267v1\n",
      "----\n",
      "Title: What limits photosynthesis? Identifying the thermodynamic constraints of the biosphere within the Earth system\n",
      "Authors: [arxiv.Result.Author('Axel Kleidon')]\n",
      "Summary: Photosynthesis converts sunlight into the chemical free energy that feeds the\n",
      "Earth's biosphere, yet at levels much lower than what thermodynamics would\n",
      "allow for. I propose here that photosynthesis is nevertheless thermodynamically\n",
      "limited, but this limit acts indirectly on the material exchange of water and\n",
      "carbon dioxide. I substantiate this interpretation using global\n",
      "observation-based datasets of radiation, photosynthesis, precipitation and\n",
      "evaporation. I first calculate the conversion efficiency of photosynthesis in\n",
      "terrestrial ecosystems and its climatological variation, with a median\n",
      "efficiency of 0.78% (n = 13445). The rates tightly correlate with evaporation\n",
      "(r2 = 0.89), which demonstrates the importance of the coupling of\n",
      "photosynthesis to material exchange. I then infer evaporation from the maximum\n",
      "material exchange between the surface and the atmosphere that is\n",
      "thermodynamically possible using datasets of solar radiation and precipitation.\n",
      "This inferred rate closely correlates with the observation-based evaporation\n",
      "dataset (r2 = 0.85). When this rate is converted back into photosynthetic\n",
      "activity, the resulting patterns correlate highly with the observation-based\n",
      "dataset (r2 = 0.56). This supports the interpretation that it is not energy\n",
      "directly that limits terrestrial photosynthesis, but rather the material\n",
      "exchange that is driven by sunlight. This interpretation can explain the very\n",
      "low, observed conversion efficiency of photosynthesis in terrestrial ecosystems\n",
      "as well as its spatial variations. More generally, this implies that one needs\n",
      "to take the necessary material flows and exchanges associated with life into\n",
      "account to understand the thermodynamics of life. This, ultimately, requires a\n",
      "perspective that links the activity of the biosphere to the thermodynamic\n",
      "constraints of transport processes in the Earth system.\n",
      "Link: http://arxiv.org/pdf/2005.06529v3\n",
      "----\n",
      "Title: Automatic Identification of Scenedesmus Polymorphic Microalgae from Microscopic Images\n",
      "Authors: [arxiv.Result.Author('Jhony-Heriberto Giraldo-Zuluaga'), arxiv.Result.Author('Geman Diez'), arxiv.Result.Author('Alexander Gomez'), arxiv.Result.Author('Tatiana Martinez'), arxiv.Result.Author('Mariana Peñuela Vasquez'), arxiv.Result.Author('Jesus Francisco Vargas Bonilla'), arxiv.Result.Author('Augusto Salazar')]\n",
      "Summary: Microalgae counting is used to measure biomass quantity. Usually, it is\n",
      "performed in a manual way using a Neubauer chamber and expert criterion, with\n",
      "the risk of a high error rate. This paper addresses the methodology for\n",
      "automatic identification of Scenedesmus microalgae (used in the methane\n",
      "production and food industry) and applies it to images captured by a digital\n",
      "microscope. The use of contrast adaptive histogram equalization for\n",
      "pre-processing, and active contours for segmentation are presented. The\n",
      "calculation of statistical features (Histogram of Oriented Gradients, Hu and\n",
      "Zernike moments) with texture features (Haralick and Local Binary Patterns\n",
      "descriptors) are proposed for algae characterization. Scenedesmus algae can\n",
      "build coenobia consisting of 1, 2, 4 and 8 cells. The amount of algae of each\n",
      "coenobium helps to determine the amount of lipids, proteins, and other\n",
      "substances in a given sample of a algae crop. The knowledge of the quantity of\n",
      "those elements improves the quality of bioprocess applications. Classification\n",
      "of coenobia achieves accuracies of 98.63% and 97.32% with Support Vector\n",
      "Machine (SVM) and Artificial Neural Network (ANN), respectively. According to\n",
      "the results it is possible to consider the proposed methodology as an\n",
      "alternative to the traditional technique for algae counting. The database used\n",
      "in this paper is publicly available for download.\n",
      "Link: http://arxiv.org/pdf/1612.07379v2\n",
      "----\n",
      "Title: The feasibility of automated identification of six algae types using neural networks and fluorescence-based spectral-morphological features\n",
      "Authors: [arxiv.Result.Author('Jason L. Deglint'), arxiv.Result.Author('Chao Jin'), arxiv.Result.Author('Angela Chao'), arxiv.Result.Author('Alexander Wong')]\n",
      "Summary: Harmful algae blooms (HABs), which produce lethal toxins, are a growing\n",
      "global concern since they negatively affect the quality of drinking water and\n",
      "have major negative impact on wildlife, the fishing industry, as well as\n",
      "tourism and recreational water use. In this study, we investigate the\n",
      "feasibility of leveraging machine learning and fluorescence-based\n",
      "spectral-morphological features to enable the identification of six different\n",
      "algae types in an automated fashion. More specifically, a custom multi-band\n",
      "fluorescence imaging microscope is used to capture fluorescence imaging data of\n",
      "a water sample at six different excitation wavelengths ranging from 405 nm -\n",
      "530 nm. A number of morphological and spectral fluorescence features are then\n",
      "extracted from the isolated micro-organism imaging data, and used to train\n",
      "neural network classification models designed for the purpose of identification\n",
      "of the six algae types given an isolated micro-organism. Experimental results\n",
      "using three different neural network classification models showed that the use\n",
      "of either fluorescence-based spectral features or fluorescence-based\n",
      "spectral-morphological features to train neural network classification models\n",
      "led to statistically significant improvements in identification accuracy when\n",
      "compared to the use of morphological features (with average identification\n",
      "accuracies of 95.7%+/-3.5% and 96.1%+/-1.5%, respectively). These preliminary\n",
      "results are quite promising, given that the identification accuracy of human\n",
      "taxonomists are typically between the range of 67% and 83%, and thus\n",
      "illustrates the feasibility of leveraging machine learning and\n",
      "fluorescence-based spectral-morphological features as a viable method for\n",
      "automated identification of different algae types.\n",
      "Link: http://arxiv.org/pdf/1805.01093v1\n",
      "----\n",
      "Title: The Influence of Photosynthesis on the Number of Metamers per Growth Unit in GreenLab Model\n",
      "Authors: [arxiv.Result.Author('Amelie Mathieu'), arxiv.Result.Author('Paul-Henry Cournède'), arxiv.Result.Author('Philippe De Reffye')]\n",
      "Summary: GreenLab Model is a functional-structural plant growth model that combines\n",
      "both organogenesis (at each cycle, new organs are created with respect to\n",
      "genetic rules) and photosynthesis (organs are filled with the biomass produced\n",
      "by the leaves photosynthesis). Our new developments of the model concern the\n",
      "retroaction of photosynthesis on organogenesis. We present here the first step\n",
      "towards the total representation of this retroaction, where the influence of\n",
      "available biomass on the number of metamers in new growth units us modelled.\n",
      "The theory is introduced and applied to a Corner model tree. Different\n",
      "interesting behaviours are pointed out.\n",
      "Link: http://arxiv.org/pdf/q-bio/0701026v1\n",
      "----\n",
      "Title: Observation of Coherence in the Photosystem II Reaction Center\n",
      "Authors: [arxiv.Result.Author('Franklin D. Fuller'), arxiv.Result.Author('Jie Pan'), arxiv.Result.Author('S. Seckin Senlik'), arxiv.Result.Author('Daniel E. Wilcox'), arxiv.Result.Author('Jennifer P. Ogilvie')]\n",
      "Summary: Photosynthesis powers life on our planet. The basic photosynthetic\n",
      "architecture comprises antenna complexes to harvest solar energy and reaction\n",
      "centers to convert the energy into a stable charge separated state. In oxygenic\n",
      "photosynthesis, the initial charge separation event occurs in the photosystem\n",
      "II reaction center; the only known natural enzyme that uses solar energy to\n",
      "split water. Energy transfer and charge separation in photosynthesis are rapid\n",
      "and have high quantum efficiencies. Recently, nonlinear spectroscopic\n",
      "experiments have suggested that electronic coherence may play a role in energy\n",
      "transfer efficiency in antenna complexes. Here we report the observation of\n",
      "coherence in the photosystem II reaction center by two dimensional electronic\n",
      "spectroscopy. The frequencies of the observed coherences match exciton\n",
      "difference frequencies and/or known vibrational modes of the photosystem II\n",
      "reaction center. These observations raise questions about the possible role of\n",
      "electronic and/or vibrational coherence in the fundamental charge separation\n",
      "process in oxygenic photosynthesis.\n",
      "Link: http://arxiv.org/pdf/1310.1111v1\n",
      "----\n",
      "Title: Compact Representation of Photosynthesis Dynamics by Rule-based Models (Full Version)\n",
      "Authors: [arxiv.Result.Author('L. Brim'), arxiv.Result.Author('J. Niznan'), arxiv.Result.Author('D. Safranek')]\n",
      "Summary: Traditional mathematical models of photosynthesis are based on mass action\n",
      "kinetics of light reactions. This approach requires the modeller to enumerate\n",
      "all the possible state combinations of the modelled chemical species. This\n",
      "leads to combinatorial explosion in the number of reactions although the\n",
      "structure of the model could be expressed more compactly. We explore the use of\n",
      "rule-based modelling, in particular, a simplified variant of Kappa, to\n",
      "compactly capture and automatically reduce existing mathematical models of\n",
      "photosynthesis. Finally, the reduction procedure is implemented in BioNetGen\n",
      "language and demonstrated on several ODE models of photosynthesis processes.\n",
      "This is an extended version of the paper published in proceedings of 5th\n",
      "International Workshop on Static Analysis and Systems Biology (SASB) 2014.\n",
      "Link: http://arxiv.org/pdf/1410.3632v1\n",
      "----\n",
      "Title: Modelling the Role of Inter-cellular Communication in Modulating Photosynthesis in Plants\n",
      "Authors: [arxiv.Result.Author('Hamdan Awan'), arxiv.Result.Author('Raviraj S. Adve'), arxiv.Result.Author('Nigel Wallbridge'), arxiv.Result.Author('Carrol Plummer'), arxiv.Result.Author('Andrew W. Eckford')]\n",
      "Summary: In this paper we show how inter-cellular molecular communication may change\n",
      "the overall levels of photosynthesis in plants. Individual plant cells respond\n",
      "to external stimuli, such as illumination levels, to regulate their\n",
      "photosynthetic output. Here, we present a mathematical model which shows that\n",
      "by sharing information internally using molecular communication, plants may\n",
      "increase overall photosynthate production. Numerical results show that higher\n",
      "mutual information between cells corresponds to an increase in overall\n",
      "photosynthesis by as much as 25 per cent. This suggests that molecular\n",
      "communication plays a vital role in maximising the photosynthesis in plants and\n",
      "therefore suggests new routes to influence plant development in agriculture and\n",
      "elsewhere.\n",
      "Link: http://arxiv.org/pdf/2103.15773v1\n",
      "----\n",
      "Title: Efficiency of the oxygenic photosynthesis on Earth-like planets in the habitable zone\n",
      "Authors: [arxiv.Result.Author('Giovanni Covone'), arxiv.Result.Author('Riccardo M. Ienco'), arxiv.Result.Author('Luca Cacciapuoti'), arxiv.Result.Author('Laura Inno')]\n",
      "Summary: Oxygenic photosynthesis is the most important biochemical process in Earth\n",
      "biosphere and likely very common on other habitable terrestrial planets, given\n",
      "the general availability of its input chemical ingredients and of light as\n",
      "source of energy. It is therefore important to evaluate the effective\n",
      "possibility of oxygenic photosynthesis on planets around stars as a function of\n",
      "their spectral type and the planet-star separation. We aim at estimating the\n",
      "photon flux, the exergy and the exergetic efficiency of the radiation in the\n",
      "wavelength range useful for the oxygenic photosynthesis as a function of the\n",
      "host star effective temperature and planet-star separation. We compute\n",
      "analytically these quantities and compare our results with the estimates for\n",
      "the small sample of known Earth-like planets. We find that exergy is an\n",
      "increasing function of the star effective temperature, within the range\n",
      "2600-7200 K. It depends both on the star-planet separation and the star\n",
      "effective temperature. Biospheres on exoplanets around cool stars might be\n",
      "generally light-limited. So far, we have not observed terrestrial planets\n",
      "comparable to Earth in terms of useful photon flux, exergy and exergetic\n",
      "efficiency.\n",
      "Link: http://arxiv.org/pdf/2104.01425v1\n",
      "----\n",
      "Title: Measuring Oscillatory Velocity Fields Due to Swimming Algae\n",
      "Authors: [arxiv.Result.Author('Jeffrey S. Guasto'), arxiv.Result.Author('Karl A. Johnson'), arxiv.Result.Author('J. P. Gollub')]\n",
      "Summary: In this fluid dynamics video, we present the first time-resolved measurements\n",
      "of the oscillatory velocity field induced by swimming unicellular\n",
      "microorganisms. Confinement of the green alga C. reinhardtii in stabilized thin\n",
      "liquid films allows simultaneous tracking of cells and tracer particles. The\n",
      "measured velocity field reveals complex time-dependent flow structures, and\n",
      "scales inversely with distance. The instantaneous mechanical power generated by\n",
      "the cells is measured from the velocity fields and peaks at 15 fW. The\n",
      "dissipation per cycle is more than four times what steady swimming would\n",
      "require.\n",
      "Link: http://arxiv.org/pdf/1010.1787v1\n",
      "----\n",
      "Title: Bifurcation Analysis in A Diffusive Mussel-Algae Model with Delay\n",
      "Authors: [arxiv.Result.Author('Zuolin Shen'), arxiv.Result.Author('Junjie Wei')]\n",
      "Summary: In this paper, we consider the dynamics of a delayed reaction-diffusion\n",
      "mussel-algae system subject to Neumann boundary conditions. When the delay is\n",
      "zero, we show the existence of positive solutions and the global stability of\n",
      "the boundary equilibrium. When the delay is not zero, we obtain the stability\n",
      "of the positive constant steady state and the existence of Hopf bifurcation by\n",
      "analyzing the distribution of characteristic values. By using the theory of\n",
      "normal form and center manifold reduction for partial functional differential\n",
      "equations, we derive an algorithm that determines the direction of Hopf\n",
      "bifurcation and the stability of bifurcating periodic solutions. Finally, some\n",
      "numerical simulations are carried out to support our theoretical results.\n",
      "Link: http://arxiv.org/pdf/1807.09525v2\n",
      "----\n",
      "Title: Effect of rotation on anisotropic scattering suspension of phototactic algae\n",
      "Authors: [arxiv.Result.Author('S. K. Rajput')]\n",
      "Summary: In this article, the effect of rotation on the onset of phototactic\n",
      "bioconvection is investigated using linear stability theory for a suspension of\n",
      "forward-scattering phototactic algae in this article. The suspension is\n",
      "uniformly illuminated by collimated flux. The bio-convective instability is\n",
      "characterized by an unstable mode of disturbance that transitions from a\n",
      "stationary (overstable) to an overstable (stationary) state as the Taylor\n",
      "number varies under fixed parameters. It is also observed that the suspension\n",
      "has significant stabilizing effect due to rotation of the system.\n",
      "Link: http://arxiv.org/pdf/2306.15211v1\n",
      "----\n",
      "Title: Multi class intracellular protein targeting predictions in diatoms and other algae with complex plastids: ASAFind 2.0\n",
      "Authors: [arxiv.Result.Author('Ansgar Gruber'), arxiv.Result.Author('Cedar McKay'), arxiv.Result.Author('Miroslav Oborník'), arxiv.Result.Author('Gabrielle Rocap')]\n",
      "Summary: Cells of diatoms and related algae with complex plastids of red algal origin\n",
      "are highly compartmentalized. These plastids are surrounded by four envelope\n",
      "membranes, which also define the periplastidic compartment (PPC), the space\n",
      "between the second and third membranes. The PPC corresponds to the cytosol of\n",
      "the eukaryotic alga that was the ancestor of the complex plastid. Metabolic\n",
      "reactions as well as cell biological processes take place in this compartment;\n",
      "however, its exact function remains elusive. Automated predictions of protein\n",
      "locations proved useful for genome wide explorations of metabolism in the case\n",
      "of plastid proteins, but until now, no automated method for the prediction of\n",
      "PPC proteins was available. Here, we present an updated version of the plastid\n",
      "protein predictor ASAFind, which includes optional prediction of PPC proteins.\n",
      "The new ASAFind version also accepts the output of the most recent versions of\n",
      "SignalP (5.0) and TargetP (2.0) input data. Furthermore, we release a Python\n",
      "script to calculate custom scoring matrices for adjustment of the ASAFind\n",
      "method to other groups of algae, and included the option to run the predictions\n",
      "with custom scoring matrices in a simplified score cut-off mode.\n",
      "Link: http://arxiv.org/pdf/2303.02488v1\n",
      "----\n",
      "Title: Algae-like Artificial Organic Phototactic Micro-swimmers\n",
      "Authors: [arxiv.Result.Author('Somnath Koley'), arxiv.Result.Author('Karuna Kar Nanda')]\n",
      "Summary: Phototaxis is a light driven self-locomotion of mass and a common phenomenon\n",
      "in motile organisms with varieties of motility such as in bacteria, algae, etc.\n",
      "In naturally occurring organisms, mechanical force is generated utilising their\n",
      "metabolic energy to propel and swim in presence of light, performing important\n",
      "bio-chemical reactions. Herein, we report a new class of micro-swimmers that\n",
      "exhibit captivating and complicated micro-swimming mediated colony formation\n",
      "properties resembling green algae. A facile pyrolysis reaction is explored\n",
      "leading to homogeneous organic Nano-structures forming patterned\n",
      "self-assemblies among themselves. A delicate balance of colloid surface forms\n",
      "interesting architectures such as dynamic colonies, thallus like patterning and\n",
      "cilia like micro-arms. In presence of weak light both positive and negative\n",
      "phototaxis are seen moving the micro-swimmers propelling towards and away from\n",
      "the light respectively. During swimming helical motion and electrostatic\n",
      "interactions of colloidal micro-swimmers with neighbouring assemblies are\n",
      "observed. The nature of assembly formation is found to be fractal and can be\n",
      "disintegrated using strong light. Strong exposure stimulates predominately fast\n",
      "negative phototaxis leading to directional propulsion along the light path. All\n",
      "these algae life-like behaviour of the colloidal carbonaceous lyophilic\n",
      "colloids are stable in alcohol and can be reversibly discontinued with water\n",
      "due to super-hydrophilicity. We therefore introduce a class of life-like\n",
      "colloidal chemical architecture. Our discovery may entice studies for creation\n",
      "of a diverse programmable micro-swimmers for microscopic understanding and\n",
      "manipulating collective effect of the assemblies for bio-mimetic and catalytic\n",
      "applications.\n",
      "Link: http://arxiv.org/pdf/2308.05592v1\n",
      "----\n",
      "Title: Green Algae as Model Organisms for Biological Fluid Dynamics\n",
      "Authors: [arxiv.Result.Author('Raymond E. Goldstein')]\n",
      "Summary: In the past decade the volvocine green algae, spanning from the unicellular\n",
      "$Chlamydomonas$ to multicellular $Volvox$, have emerged as model organisms for\n",
      "a number of problems in biological fluid dynamics. These include flagellar\n",
      "propulsion, nutrient uptake by swimming organisms, hydrodynamic interactions\n",
      "mediated by walls, collective dynamics and transport within suspensions of\n",
      "microswimmers, the mechanism of phototaxis, and the stochastic dynamics of\n",
      "flagellar synchronization. Green algae are well suited to the study of such\n",
      "problems because of their range of sizes (from 10 $\\mu$m to several\n",
      "millimetres), their geometric regularity, the ease with which they can be\n",
      "cultured and the availability of many mutants that allow for connections\n",
      "between molecular details and organism-level behavior. This review summarizes\n",
      "these recent developments and highlights promising future directions in the\n",
      "study of biological fluid dynamics, especially in the context of evolutionary\n",
      "biology, that can take advantage of these remarkable organisms.\n",
      "Link: http://arxiv.org/pdf/1409.2338v1\n",
      "----\n",
      "Title: Extreme congestion of microswimmers at a bottleneck constriction\n",
      "Authors: [arxiv.Result.Author('Marvin Brun-Cosme-Bruny'), arxiv.Result.Author('Vincent Borne'), arxiv.Result.Author('Sylvain Faure'), arxiv.Result.Author('Bertrand Maury'), arxiv.Result.Author('Philippe Peyla'), arxiv.Result.Author('Salima Rafai')]\n",
      "Summary: When attracted by a stimulus (e. g. light), microswimmers can build up very\n",
      "densely at a constriction and thus cause clogging. The micro-alga\n",
      "\\textit{Chlamydomonas Reinhardtii} is used here as a model system to study this\n",
      "phenomenon. Its negative phototaxis makes the algae swim away from a light\n",
      "source and go through a microfabricated bottleneck-shaped constriction.\n",
      "Successive clogging events interspersed with bursts of algae are observed. A\n",
      "power law decrease is found to describe well the distribution of time lapses of\n",
      "blockages. Moreover, the evacuation time is found to increase when increasing\n",
      "the swimming velocity. These results might be related to the phenomenology of\n",
      "crowd dynamics and in particular what has been called the Faster is Slower\n",
      "effect in the dedicated literature. It also raises the question of the presence\n",
      "of tangential solid friction between motile cells densely packed that may\n",
      "accompany arches formation. Using the framework of crowd dynamics we analyze\n",
      "the microswimmers behavior and in particular question the role of\n",
      "hydrodynamics.\n",
      "Link: http://arxiv.org/pdf/1911.10681v2\n",
      "----\n",
      "Title: Spatiotemporal patterns near the Turing-Hopf bifurcation in a delay-diffusion mussel-algae model\n",
      "Authors: [arxiv.Result.Author('Zuolin Shen'), arxiv.Result.Author('Junjie Wei')]\n",
      "Summary: The spatiotemporal patterns of a reaction diffusion mussel-algae system with\n",
      "a delay subject to Neumann boundary conditions is considered. The paper is a\n",
      "continuation of our previous studies on delay-diffusion mussel-algae model. The\n",
      "global existence and positivity of solutions are obtained. The stability of the\n",
      "positive constant steady state and existence of Hopf bifurcation and Turing\n",
      "bifurcation are discussed by analyzing the distribution of eigenvalues.\n",
      "Furthermore, the dynamic classifications near the Turing-Hopf bifurcation point\n",
      "are obtained in the dimensionless parameter space by calculating the normal\n",
      "form on the center manifold, and the spatiotemporal patterns consisting of\n",
      "spatially homogeneous periodic solutions, spatially inhomogeneous steady\n",
      "states, and spatially inhomogeneous periodic solutions are identified in this\n",
      "parameter space through some numerical simulations. Both theoretical and\n",
      "numerical results reveal that the Turing-Hopf bifurcation can enrich the\n",
      "diversity of spatial distribution of populations.\n",
      "Link: http://arxiv.org/pdf/1807.09522v1\n",
      "----\n",
      "Title: \\b{eta}-phase (AlxGa1-x)2O3 thin film with Al composition more than 70%\n",
      "Authors: [arxiv.Result.Author('Che-Hao Liao'), arxiv.Result.Author('Kuang-Hui Li'), arxiv.Result.Author('C. G. Torres. Castanedo'), arxiv.Result.Author('Guozheng Zhang'), arxiv.Result.Author('Xiaohang Li')]\n",
      "Summary: In this work, we have demonstrated wide-composition-range\n",
      "\\b{eta}-(AlxGa1-x)2O3 thin films with record-high Al compositions up to 77% for\n",
      "\\b{eta}-(AlxGa1-x)2O3 covering bandgaps from 4.9 to 6.4 eV. With optimized\n",
      "thermal annealing conditions, the \\b{eta}-Ga2O3 binary thin films on sapphire\n",
      "substrates transformed to the \\b{eta}-(AlGa)2O3 ternary thin films with\n",
      "different compositions. The binary to ternary transformation resulted from the\n",
      "Al atom diffusion from sapphire into the oxide layers; meanwhile, the Ga atoms\n",
      "diffused into sapphire leading to thicker thin films than the original\n",
      "thicknesses. The interdiffusion processes were confirmed by transmission\n",
      "electron microscopy, which enhanced in proportion to the annealing temperature.\n",
      "The strain states of the \\b{eta}-(AlGa)2O3 films have been analyzed showing\n",
      "reduced in-plane compressive strain with higher annealing temperature; and the\n",
      "film eventually became strain-free when the temperature was 1400 oC\n",
      "corresponding to the Al composition of 77%. The proposed method is promising\n",
      "for the preparation of the \\b{eta}-(AlGa)2O3 thin films without employing\n",
      "sophisticated direct-growth techniques for alloys.\n",
      "Link: http://arxiv.org/pdf/2005.05799v2\n",
      "----\n",
      "Title: Quantitative elemental imaging in eukaryotic algae\n",
      "Authors: [arxiv.Result.Author('Stefan Schmollinger'), arxiv.Result.Author('Si Chen'), arxiv.Result.Author('Sabeeha S. Merchant')]\n",
      "Summary: All organisms, fundamentally, are made from the same raw material, namely the\n",
      "elements of the periodic table. Biochemical diversity is achieved with how\n",
      "these elements are utilized, for what purpose and in which physical location.\n",
      "Determining elemental distributions, especially those of trace elements that\n",
      "facilitate metabolism as cofactors in the active centers of essential enzymes,\n",
      "can determine the state of metabolism, the nutritional status or the\n",
      "developmental stage of an organism. Photosynthetic eukaryotes, especially\n",
      "algae, are excellent subjects for quantitative analysis of elemental\n",
      "distribution. These microbes utilize unique metabolic pathways that require\n",
      "various trace nutrients at their core to enable its operation. Photosynthetic\n",
      "microbes also have important environmental roles as primary producers in\n",
      "habitats with limited nutrient supply or toxin contaminations. Accordingly,\n",
      "photosynthetic eukaryotes are of great interest for biotechnological\n",
      "exploitation, carbon sequestration and bioremediation, with many of the\n",
      "applications involving various trace elements and consequently affecting their\n",
      "quota and intracellular distribution. A number of diverse applications were\n",
      "developed for elemental imaging allowing subcellular resolution, with X-ray\n",
      "fluorescence microscopy (XFM) being at the forefront, enabling quantitative\n",
      "descriptions of intact cells in a non-destructive method. This Tutorial Review\n",
      "summarizes the workflow of a quantitative, single-cell elemental distribution\n",
      "analysis of a eukaryotic alga using XFM.\n",
      "Link: http://arxiv.org/pdf/2210.14744v1\n",
      "----\n",
      "Title: Charge separation in photosynthesis via a spin exchange coupling mechanism\n",
      "Authors: [arxiv.Result.Author('S. F. Fischer'), arxiv.Result.Author('P. O. J. Scherer')]\n",
      "Summary: A new mechanism for the primary photoinduced charge separation in\n",
      "photosynthesis is proposed. It involves as real intermediate between the\n",
      "excited special pair state P* and the primary charge separated state P+HL- a\n",
      "trip-trip-singlet PTBLT, which consists of a triplet on the dimer P and a\n",
      "further triplet on the monomer BL. Both combine to a singlet. The electron\n",
      "transfer is caused by spin exchange couplings. The transient spectrum of the\n",
      "short lived intermediate, formerly taken as evidence for the charge transfer\n",
      "state P+BL-, is reinterpreted as a transient excitation of this trip-trip\n",
      "singlet.\n",
      "Link: http://arxiv.org/pdf/cond-mat/9708033v1\n",
      "----\n",
      "Title: 'Photosynthetic' Quantum Computers?\n",
      "Authors: [arxiv.Result.Author('Scott M. Hitchcock')]\n",
      "Summary: Do quantum computers already exist in Nature? It is proposed that they do.\n",
      "Photosynthesis is one example in which a 'quantum computer' component may play\n",
      "a role in the 'classical' world of complex biological systems. A 'translation'\n",
      "of the standard metabolic description of the 'front-end' light harvesting\n",
      "complex in photosynthesis into the language of quantum computers is presented.\n",
      "Biological systems represent an untapped resource for thinking about the design\n",
      "and operation of hybrid quantum-classical computers and expanding our current\n",
      "conceptions of what defines a 'quantum computer' in Nature.\n",
      "Link: http://arxiv.org/pdf/quant-ph/0108087v1\n",
      "----\n",
      "Title: Prey-predator modeling of CO2 atmospheric concentration\n",
      "Authors: [arxiv.Result.Author('Luis Augusto Trevisan'), arxiv.Result.Author('Fabiano Meira de Moura Luz')]\n",
      "Summary: In this work we propose a mathematical model, based in a modified version of\n",
      "the Lotka-Volterra prey-predator equations, to predict the increasing in CO2\n",
      "atmospheric concentration. We consider how the photosynthesis rate has changed\n",
      "with the increase of CO2 and how this affects plant reproduction and CO2\n",
      "absorptions rates. Total CO2 emissions (natural and manmade) and biomass\n",
      "numerical parameter changes are considered. It is shown that the atmospheric\n",
      "system can be in equilibrium under some specific conditions, and also some\n",
      "comparisons with historical are done.\n",
      "Link: http://arxiv.org/pdf/0805.0819v1\n",
      "----\n",
      "Title: Overload breakdown in models for photosynthesis\n",
      "Authors: [arxiv.Result.Author('Dorothea Möhring'), arxiv.Result.Author('Alan D. Rendall')]\n",
      "Summary: In many models of the Calvin cycle of photosynthesis it is observed that\n",
      "there are solutions where concentrations of key substances belonging to the\n",
      "cycle tend to zero at late times, a phenomenon known as overload breakdown. In\n",
      "this paper we prove theorems about the existence and non-existence of solutions\n",
      "of this type and obtain information on which concentrations tend to zero when\n",
      "overload breakdown occurs. As a starting point we take a model of Pettersson\n",
      "and Ryde-Pettersson which seems to be prone to overload breakdown and a\n",
      "modification of it due to Poolman which was intended to avoid this effect.\n",
      "Link: http://arxiv.org/pdf/1509.01697v1\n",
      "----\n",
      "Title: Flows in nonequilibrium quantum systems and quantum photosynthesis\n",
      "Authors: [arxiv.Result.Author('S. V. Kozyrev'), arxiv.Result.Author('A. A. Mironov'), arxiv.Result.Author('A. E. Teretenkov'), arxiv.Result.Author('I. V. Volovich')]\n",
      "Summary: A three level quantum system interacting with nonequilibrium environment is\n",
      "investigated. The stationary state of the system is found (both for\n",
      "non-coherent and coherent environment) and relaxation and decoherence to the\n",
      "stationary state is described. The stationary state of the system will be\n",
      "non-equilibrium and will generate flows. We describe the dependence of the\n",
      "flows on the state of the environment.\n",
      "  We also discuss application of this model to the problem of quantum\n",
      "photosynthesis, in particular, to description of flows of excitons and\n",
      "generation of excitonic coherences.\n",
      "Link: http://arxiv.org/pdf/1612.00213v1\n",
      "----\n",
      "Title: Resonant Tunneling in Natural Photosynthetic Systems\n",
      "Authors: [arxiv.Result.Author('Kit M. Gerodias'), arxiv.Result.Author('M. Victoria Carpio-Bernido'), arxiv.Result.Author('Christopher C. Bernido')]\n",
      "Summary: The high internal quantum efficiency observed in higher plants remains an\n",
      "outstanding problem in understanding photosynthesis. Several approaches such as\n",
      "quantum entanglement and quantum coherence have been explored. However, none\n",
      "has yet drawn an analogy between superlattices and the geometrical structure of\n",
      "granal thylakoids in leaves. In this paper, we calculate the transmission\n",
      "coefficients and perform numerical simulations using the parameters relevant to\n",
      "a stack of thylakoid discs. We then show that quantum resonant tunneling can\n",
      "occur at low effective mass of particles for 680 nm and 700 nm incident\n",
      "wavelengths corresponding to energies at which photosynthesis occurs.\n",
      "Link: http://arxiv.org/pdf/2103.07457v1\n",
      "----\n",
      "Title: Temporal correlations of sunlight may assist photoprotection in bacterial Photosynthesis\n",
      "Authors: [arxiv.Result.Author('Adriana M. De Mendoza'), arxiv.Result.Author('Felipe Caycedo-Soler'), arxiv.Result.Author('Susana F. Huelga'), arxiv.Result.Author('Martin B. Plenio')]\n",
      "Summary: Photosynthetic systems utilize adaptability to respond efficiently to\n",
      "fluctuations in their light environment. As a result, large photosynthetic\n",
      "yields can be achieved in conditions of low light intensity, while\n",
      "photoprotection mechanisms are activated in conditions of elevated light\n",
      "intensity. In sharp contrast with these observations, current theoretical\n",
      "models predict bacterial cell death for physiologically high light intensities.\n",
      "To resolve this discrepancy, we consider a unified framework to describe three\n",
      "stages of photosynthesis in natural conditions, namely light absorption,\n",
      "exciton transfer and charge separation dynamics, to investigate the\n",
      "relationship between the statistical features of thermal light and the Quinol\n",
      "production in bacterial photosynthesis. This approach allows us to identify a\n",
      "mechanism of photoprotection that relies on charge recombination facilitated by\n",
      "the photon bunching statistics characteristic of thermal sunlight. Our results\n",
      "suggest that the flexible design underpinning natural photosynthesis may\n",
      "therefore rely on exploiting the temporal correlations of thermal light,\n",
      "manifested in photo-bunching patterns, which are preserved for excitations\n",
      "reaching the reaction center.\n",
      "Link: http://arxiv.org/pdf/1809.06670v2\n",
      "----\n",
      "Title: Effects of primitive photosynthesis on Earth's early climate system\n",
      "Authors: [arxiv.Result.Author('Kazumi Ozaki'), arxiv.Result.Author('Eiichi Tajika'), arxiv.Result.Author('Peng K. Hong'), arxiv.Result.Author('Yusuke Nakagawa'), arxiv.Result.Author('Christopher T. Reinhard')]\n",
      "Summary: The evolution of different forms of photosynthetic life has profoundly\n",
      "altered the activity level of the biosphere, radically reshaping the\n",
      "composition of Earth's oceans and atmosphere over time. However, the\n",
      "mechanistic impacts of a primitive photosynthetic biosphere on Earth's early\n",
      "atmospheric chemistry and climate are poorly understood. Here, we use a global\n",
      "redox balance model to explore the biogeochemical and climatological effects of\n",
      "different forms of primitive photosynthesis. We find that a hybrid ecosystem of\n",
      "H2-based and Fe-based anoxygenic photoautotrophs - organisms that perform\n",
      "photosynthesis without producing oxygen - gives rise to a strong nonlinear\n",
      "amplification of Earth's methane (CH4) cycle, and would thus have represented a\n",
      "critical component of Earth's early climate system before the advent of\n",
      "oxygenic photosynthesis. Using a Monte Carlo approach, we find that a hybrid\n",
      "photosynthetic biosphere widens the range of geochemical conditions that allow\n",
      "for warm climate states well beyond either of these metabolic processes acting\n",
      "in isolation. Our results imply that Earth's early climate was governed by a\n",
      "novel and poorly explored set of regulatory feedbacks linking the anoxic\n",
      "biosphere and the coupled H, C and Fe cycles. We suggest that similar processes\n",
      "should be considered when assessing the potential for sustained habitability on\n",
      "Earth-like planets with reducing atmospheres.\n",
      "Link: http://arxiv.org/pdf/1907.12995v1\n",
      "----\n",
      "Title: Ni-O-Ag catalyst enables 103-m$^2$ artificial photosynthesis with >16% solar-to-chemical energy conversion efficiency\n",
      "Authors: [arxiv.Result.Author('Yaguang Li'), arxiv.Result.Author('Fanqi Meng'), arxiv.Result.Author('Qixuan Wu'), arxiv.Result.Author('Dachao Yuan'), arxiv.Result.Author('Haixiao Wang'), arxiv.Result.Author('Bang Liu'), arxiv.Result.Author('Junwei Wang'), arxiv.Result.Author('Xingyuan San'), arxiv.Result.Author('Lin Gu'), arxiv.Result.Author('Shufang Wang'), arxiv.Result.Author('Qingbo Meng')]\n",
      "Summary: Herein, NiO nanosheets supported with Ag single atoms are synthesized for\n",
      "photothermal CO2 hydrogenation to achieve 1065 mmol g$^{-1}$ h$^{-1}$ of CO\n",
      "production rate under 1 sun irradiation, revealing the unparalleled weak\n",
      "sunlight driven reverse water-gas shift reaction (RWGS) activity. This\n",
      "performance is attributed to the coupling effect of Ag-O-Ni sites to enhance\n",
      "the hydrogenation of CO$_2$ and weaken the CO adsorption, resulting in 1434\n",
      "mmol g$^{-1}$ h$^{-1}$ of CO yield at 300$^\\circ$ C, surpassing any\n",
      "low-temperature RWGS performances ever reported. Building on this, we\n",
      "integrated the 2D Ni$_1$Ag$_{0.02}$O$_1$ supported photothermal RWGS with\n",
      "commercial photovoltaic electrolytic water splitting, leading to the\n",
      "realization of 103 m$^2$ scale artificial photosynthesis system\n",
      "(CO$_2$+H$_2$$\\to$CO+H$_2$O) with a daily CO yield of 18.70 m$^3$, a\n",
      "photochemical energy conversion efficiency of >16%, over 90% H$_2$ ultilization\n",
      "efficiency, outperforming other types of artificial photosynthesis. The results\n",
      "of this research chart a promising course for designing practical, natural\n",
      "sunlight-driven artificial photosynthesis systems and highly efficient\n",
      "platinum-free CO$_2$ hydrogenation catalysts. This work is a significant step\n",
      "towards harnessing solar energy more efficiently and sustainably, opening\n",
      "exciting possibilities for future research and development in this area.\n",
      "Link: http://arxiv.org/pdf/2307.12783v1\n",
      "----\n",
      "Title: Spectral signatures of photosynthesis I: Review of Earth organisms\n",
      "Authors: [arxiv.Result.Author('Nancy Y. Kiang'), arxiv.Result.Author('Janet Siefert'), arxiv.Result.Author('Govindjee'), arxiv.Result.Author('Robert E. Blankenship')]\n",
      "Summary: Why do plants reflect in the green and have a 'red edge' in the red, and\n",
      "should extrasolar photosynthesis be the same? We provide: 1) a brief review of\n",
      "how photosynthesis works; 2) an overview of the diversity of photosynthetic\n",
      "organisms, their light harvesting systems, and environmental ranges; 3) a\n",
      "synthesis of photosynthetic surface spectral signatures; 4) evolutionary\n",
      "rationales for photosynthetic surface reflectance spectra with regard to\n",
      "utilization of photon energy and the planetary light environment. Given the\n",
      "surface incident photon flux density spectrum and resonance transfer in light\n",
      "harvesting, we propose some rules with regard to where photosynthetic pigments\n",
      "will peak in absorbance: a) the wavelength of peak incident photon flux; b) the\n",
      "longest available wavelength for core antenna or reaction center pigments; and\n",
      "c) the shortest wavelengths within an atmospheric window for accessory\n",
      "pigments. That plants absorb less green light may not be an inefficient legacy\n",
      "of evolutionary history, but may actually satisfy the above criteria.\n",
      "Link: http://arxiv.org/pdf/astro-ph/0701382v1\n",
      "----\n",
      "Title: On the Mechanism of the Primary Charge Separation in Bacterial Photosynthesis\n",
      "Authors: [arxiv.Result.Author('C. H. Mak'), arxiv.Result.Author('Reinhold Egger')]\n",
      "Summary: We present a detailed analysis of the mechanism of the primary charge\n",
      "separation process in bacterial photosynthesis using real-time path integrals.\n",
      "Direct computer simulations as well as an approximate analytical theory have\n",
      "been employed to map out the dynamics of the charge separation process in many\n",
      "regions of the parameter space relevant to bacterial photosynthesis. Two\n",
      "distinct parameter regions, one characteristic of sequential transfer and the\n",
      "other characteristic of superexchange, have been found to yield charge\n",
      "separation dynamics in agreement with experiments. Nonadiabatic theory provides\n",
      "accurate rate estimates for low-lying and very high-lying bacteriochlorophyll\n",
      "state energies, but it breaks down in between these two regimes.\n",
      "Link: http://arxiv.org/pdf/chem-ph/9410001v1\n",
      "----\n",
      "Title: Short-term effects of Gamma Ray Bursts on oceanic photosynthesis\n",
      "Authors: [arxiv.Result.Author('Liuba Penate'), arxiv.Result.Author('Osmel Martin'), arxiv.Result.Author('Rolando Cardenas'), arxiv.Result.Author('Susana Agusti')]\n",
      "Summary: We continue our previous work on the potential short-term influence of a\n",
      "gamma ray bursts on Earth's biosphere, focusing on the only important\n",
      "short-term effect on life: the ultraviolet flash which occurs as a result of\n",
      "the retransmission of the {\\gamma} radiation through the atmosphere. Thus, in\n",
      "this work we calculate the ultraviolet irradiances penetrating the first\n",
      "hundred meters of the water column, for Jerlov's ocean water types I, II and\n",
      "III. Then we estimate the UV flash potential for photosynthesis inhibition,\n",
      "showing that it can be important in a considerable part of the water column\n",
      "with light enough for photosynthesis to be done, the so called photic zone.\n",
      "Link: http://arxiv.org/pdf/1007.2879v1\n",
      "----\n",
      "Title: Energy conversion in Purple Bacteria Photosynthesis\n",
      "Authors: [arxiv.Result.Author('Felipe Caycedo-Soler'), arxiv.Result.Author('Ferney J. Rodriguez'), arxiv.Result.Author('Luis Quiroga'), arxiv.Result.Author('Guannan Zhao'), arxiv.Result.Author('Neil F. Johnson')]\n",
      "Summary: The study of how photosynthetic organisms convert light offers insight not\n",
      "only into nature's evolutionary process, but may also give clues as to how best\n",
      "to design and manipulate artificial photosynthetic systems -- and also how far\n",
      "we can drive natural photosynthetic systems beyond normal operating conditions,\n",
      "so that they can harvest energy for us under otherwise extreme conditions. In\n",
      "addition to its interest from a basic scientific perspective, therefore, the\n",
      "goal to develop a deep quantitative understanding of photosynthesis offers the\n",
      "potential payoff of enhancing our current arsenal of alternative energy sources\n",
      "for the future.\n",
      "  In the following Chapter, we consider the trade-off between dynamics,\n",
      "structure and function of light harvesting membranes in Rps. Photometricum\n",
      "purple bacteria, as a model to highlight the priorities that arise when\n",
      "photosynthetic organisms adapt to deal with the ever-changing natural\n",
      "environment conditions.\n",
      "Link: http://arxiv.org/pdf/1107.0191v1\n",
      "----\n",
      "Title: Efficient Direct Solar-to-Hydrogen Conversion by In Situ Interface Transformation of a Tandem Structure\n",
      "Authors: [arxiv.Result.Author('Matthias M. May'), arxiv.Result.Author('Hans-Joachim Lewerenz'), arxiv.Result.Author('David Lackner'), arxiv.Result.Author('Frank Dimroth'), arxiv.Result.Author('Thomas Hannappel')]\n",
      "Summary: Photosynthesis is nature's route to convert intermittent solar irradiation\n",
      "into storable energy, while its use for an industrial energy supply is impaired\n",
      "by low efficiency. Artificial photosynthesis provides a promising alternative\n",
      "for efficient robust carbon-neutral renewable energy generation. The approach\n",
      "of direct hydrogen generation by photoelectrochemical water splitting utilises\n",
      "customised tandem absorber structures to mimic the Z-scheme of natural\n",
      "photosynthesis. Here, a combined chemical surface transformation of a tandem\n",
      "structure and catalyst deposition at ambient temperature yields photocurrents\n",
      "approaching the theoretical limit of the absorber and results in a\n",
      "solar-to-hydrogen efficiency of 14%. The potentiostatically assisted\n",
      "photoelectrode efficiency is 17%. Present benchmarks for integrated systems are\n",
      "clearly exceeded. Details of the in situ interface transformation, the\n",
      "electronic improvement and chemical passivation are presented. The surface\n",
      "functionalisation procedure is widely applicable and can be precisely\n",
      "controlled, allowing further developments of high-efficiency robust hydrogen\n",
      "generators.\n",
      "Link: http://arxiv.org/pdf/1508.01666v1\n",
      "----\n",
      "Title: A quantum protective mechanism in photosynthesis\n",
      "Authors: [arxiv.Result.Author('Adriana Marais'), arxiv.Result.Author('Ilya Sinayskiy'), arxiv.Result.Author('Francesco Petruccione'), arxiv.Result.Author('Rienk van Grondelle')]\n",
      "Summary: Since the emergence of oxygenic photosynthesis, living systems have developed\n",
      "protective mechanisms against reactive oxygen species. During charge separation\n",
      "in photosynthetic reaction centres, triplet states can react with molecular\n",
      "oxygen generating destructive singlet oxygen. The triplet product yield in\n",
      "bacteria is observed to be reduced by weak magnetic fields. Reaction centres\n",
      "from plants' photosystem II share many features with bacterial reaction\n",
      "centres, including a high-spin iron whose function has remained obscure. To\n",
      "explain observations that the magnetic field effect is reduced by the iron, we\n",
      "propose that its fast-relaxing spin plays a protective role in photosynthesis\n",
      "by generating an effective magnetic field. We consider a simple model of the\n",
      "system, derive an analytical expression for the effective magnetic field and\n",
      "analyse the resulting triplet yield reduction. The protective mechanism is\n",
      "robust for realistic parameter ranges, constituting a clear example of a\n",
      "quantum effect playing a macroscopic role vital for life.\n",
      "Link: http://arxiv.org/pdf/1602.01689v1\n",
      "----\n",
      "Title: The potential for photosynthesis in hydrothermal vents: a new avenue for life in the Universe?\n",
      "Authors: [arxiv.Result.Author('Noel Perez'), arxiv.Result.Author('Rolando Cardenas'), arxiv.Result.Author('Osmel Martin'), arxiv.Result.Author('Michel Leiva-Mora')]\n",
      "Summary: We perform a quantitative assessment for the potential for photosynthesis in\n",
      "hydrothermal vents in the deep ocean. The photosynthetically active radiation\n",
      "in this case is from geothermal origin: the infrared thermal radiation emitted\n",
      "by hot water, at temperatures ranging from 473 up to 673 K. We find that at\n",
      "these temperatures the photosynthetic potential is rather low in these\n",
      "ecosystems for most known species. However, species which a very high\n",
      "efficiency in the use of light and which could use infrared photons till\n",
      "1300nm, could achieve good rates of photosynthesis in hydrothermal vents. These\n",
      "organisms might also thrive in deep hydrothermal vents in other planetary\n",
      "bodies, such as one of the more astrobiologically promising Jupiter satellites:\n",
      "Europa.\n",
      "Link: http://arxiv.org/pdf/1304.6127v1\n",
      "----\n",
      "Title: From leaf to tree: upscaling of artificial photosynthesis\n",
      "Authors: [arxiv.Result.Author('Bugra Turan'), arxiv.Result.Author('Jan-Philipp Becker'), arxiv.Result.Author('Felix Urbain'), arxiv.Result.Author('Friedhelm Finger'), arxiv.Result.Author('Uwe Rau'), arxiv.Result.Author('Stefan Haas')]\n",
      "Summary: Energy storage becomes crucial for energy systems with an increasing share of\n",
      "renewable energy sources. Artificial photosynthesis, in particular photovoltaic\n",
      "water splitting, provides both sustainable energy generation and energy storage\n",
      "in the form of hydrogen. However, only a few concepts for scalable devices were\n",
      "reported in the literature. Here, we introduce a new concept which, by design,\n",
      "is scalable and compatible with every thin-film photovoltaic technology. The\n",
      "concept allows for independent geometrical optimization of the photovoltaic and\n",
      "the electrochemical part. The scalability is achieved by continuous mirroring\n",
      "of a base unit. We demonstrate a fully integrated, wireless device with a\n",
      "stable and bias-free operation for 40 hours. The concept was scaled to an area\n",
      "of 64 cm2 comprising 13 base units and exhibited a solar-to-hydrogen efficiency\n",
      "of 3.9%. The concept and its successful realization is an important\n",
      "contribution towards the large scale application of artificial photosynthesis.\n",
      "Link: http://arxiv.org/pdf/1604.03074v1\n",
      "----\n",
      "Title: Model of vibrones in quantum photosynthesis as an analog of model of laser\n",
      "Authors: [arxiv.Result.Author('S. V. Kozyrev')]\n",
      "Summary: Mechanism of vibronic amplification of transport of excitons was discussed in\n",
      "relation to quantum photosynthesis. Vibrones (some modes of vibrations of\n",
      "molecules) are observed experimentally in photosynthetic systems. In the\n",
      "present paper we discuss a model of vibronic amplification of quantum transfer\n",
      "where generation of vibrones as a coherent vibrational mode is described by an\n",
      "analog of semiclassical theory of laser. We consider two models --- a model of\n",
      "nonequilibrium three level system with vibronic mode, and some variant of a\n",
      "model of laser without inversion. We conjecture that dark states discussed in\n",
      "relation to quantum photosynthesis might be related to mechanism of vibronic\n",
      "\"laser\" without inversion which amplifies the transfer of excitons. We prove\n",
      "that in presence of vibronic mode transfer rate of excitons increases and\n",
      "compute dependence of the transfer rate on parameters of the model.\n",
      "Link: http://arxiv.org/pdf/1810.09334v1\n",
      "----\n",
      "Title: Coherent and incoherent theories for photosynthetic energy transfer\n",
      "Authors: [arxiv.Result.Author('Ming-Jie Tao'), arxiv.Result.Author('Na-Na Zhang'), arxiv.Result.Author('Peng-Yu Wen'), arxiv.Result.Author('Fu-Guo Deng'), arxiv.Result.Author('Qing Ai'), arxiv.Result.Author('Gui-Lu Long')]\n",
      "Summary: There is a remarkable characteristic of photosynthesis in nature, that is,\n",
      "the energy transfer efficiency is close to 100%. Recently, due to the rapid\n",
      "progress made in the experimental techniques, quantum coherent effects have\n",
      "been experimentally demonstrated. Traditionally, the incoherent theories are\n",
      "capable of calculating the energy transfer efficiency, e.g., (generalized)\n",
      "F\\\"orster theory and modified Redfield theory. However, in order to describe\n",
      "the quantum coherent effects in photosynthesis, the coherent theories have been\n",
      "developed, such as hierarchical equation of motion, quantum path integral,\n",
      "coherent modified Redfield theory, small-polaron quantum master equation, and\n",
      "general Bloch-Redfield theory in addition to the Redfield theory. Here, we\n",
      "summarize the main points of the above approaches, which might be beneficial to\n",
      "the quantum simulation of quantum dynamics of exciton energy transfer in\n",
      "natural photosynthesis, and shed light on the design of artificial\n",
      "light-harvesting devices.\n",
      "Link: http://arxiv.org/pdf/1907.06528v2\n",
      "----\n",
      "Title: Anoxygenic photosynthesis and the delayed oxygenation of Earth's atmosphere\n",
      "Authors: [arxiv.Result.Author('Kazumi Ozaki'), arxiv.Result.Author('Katharine J. Thompson'), arxiv.Result.Author('Rachel L. Simister'), arxiv.Result.Author('Sean A. Crowe'), arxiv.Result.Author('Christopher T. Reinhard')]\n",
      "Summary: The emergence of oxygenic photosynthesis created a new niche with dramatic\n",
      "potential to transform energy flow through Earth's biosphere. However, more\n",
      "primitive forms of photosynthesis that fix CO2 into biomass using electrons\n",
      "from reduced species like Fe(II) and H2 instead of water would have competed\n",
      "with Earth's early oxygenic biosphere for essential nutrients. Here, we combine\n",
      "experimental microbiology, genomic analyses, and Earth system modeling to\n",
      "demonstrate that competition for light and nutrients in the surface ocean\n",
      "between oxygenic phototrophs and Fe(II)-oxidizing, anoxygenic photosynthesizers\n",
      "(photoferrotrophs) translates into diminished global photosynthetic O2 release\n",
      "when the ocean interior is Fe(II)-rich. These results provide a simple\n",
      "ecophysiological mechanism for inhibiting atmospheric oxygenation during\n",
      "Earth's early history. We also find a novel positive feedback within the\n",
      "coupled C-P-O-Fe cycles that can lead to runaway planetary oxygenation as\n",
      "rising atmospheric pO2 sweeps the deep ocean of the ferrous iron substrate for\n",
      "photoferrotrophy.\n",
      "Link: http://arxiv.org/pdf/1907.13001v1\n",
      "----\n",
      "Title: Quantum feedback control in quantum photosynthesis\n",
      "Authors: [arxiv.Result.Author('S. V. Kozyrev'), arxiv.Result.Author('A. N. Pechen')]\n",
      "Summary: A model of charge separation in quantum photosynthesis as a model of quantum\n",
      "feedback control in a system of interacting excitons and vibrons is introduced.\n",
      "Quantum feedback in this approach describes the Landau--Zener transition with\n",
      "decoherence. The model explains irreversibility in the process of charge\n",
      "separation for quantum photosynthesis -- direct transitions for this quantum\n",
      "control model will have probabilities close to one and reverse transitions will\n",
      "have probabilities close to zero. This can be considered as a model of quantum\n",
      "ratchet. Also this model explains coincidence of energy of the vibron paired to\n",
      "the transition and Bohr frequency of the transition.\n",
      "Link: http://arxiv.org/pdf/2105.12128v3\n",
      "----\n",
      "Title: All-carbon nanotube solar cell devices mimic photosynthesis\n",
      "Authors: [arxiv.Result.Author('Gideon Oyibo'), arxiv.Result.Author('Thomas Barrett'), arxiv.Result.Author('Sharadh Jois'), arxiv.Result.Author('Jeffrey Blackburn'), arxiv.Result.Author('Ji Ung Lee')]\n",
      "Summary: Photovoltaics has two main processes: Optical absorption and power\n",
      "conversion. In photosynthesis, the two equivalent processes are optical\n",
      "absorption and chemical conversion. Whereas in the latter, the two processes\n",
      "are carried out by distinct proteins, in conventional photovoltaic diodes, the\n",
      "two processes are convoluted because the optical and transport paths are the\n",
      "same, leading to inefficiencies. Here, we separate the site and direction of\n",
      "light absorption from those of power generation to show that semiconducting\n",
      "single-walled carbon nanotubes (s-SWCNTs) provide an artificial system that\n",
      "models photosynthesis in a tandem geometry. Using different s-SWCNT\n",
      "chiralities, we implement an energy funnel in dual-gated p-n diodes. This\n",
      "enables the capture of photons from multiple regions of the solar spectrum and\n",
      "the funneling of photogenerated excitons to the smallest bandgap s-SWCNT layer,\n",
      "where they become free carriers. As a result, we demonstrate an increase in the\n",
      "magnitude and spectral response of photocurrent by adding more s-SWCNT layers\n",
      "of different bandgaps without a corresponding deleterious increase in the dark\n",
      "leakage current.\n",
      "Link: http://arxiv.org/pdf/2210.07986v1\n",
      "----\n",
      "Title: Lévy Fluctuations and Tracer Diffusion in Dilute Suspensions of Algae and Bacteria\n",
      "Authors: [arxiv.Result.Author('Irwin M. Zaid'), arxiv.Result.Author('Jörn Dunkel'), arxiv.Result.Author('Julia M. Yeomans')]\n",
      "Summary: Swimming microorganisms rely on effective mixing strategies to achieve\n",
      "efficient nutrient influx. Recent experiments, probing the mixing capability of\n",
      "unicellular biflagellates, revealed that passive tracer particles exhibit\n",
      "anomalous non-Gaussian diffusion when immersed in a dilute suspension of\n",
      "self-motile Chlamydomonas reinhardtii algae. Qualitatively, this observation\n",
      "can be explained by the fact that the algae induce a fluid flow that may\n",
      "occasionally accelerate the colloidal tracers to relatively large velocities. A\n",
      "satisfactory quantitative theory of enhanced mixing in dilute active\n",
      "suspensions, however, is lacking at present. In particular, it is unclear how\n",
      "non-Gaussian signatures in the tracers' position distribution are linked to the\n",
      "self-propulsion mechanism of a microorganism. Here, we develop a systematic\n",
      "theoretical description of anomalous tracer diffusion in active suspensions,\n",
      "based on a simplified tracer-swimmer interaction model that captures the\n",
      "typical distance scaling of a microswimmer's flow field. We show that the\n",
      "experimentally observed non-Gaussian tails are generic and arise due to a\n",
      "combination of truncated L\\'evy statistics for the velocity field and\n",
      "algebraically decaying time correlations in the fluid. Our analytical\n",
      "considerations are illustrated through extensive simulations, implemented on\n",
      "graphics processing units to achieve the large sample sizes required for\n",
      "analyzing the tails of the tracer distributions.\n",
      "Link: http://arxiv.org/pdf/1009.3704v1\n",
      "----\n",
      "Title: Dispersion of swimming algae in laminar and turbulent channel flows: consequences for photobioreactors\n",
      "Authors: [arxiv.Result.Author('O. A. Croze'), arxiv.Result.Author('G. Sardina'), arxiv.Result.Author('M. Ahmed'), arxiv.Result.Author('M. A. Bees'), arxiv.Result.Author('L. Brandt')]\n",
      "Summary: Shear flow significantly affects the transport of swimming algae in\n",
      "suspension. For example, viscous and gravitational torques bias bottom-heavy\n",
      "cells to swim towards regions of downwelling fluid (gyrotaxis). It is necessary\n",
      "to understand how such biases affect algal dispersion in natural and industrial\n",
      "flows, especially in view of growing interest in algal photobioreactors.\n",
      "Motivated by this, we here study the dispersion of gyrotactic algae in laminar\n",
      "and turbulent channel flows using direct numerical simulation (DNS) and the\n",
      "analytical swimming dispersion theory of Bees and Croze (2010). Time-resolved\n",
      "dispersion measures are evaluated as functions of the Peclet and Reynolds\n",
      "numbers in upwelling and downwelling flows. For laminar flows, DNS results are\n",
      "compared with theory using competing descriptions of biased swimming cells in\n",
      "shear flow. Excellent agreement is found for predictions that employ\n",
      "generalized-Taylor-dispersion. The results highlight peculiarities of\n",
      "gyrotactic swimmer dispersion relative to passive tracers. In laminar\n",
      "downwelling flow the cell distribution drifts in excess of the mean flow,\n",
      "increasing in magnitude with Peclet number. The cell effective axial\n",
      "diffusivity increases and decreases with Peclet number (for tracers it merely\n",
      "increases). In turbulent flows, gyrotactic effects are weaker, but discernable\n",
      "and manifested as non-zero drift. These results should significantly impact\n",
      "photobioreactor design.\n",
      "Link: http://arxiv.org/pdf/1205.2840v2\n",
      "----\n",
      "Title: Transcriptomic and metabolomic analysis of copper stress acclimation in Ectocarpus siliculosus highlights signaling and tolerance mechanisms in brown algae\n",
      "Authors: [arxiv.Result.Author('Andrés Ritter'), arxiv.Result.Author('Simon M Dittami'), arxiv.Result.Author('Sophie Goulitquer'), arxiv.Result.Author('Juan A Correa'), arxiv.Result.Author('Catherine Boyen'), arxiv.Result.Author('Philippe Potin'), arxiv.Result.Author('Thierry Tonon')]\n",
      "Summary: Brown algae are sessile macro-organisms of great ecological relevance in\n",
      "coastal ecosystems. They evolved independently from land plants and other\n",
      "multicellular lineages, and therefore hold several original ontogenic and\n",
      "metabolic features. Most brown algae grow along the coastal zone where they\n",
      "face frequent environmental changes, including exposure to toxic levels of\n",
      "heavy metals such as copper (Cu). We carried out large-scale transcriptomic and\n",
      "metabolomic analyses to decipher the short-term acclimation of the brown algal\n",
      "model E. siliculosus to Cu stress, and compared these data to results known for\n",
      "other abiotic stressors. This comparison demonstrates that Cu induces oxidative\n",
      "stress in E. siliculosus as illustrated by the transcriptomic overlap between\n",
      "Cu and H2O2 treatments. The common response to Cu and H2O2 consisted in the\n",
      "activation of the oxylipin and the repression of inositol signaling pathways,\n",
      "together with the regulation of genes coding for several\n",
      "transcription-associated proteins. Concomitantly, Cu stress specifically\n",
      "activated a set of genes coding for orthologs of ABC transporters, a P1B-type\n",
      "ATPase, ROS detoxification systems such as a vanadium-dependent\n",
      "bromoperoxidase, and induced an increase of free fatty acid contents. Finally\n",
      "we observed, as a common abiotic stress mechanism, the activation of autophagic\n",
      "processes on one hand and the repression of genes involved in nitrogen\n",
      "assimilation on the other hand. Comparisons with data from green plants\n",
      "indicate that some processes involved in Cu and oxidative stress response are\n",
      "conserved across these two distant lineages. At the same time the high number\n",
      "of yet uncharacterized brown alga-specific genes induced in response to copper\n",
      "stress underlines the potential to discover new components and molecular\n",
      "interactions unique to these organisms. Of particular interest for future\n",
      "research is the potential cross-talk between reactive oxygen species (ROS)-,\n",
      "myo-inositol-, and oxylipin signaling.\n",
      "Link: http://arxiv.org/pdf/1502.02001v1\n",
      "----\n",
      "Title: Quantitative predictions from competition theory with incomplete information on model parameters tested against experiments across diverse taxa\n",
      "Authors: [arxiv.Result.Author('Hugo Fort')]\n",
      "Summary: We derive an analytical approximation for making quantitative predictions for\n",
      "ecological communities as a function of the mean intensity of the\n",
      "inter-specific competition and the species richness. This method, with only a\n",
      "fraction of the model parameters (carrying capacities and competition\n",
      "coefficients), is able to predict accurately empirical measurements covering a\n",
      "wide variety of taxa (algae, plants, protozoa).\n",
      "Link: http://arxiv.org/pdf/1708.03593v1\n",
      "----\n",
      "Title: Modeling Coral Reef Bleaching Recovery Through KCC-Theory\n",
      "Authors: [arxiv.Result.Author('Rafael Cavalcanti'), arxiv.Result.Author('Solange Rutz')]\n",
      "Summary: We use Volterra-Hamilton systems theory and their associated cost functional\n",
      "to study the population dynamics and productive processes of coral reefs in\n",
      "recovery from bleaching and show that the cost of production remains the same\n",
      "after the process. The KCC-theory geometrical invariants are determined for the\n",
      "model proposed to describe the renewed symbiotic interaction between coral and\n",
      "algae.\n",
      "Link: http://arxiv.org/pdf/2103.11035v1\n",
      "----\n",
      "Title: Sea urchin feeding fronts\n",
      "Authors: [arxiv.Result.Author('Edward R Abraham')]\n",
      "Summary: Sea urchin feeding fronts are a striking example of spatial pattern formation\n",
      "in an ecological system. If it is assumed that urchins are asocial, and that\n",
      "they move randomly, then the formation of these dense fronts is an apparent\n",
      "paradox. The key lies in observations that urchins move further in areas where\n",
      "their algal food is less plentiful. This naturally leads to the accumulation of\n",
      "urchins in areas with abundant algae. If urchin movement is represented as a\n",
      "random walk, with a step size that depends on algal concentration, then their\n",
      "movement may be described by a Fokker-Planck diffusion equation. For certain\n",
      "combinations of algal growth and urchin grazing, travelling wave solutions are\n",
      "obtained. Two dimensional simulations of urchin algal dynamics show that an\n",
      "initially uniformly distributed urchin population, grazing on an alga with a\n",
      "smoothly varying density, may form a propagating front separating two sharply\n",
      "delineated regions. On one side of the front algal density is uniformly low,\n",
      "and on the other side of the front algal density is uniformly high. Bounds on\n",
      "when stable fronts will form are obtained in terms of urchin density and\n",
      "grazing, and algal growth.\n",
      "Link: http://arxiv.org/pdf/q-bio/0610004v1\n",
      "----\n",
      "Title: Dancing Volvox: Hydrodynamic Bound States of Swimming Algae\n",
      "Authors: [arxiv.Result.Author('Knut Drescher'), arxiv.Result.Author('Kyriacos C. Leptos'), arxiv.Result.Author('Idan Tuval'), arxiv.Result.Author('Takuji Ishikawa'), arxiv.Result.Author('Timothy J. Pedley'), arxiv.Result.Author('Raymond E. Goldstein')]\n",
      "Summary: The spherical alga Volvox swims by means of flagella on thousands of surface\n",
      "somatic cells. This geometry and its large size make it a model organism for\n",
      "studying the fluid dynamics of multicellularity. Remarkably, when two nearby\n",
      "Volvox swim close to a solid surface, they attract one another and can form\n",
      "stable bound states in which they \"waltz\" or \"minuet\" around each other. A\n",
      "surface-mediated hydrodynamic attraction combined with lubrication forces\n",
      "between spinning, bottom-heavy Volvox explains the formation, stability and\n",
      "dynamics of the bound states. These phenomena are suggested to underlie\n",
      "observed clustering of Volvox at surfaces.\n",
      "Link: http://arxiv.org/pdf/0901.2087v1\n",
      "----\n",
      "Title: The random walk of a low-Reynolds-number swimmer\n",
      "Authors: [arxiv.Result.Author('Michaël Garcia'), arxiv.Result.Author('Stefano Berti'), arxiv.Result.Author('Philippe Peyla'), arxiv.Result.Author('Salima Rafaï')]\n",
      "Summary: Swimming at a micrometer scale demands particular strategies. Indeed when\n",
      "inertia is negligible as compared to viscous forces (i.e. Reynolds number $Re$\n",
      "is lower than unity), hydrodynamics equations are reversible in time. To\n",
      "achieve propulsion at low Reynolds number, swimmers must then deform in a way\n",
      "that is not invariant under time reversal. Here, we investigate dispersal\n",
      "properties of self propelled organisms by means of microscopy and cell\n",
      "tracking. Our system of interest is the micro-alga \\textit{Chlamydomonas\n",
      "Reinhardtii}, a motile single celled green alga about 10 micrometers in\n",
      "diameter that swims with to two front flagella. In the case of dilute\n",
      "suspensions, we show that tracked trajectories are well modeled by a correlated\n",
      "random walk. This process is based on short time correlations in the direction\n",
      "of movement called persistence. At longer times, correlations are lost and a\n",
      "standard random walk characterizes the trajectories. Moreover, high speed\n",
      "imaging enables us to show how the back-and-forth motion of flagella at very\n",
      "short times affects the statistical description of the dynamics. Finally we\n",
      "show how drag forces modify the characteristics of this particular random walk.\n",
      "Link: http://arxiv.org/pdf/1011.2931v2\n",
      "----\n",
      "Title: Daphnias: from the individual based model to the large population equation\n",
      "Authors: [arxiv.Result.Author('J. A. J. Metz'), arxiv.Result.Author('Viet Chi Tran')]\n",
      "Summary: The class of deterministic 'Daphnia' models treated by Diekmann et al. (J\n",
      "Math Biol 61: 277-318, 2010) has a long history going back to Nisbet and Gurney\n",
      "(Theor Pop Biol 23: 114-135, 1983) and Diekmann et al. (Nieuw Archief voor\n",
      "Wiskunde 4: 82-109, 1984). In this note, we formulate the individual based\n",
      "models (IBM) supposedly underlying those deterministic models. The models treat\n",
      "the interaction between a general size-structured consumer population\n",
      "('Daphnia') and an unstructured resource ('algae'). The discrete, size and\n",
      "age-structured Daphnia population changes through births and deaths of its\n",
      "individuals and throught their aging and growth. The birth and death rates\n",
      "depend on the sizes of the individuals and on the concentration of the algae.\n",
      "The latter is supposed to be a continuous variable with a deterministic\n",
      "dynamics that depends on the Daphnia population. In this model setting we prove\n",
      "that when the Daphnia population is large, the stochastic differential equation\n",
      "describing the IBM can be approximated by the delay equation featured in\n",
      "(Diekmann et al., l.c.).\n",
      "Link: http://arxiv.org/pdf/1205.4919v1\n",
      "----\n",
      "Title: Emergent Run-and-Tumble Behavior in a Simple Model of Chlamydomonas with Intrinsic Noise\n",
      "Authors: [arxiv.Result.Author('Rachel R. Bennett'), arxiv.Result.Author('Ramin Golestanian')]\n",
      "Summary: Recent experiments on the green alga Chlamydomonas that swims using\n",
      "synchronized beating of a pair of flagella have revealed that it exhibits a\n",
      "run-and-tumble behavior similar to that of bacteria such as E. Coli. Using a\n",
      "simple purely hydrodynamic model that incorporates a stroke cycle and an\n",
      "intrinsic Gaussian white noise, we show that a stochastic run-and-tumble\n",
      "behavior could emerge, due to the nonlinearity of the combined\n",
      "synchronization-rotation-translation dynamics. This suggests the intriguing\n",
      "possibility that the alga might exploit nonlinear mechanics---as opposed to\n",
      "sophisticated biochemical circuitry as used by bacteria---to control its\n",
      "behavior.\n",
      "Link: http://arxiv.org/pdf/1211.3272v1\n",
      "----\n",
      "Title: Flagellar Kinematics and Swimming of Algal Cells in Viscoelastic Fluids\n",
      "Authors: [arxiv.Result.Author('Boyang Qin'), arxiv.Result.Author('Arvind Gopinath'), arxiv.Result.Author('Jing Yang'), arxiv.Result.Author('Jerry P Gollub'), arxiv.Result.Author('Paulo E Arratia')]\n",
      "Summary: The motility of microorganisms is influenced greatly by their hydrodynamic\n",
      "interactions with the fluidic environment they inhabit. We show by direct\n",
      "experimental observation of the bi-flagellated alga Chlamydomonas reinhardtii\n",
      "that fluid elasticity and viscosity strongly influence the beating pattern -\n",
      "the gait - and thereby control the propulsion speed. The beating frequency and\n",
      "the wave speed characterizing the cyclical bending are both enhanced by fluid\n",
      "elasticity. Despite these enhancements, the net swimming speed of the alga is\n",
      "hindered for fluids that are sufficiently elastic. The origin of this complex\n",
      "response lies in the interplay between the elasticity-induced changes in the\n",
      "spatial and temporal aspects of the flagellar cycle and the buildup and\n",
      "subsequent relaxation of elastic stresses during the power and recovery\n",
      "strokes.\n",
      "Link: http://arxiv.org/pdf/1511.00662v1\n",
      "----\n",
      "Title: Clustering instability of focused swimmers\n",
      "Authors: [arxiv.Result.Author('Eric Lauga'), arxiv.Result.Author('Francois Nadal')]\n",
      "Summary: One of the hallmarks of active matter is its rich nonlinear dynamics and\n",
      "instabilities. Recent numerical simulations of phototactic algae showed that a\n",
      "thin jet of swimmers, obtained from hydrodynamic focusing inside a Poiseuille\n",
      "flow, was unstable to longitudinal perturbations with swimmers dynamically\n",
      "clustering (Jibuti et al., Phys. Rev. E, 90, 2014). As a simple starting point\n",
      "to understand these instabilities, we consider in this paper an initially\n",
      "homogeneous one-dimensional line of aligned swimmers moving along the same\n",
      "direction, and characterise its instability using both a continuum framework\n",
      "and a discrete approach. In both cases, we show that hydrodynamic interactions\n",
      "between the swimmers lead to instabilities in density for which we compute the\n",
      "growth rate analytically. Lines of pusher-type swimmers are predicted to remain\n",
      "stable while lines of pullers (such as flagellated algae) are predicted to\n",
      "always be unstable.\n",
      "Link: http://arxiv.org/pdf/1701.05145v1\n",
      "----\n",
      "Title: An ab initio based approach to optical properties of semiconductor heterostructures\n",
      "Authors: [arxiv.Result.Author('L. C. Bannow'), arxiv.Result.Author('P. Rosenow'), arxiv.Result.Author('P. Springer'), arxiv.Result.Author('E. W. Fischer'), arxiv.Result.Author('J. Hader'), arxiv.Result.Author('J. V. Moloney'), arxiv.Result.Author('R. Tonner'), arxiv.Result.Author('S. W. Koch')]\n",
      "Summary: A procedure is presented that combines density functional theory computations\n",
      "of bulk semiconductor alloys with the semiconductor Bloch equations, in order\n",
      "to achieve an ab initio based prediction of the optical properties of\n",
      "semiconductor alloy heterostructures. The parameters of an eight-band\n",
      "kp-Hamiltonian are fitted to the effective band structure of an appropriate\n",
      "alloy. The envelope function approach is applied to model the quantum well\n",
      "using the kp-wave functions and eigenvalues as starting point for calculating\n",
      "the optical properties of the heterostructure. It is shown that Luttinger\n",
      "parameters derived from band structures computed with the TB09 density\n",
      "functional reproduce extrapolated values. The procedure is illustrated by\n",
      "computing the absorption spectra for a (AlGa)As/Ga(AsP)/(AlGa)As quantum well\n",
      "system with varying phosphide content in the active layer.\n",
      "Link: http://arxiv.org/pdf/1704.00983v1\n",
      "----\n",
      "Title: Microscopic flows of suspensions of the green non-motile Chlorella micro-alga at various volume fractions: applications to intensified photo bio reactors\n",
      "Authors: [arxiv.Result.Author('Soulies Antoine'), arxiv.Result.Author('Jeremy Pruvost'), arxiv.Result.Author('Cathy Castelain'), arxiv.Result.Author('Teodor Burghelea')]\n",
      "Summary: An experimental study of flows of the green non-motile Chlorella micro-alga\n",
      "in a plane microchannel is presented. Depending on the value of the cell volume\n",
      "fraction, three distinct flow regimes are observed. For low values of the cell\n",
      "volume fraction a Newtonian flow regime characterised by a Poiseuille like flow\n",
      "field, absence of wall slip and hydrodynamic reversibility of the flow states\n",
      "is observed. For intermediate values of the cell volume fraction, the flow\n",
      "profiles are consistent with a Poiseuille flow of a shear thinning fluid in the\n",
      "presence of slip at the channel's wall. For even larger cell volume fractions,\n",
      "a yield stress like behaviour manifested through the presence of a central\n",
      "solid plug is observed. Except for the Newtonian flow regime, a strong\n",
      "hydrodynamic irreversibility of the flow and wall slip are found. The\n",
      "calculation of the wall shear rate and wall stress based on the measured flow\n",
      "fields allows one to identify the mechanisms of wall slip observed in the shear\n",
      "thinning and yield stress regimes.\n",
      "Link: http://arxiv.org/pdf/1603.04983v1\n",
      "----\n",
      "Title: Meshfree and efficient modelling of swimming cells\n",
      "Authors: [arxiv.Result.Author('Meurig T. Gallagher'), arxiv.Result.Author('David J. Smith')]\n",
      "Summary: Locomotion in Stokes flow is an intensively-studied problem because it\n",
      "describes important biological phenomena such as the motility of many species'\n",
      "sperm, bacteria, algae and protozoa. Numerical computations can be challenging,\n",
      "particularly in three dimensions, due to the presence of moving boundaries and\n",
      "complex geometries; methods which combine ease-of-implementation and\n",
      "computational efficiency are therefore needed. A recently-proposed method to\n",
      "discretise the regularised Stokeslet boundary integral equation without the\n",
      "need for a connected 'mesh' is applied to the inertialess locomotion problem in\n",
      "Stokes flow. The mathematical formulation and key aspects of the computational\n",
      "implementation in MATLAB/GNU Octave are described, followed by numerical\n",
      "experiments with biflagellate algae and multiple uniflagellate sperm swimming\n",
      "between no-slip surfaces, for which both swimming trajectories and flow fields\n",
      "are calculated. These computational experiments required minutes of time on\n",
      "modest hardware; an extensible implementation is provided in a github\n",
      "repository. The nearest neighbour discretisation dramatically improves\n",
      "convergence and robustness, a key challenge in extending the regularised\n",
      "Stokeslet method to complicated, three dimensional, biological fluid problems.\n",
      "Link: http://arxiv.org/pdf/1801.04142v3\n",
      "----\n",
      "Title: Run stop shock, run shock run: Spontaneous and stimulated gait-switching in a unicellular octoflagellate\n",
      "Authors: [arxiv.Result.Author('Kirsty Y. Wan'), arxiv.Result.Author('Raymond E. Goldstein')]\n",
      "Summary: In unicellular flagellates, growing evidence suggests control over a complex\n",
      "repertoire of swimming gaits is conferred intracellularly by ultrastructural\n",
      "components, resulting in motion that depends on flagella number and\n",
      "configuration. We report the discovery of a novel, tripartite motility in an\n",
      "octoflagellate alga, comprising a forward gait ($run$), a fast knee-jerk\n",
      "response with dramatic reversals in beat waveform ($shock$), and, remarkably,\n",
      "long quiescent periods ($stop$) within which the flagella quiver. In a reaction\n",
      "graph representation, transition probabilities show that gait switching is only\n",
      "weakly reversible. Shocks occur spontaneously but are also triggered by direct\n",
      "mechanical contact. In this primitive alga, the capability for a millisecond\n",
      "stop-start switch from rest to full speed implicates an early evolution of\n",
      "excitable signal transduction to and from peripheral appendages.\n",
      "Link: http://arxiv.org/pdf/1706.07922v1\n",
      "----\n",
      "Title: Unjamming of active rotators\n",
      "Authors: [arxiv.Result.Author('Linda Ravazzano'), arxiv.Result.Author('Maria Chiara Lionetti'), arxiv.Result.Author('Maria Rita Fumagalli'), arxiv.Result.Author('Silvia Bonfanti'), arxiv.Result.Author('Roberto Guerra'), arxiv.Result.Author('Oleksandr Chepizhko'), arxiv.Result.Author('Caterina A. M. La Porta'), arxiv.Result.Author('Stefano Zapperi')]\n",
      "Summary: Active particle assemblies can exhibit a wide range of interesting dynamical\n",
      "phases depending on internal parameters such as density, adhesion strength or\n",
      "self-propulsion. Active self-rotations are rarely studied in this context,\n",
      "although they can be relevant for active matter systems, as we illustrate by\n",
      "analyzing the motion of Chlamydomonas reinhardtii algae under different\n",
      "experimental conditions. Inspired by this example, we simulate the dynamics of\n",
      "a system of interacting active disks endowed with active torques. At low\n",
      "packing fractions, adhesion causes the formation of small rotating clusters,\n",
      "resembling those observed when algae are stressed. At higher densities, the\n",
      "model shows a jamming to unjamming transition promoted by active torques and\n",
      "hindered by adhesion. Our results yield a comprehensive picture of the dynamics\n",
      "of active rotators, providing useful guidance to interpret experimental results\n",
      "in cellular systems where rotations might play a role.\n",
      "Link: http://arxiv.org/pdf/2003.06239v1\n",
      "----\n",
      "Title: HJB and Fokker-Planck equations for river environmental management based on stochastic impulse control with discrete and random observation\n",
      "Authors: [arxiv.Result.Author('H. Yoshioka'), arxiv.Result.Author('M. Tsujimura'), arxiv.Result.Author('K. Hamagami'), arxiv.Result.Author('Y. Yaegashi'), arxiv.Result.Author('Y. Yoshioka')]\n",
      "Summary: We formulate a new two-variable river environmental restoration problem based\n",
      "on jump stochastic differential equations (SDEs) governing the sediment storage\n",
      "and nuisance benthic algae population dynamics in a dam-downstream river.\n",
      "Controlling the dynamics is carried out through impulsive sediment\n",
      "replenishment with discrete and random observation/intervention to avoid\n",
      "sediment depletion and thick algae growth. We consider a cost-efficient\n",
      "management problem of the SDEs to achieve the objectives whose resolution\n",
      "reduces to solving a Hamilton-Jacobi-Bellman (HJB) equation. We also consider a\n",
      "Fokker-Planck (FP) equation governing the probability density function of the\n",
      "controlled dynamics. The HJB equation has a discontinuous solution, while the\n",
      "FP equation has a Dirac's delta along boundaries. We show that the value\n",
      "function, the optimized objective function, is governed by the HJB equation in\n",
      "the simplified case and further that a threshold-type control is optimal. We\n",
      "demonstrate that simple numerical schemes can handle these equations. Finally,\n",
      "we numerically analyze the optimal controls and the resulting probability\n",
      "density functions.\n",
      "Link: http://arxiv.org/pdf/2009.00184v2\n",
      "----\n",
      "Title: Rebound and scattering of motile Chlamydomonas algae in confined chambers\n",
      "Authors: [arxiv.Result.Author('Albane Théry'), arxiv.Result.Author('Yuxuan Wang'), arxiv.Result.Author('Mariia Dvoriashyna'), arxiv.Result.Author('Christophe Eloy'), arxiv.Result.Author('Florence Elias'), arxiv.Result.Author('Eric Lauga')]\n",
      "Summary: Motivated by recent experiments demonstrating that motile algae get trapped\n",
      "in draining foams, we study the trajectories of microorganisms confined in\n",
      "model foam channels (section of a Plateau border). We track single\n",
      "Chlamydomonas reinhardtii cells confined in a thin three-circle microfluidic\n",
      "chamber and show that their spatial distribution exhibits strong corner\n",
      "accumulation. Using empirical scattering laws observed in previous experiments\n",
      "(scattering with a constant scattering angle), we next develop a two-dimension\n",
      "geometrical model and compute the phase space of trapped and periodic\n",
      "trajectories of swimmers inside a three-circles billiard. We find that the\n",
      "majority of cell trajectories end up in a corner, providing a geometrical\n",
      "mechanism for corner accumulation. Incorporating the distribution of scattering\n",
      "angles observed in our experiments and including hydrodynamic interactions\n",
      "between the cells and the surfaces into the geometrical model enables us to\n",
      "reproduce the experimental probability density function of micro-swimmers in\n",
      "microfluidic chambers. Both our experiments and models demonstrate therefore\n",
      "that motility leads generically to trapping in complex geometries.\n",
      "Link: http://arxiv.org/pdf/2104.08218v1\n",
      "----\n",
      "Title: Circular swimming motility and disordered hyperuniform state in an algae system\n",
      "Authors: [arxiv.Result.Author('Mingji Huang'), arxiv.Result.Author('Wensi Hu'), arxiv.Result.Author('Siyuan Yang'), arxiv.Result.Author('Quan-Xing Liu'), arxiv.Result.Author('H. P. Zhang')]\n",
      "Summary: Active matter comprises individually driven units that convert locally stored\n",
      "energy into mechanical motion. Interactions between driven units lead to a\n",
      "variety of non-equilibrium collective phenomena in active matter. One of such\n",
      "phenomena is anomalously large density fluctuations, which have been observed\n",
      "in both experiments and theories. Here we show that, on the contrary, density\n",
      "fluctuations in active matter can also be greatly suppressed. Our experiments\n",
      "are carried out with marine algae ($\\it{Effrenium\\ voratum}$) which swim in\n",
      "circles at the air-liquid interfaces with two different eukaryotic flagella.\n",
      "Cell swimming generates fluid flow which leads to effective repulsions between\n",
      "cells in the far field. Long-range nature of such repulsive interactions\n",
      "suppresses density fluctuations and generates disordered hyperuniform states\n",
      "under a wide range of density conditions. Emergence of hyperuniformity and\n",
      "associated scaling exponent are quantitatively reproduced in a numerical model\n",
      "whose main ingredients are effective hydrodynamic interactions and uncorrelated\n",
      "random cell motion. Our results demonstrate a new form of collective state in\n",
      "active matter and suggest the possibility to use hydrodynamic flow for\n",
      "self-assembly in active matter.\n",
      "Link: http://arxiv.org/pdf/2106.06754v1\n",
      "----\n",
      "Title: Collective motion of active particles exhibiting non-reciprocal orientational interactions\n",
      "Authors: [arxiv.Result.Author('Milos Knezevic'), arxiv.Result.Author('Till Welker'), arxiv.Result.Author('Holger Stark')]\n",
      "Summary: We present a Brownian dynamics study of a 2d bath of active particles\n",
      "interacting among each other through usual steric interactions and,\n",
      "additionally, via non-reciprocal avoidant orientational interactions. We\n",
      "motivate them by the fact that the two flagella of the alga Chlamydomonas\n",
      "interact sterically with nearby surfaces such that a torque acts on the alga.\n",
      "As expected, in most cases such interactions disrupt the motility-induced\n",
      "particle clustering in active baths. Surprisingly, however, we find that the\n",
      "active particles can self-organize into collectively moving flocks if the range\n",
      "of non-reciprocal interactions is close to that of steric interactions. We\n",
      "observe that the flocking motion can manifest itself through a variety of\n",
      "structural forms, spanning from single dense bands to multiple moderately-dense\n",
      "stripes, which are highly dynamic. The flocking order parameter is found to be\n",
      "only weakly dependent on the underlying flock structure. Together with the\n",
      "variance of the local-density distribution, one can clearly group the flocking\n",
      "motion into the two separate band and dynamic-stripes states.\n",
      "Link: http://arxiv.org/pdf/2204.06089v2\n",
      "----\n",
      "Title: Bioconvection in a phototactic algae suspension with oblique irradiation and forward anisotropic scattering\n",
      "Authors: [arxiv.Result.Author('Sandeep Kumar'), arxiv.Result.Author('Preeti Sharma')]\n",
      "Summary: In this study, we analyze the bioconvection in a suspension of phototactic\n",
      "algae that exhibits anisotropic scattering. The top layer of the suspension is\n",
      "illuminated by oblique collimated irradiation. During the study, the bottom\n",
      "boundary is considered as rigid whereas the top boundary is considered\n",
      "stress-free. In order to solve the eigenvalue problem, the\n",
      "Newton-Raphson-Kantorovich finite difference method of order four is used.\n",
      "Linear analysis of the basic state is performed using neutral curves. The\n",
      "results demonstrate a change in the most unstable mode from an overstable to a\n",
      "stationary state or vice versa for particular parameters in response to a\n",
      "variation in the incidence angle. The position of the maximum basic\n",
      "concentration shifts toward the top of the suspension as the incidence angle is\n",
      "increased. In most cases, the system becomes more unstable with an increment in\n",
      "the incidence angle.\n",
      "Link: http://arxiv.org/pdf/2303.02371v1\n",
      "----\n",
      "Title: Cryptic photosynthesis, Extrasolar planetary oxygen without a surface biological signature\n",
      "Authors: [arxiv.Result.Author('C. S. Cockell'), arxiv.Result.Author('L. Kaltenegger'), arxiv.Result.Author('J. A. Raven')]\n",
      "Summary: On the Earth, photosynthetic organisms are responsible for the production of\n",
      "virtually all of the oxygen in the atmosphere. On the land, vegetation reflects\n",
      "in the visible, leading to a red edge that developed about 450 Myr ago and has\n",
      "been proposed as a biosignature for life on extrasolar planets. However, in\n",
      "many regions of the Earth, and particularly where surface conditions are\n",
      "extreme, for example in hot and cold deserts, photosynthetic organisms can be\n",
      "driven into and under substrates where light is still sufficient for\n",
      "photosynthesis. These communities exhibit no detectable surface spectral\n",
      "signature to indicate life. The same is true of the assemblages of\n",
      "photosynthetic organisms at more than a few metres depth in water bodies. These\n",
      "communities are widespread and dominate local photosynthetic productivity. We\n",
      "review known cryptic photosynthetic communities and their productivity. We link\n",
      "geomicrobiology with observational astronomy by calculating the disk-averaged\n",
      "spectra of cryptic habitats and identifying detectable features on an exoplanet\n",
      "dominated by such a biota. The hypothetical cryptic photosynthesis worlds\n",
      "discussed here are Earth-analogs that show detectable atmospheric biomarkers\n",
      "like our own planet, but do not exhibit a discernable biological surface\n",
      "feature in the disc-averaged spectrum.\n",
      "Link: http://arxiv.org/pdf/0809.3990v3\n",
      "----\n",
      "Title: Reductions in Depth-integrated Picophytoplanktonic Photosynthesis Due to Inhibition by Ultraviolet and Photosynthetically Available Radiation: Global Predictions for $\\textit{Prochlorococcus}$ and $\\textit{Synechococcus}$\n",
      "Authors: [arxiv.Result.Author('Patrick J. Neale'), arxiv.Result.Author('Brian C. Thomas')]\n",
      "Summary: Phytoplankton photosynthesis in most natural waters is often inhibited by\n",
      "ultraviolet (UV) and intense photosynthetically available radiation (PAR) but\n",
      "the effects on ocean productivity have received little consideration aside from\n",
      "polar areas subject to periodic enhanced UV-B due to depletion of stratospheric\n",
      "ozone. Here we consider responses in the temperate and tropical mid-ocean\n",
      "regions typically dominated by picophytoplankton including the prokaryotic\n",
      "lineages, $\\textit{Prochlorococcus}$ and $\\textit{Synechococcus}$. Spectral\n",
      "models of photosynthetic response for each lineage were constructed using model\n",
      "strains cultured at different growth irradiances and temperatures. In the\n",
      "model, inhibition becomes more severe once exposure exceeds a threshold (Emax)\n",
      "related to repair capacity. Model parameters are presented for\n",
      "$\\textit{Prochlorococcus}$ adding to those previously presented for\n",
      "$\\textit{Synechococcus}$. The models were applied to the estimation of mid-day,\n",
      "water-column photosynthesis based on an atmospheric model of spectral incident\n",
      "radiation, satellite-derived spectral water transparency and sea surface\n",
      "temperature. Comparing predictions integrated over the water column including\n",
      "versus excluding inhibition, production was 7-28% lower due to inhibition\n",
      "depending on strain and site conditions. Inhibition was consistently greater\n",
      "for $\\textit{Prochlorococcus}$ compared to two strains of\n",
      "$\\textit{Synechococcus}$. Considering only the surface mixed layer, production\n",
      "was inhibited 7-73%. Weighted by lineage abundance and daily PAR exposure,\n",
      "inhibition of full water column production averages around 20% for the modeled\n",
      "region of the Pacific with two-thirds of the inhibition due to UV. The results\n",
      "suggest more consideration is needed on inhibition effects, especially due to\n",
      "UV, which are largely excluded from present models of global phytoplankton\n",
      "production.\n",
      "Link: http://arxiv.org/pdf/1607.02980v1\n",
      "----\n",
      "Title: Early evolution of purple retinal pigments on Earth and implications for exoplanet biosignatures\n",
      "Authors: [arxiv.Result.Author('Shiladitya DasSarma'), arxiv.Result.Author('Edward W. Schwieterman')]\n",
      "Summary: We propose that retinal-based phototrophy arose early in the evolution of\n",
      "life on Earth, profoundly impacting the development of photosynthesis and\n",
      "creating implications for the search for life beyond our planet. While the\n",
      "early evolutionary history of phototrophy is largely in the realm of the\n",
      "unknown, the onset of oxygenic photosynthesis in primitive cyanobacteria\n",
      "significantly altered the Earth's atmosphere by contributing to the rise of\n",
      "oxygen ~2.3 billion years ago. However, photosynthetic chlorophyll and\n",
      "bacteriochlorophyll pigments lack appreciable absorption at wavelengths about\n",
      "500-600 nm, an energy-rich region of the solar spectrum. By contrast, simpler\n",
      "retinal-based light-harvesting systems such as the haloarchaeal purple membrane\n",
      "protein bacteriorhodopsin show a strong well-defined peak of absorbance\n",
      "centered at 568 nm, which is complementary to that of chlorophyll pigments. We\n",
      "propose a scenario where simple retinal-based light-harvesting systems like\n",
      "that of the purple chromoprotein bacteriorhodopsin, originally discovered in\n",
      "halophilic Archaea, may have dominated prior to the development of\n",
      "photosynthesis. We explore this hypothesis, termed the 'Purple Earth,' and\n",
      "discuss how retinal photopigments may serve as remote biosignatures for\n",
      "exoplanet research.\n",
      "Link: http://arxiv.org/pdf/1810.05150v1\n",
      "----\n",
      "Title: A New Definition of Exoplanet Habitability: Introducing the Photosynthetic Habitable Zone\n",
      "Authors: [arxiv.Result.Author('C. Hall'), arxiv.Result.Author('P. C. Stancil'), arxiv.Result.Author('J. P. Terry'), arxiv.Result.Author('C. K. Ellison')]\n",
      "Summary: It may be possible to detect biosignatures of photosynthesis in an\n",
      "exoplanet's atmosphere. However, such a detection would likely require a\n",
      "dedicated study, occupying a large amount of telescope time. It is therefore\n",
      "prudent, while searching for signs of life that we may recognise, to pick the\n",
      "best target possible. In this work, we present a new region, the\n",
      "``photosynthetic habitable zone'' \\textemdash the distance from a star where\n",
      "both liquid water and oxygenic photosynthesis can occur. It is therefore the\n",
      "region where detectable biosignatures of oxygenic photosynthesis are most\n",
      "likely to occur. Our analysis indicates that in the most ideal conditions for\n",
      "life and no atmospheric effects, the photosynthetic habitable zone is almost as\n",
      "broad as the habitable zone. On the other hand, if conditions for life are\n",
      "anything less than excellent and atmospheric effects are even moderate, the\n",
      "photosynthetic habitable zone is concentrated at larger separations around more\n",
      "massive stars. Such cases are also not tidally locked to their host star, which\n",
      "could result in planetary rotation periods similar to the Earth's. We identify\n",
      "five planets, Kepler-452 b, Kepler-1638 b, Kepler-1544 b and Kepler-62 e and\n",
      "Kepler-62 f, that are consistently in the photosynthetic habitable zone for a\n",
      "variety of conditions, and we predict their day lengths to be between 9 and 11\n",
      "hours. We conclude that the parameter space in which we should search for signs\n",
      "of life is much narrower than the standard habitable zone.\n",
      "Link: http://arxiv.org/pdf/2301.13836v2\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "# Search query\n",
    "query = \"algae photosynthesis\"\n",
    "\n",
    "# Search arXiv for the query\n",
    "search = arxiv.Search(\n",
    "  query=query,\n",
    "  max_results=100,\n",
    ")\n",
    "\n",
    "# Loop through each paper found\n",
    "for result in search.get():\n",
    "    print(\"Title:\", result.title)\n",
    "    print(\"Authors:\", result.authors)\n",
    "    print(\"Summary:\", result.summary)\n",
    "    print(\"Link:\", result.pdf_url)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1007cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Obtaining dependency information for arxiv from https://files.pythonhosted.org/packages/f0/06/9b9d553d93e25ae27ec5ba794216afb1af248e43d85a35e922a85cbb396a/arxiv-1.4.8-py3-none-any.whl.metadata\n",
      "  Downloading arxiv-1.4.8-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting feedparser (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k (from feedparser->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading arxiv-1.4.8-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=b27463105fda743c7d2f5f004d236842e01abe116a86322ff9e1082ba2ece1f5\n",
      "  Stored in directory: /Users/adnanwahab/Library/Caches/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-1.4.8 feedparser-6.0.10 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9f32cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.airbnb.com/rooms/3850',\n",
       " 'https://www.airbnb.com/rooms/12584',\n",
       " 'https://www.airbnb.com/rooms/24450',\n",
       " 'https://www.airbnb.com/rooms/24463',\n",
       " 'https://www.airbnb.com/rooms/25094',\n",
       " 'https://www.airbnb.com/rooms/25463',\n",
       " 'https://www.airbnb.com/rooms/29373',\n",
       " 'https://www.airbnb.com/rooms/29557',\n",
       " 'https://www.airbnb.com/rooms/32414',\n",
       " 'https://www.airbnb.com/rooms/39174',\n",
       " 'https://www.airbnb.com/rooms/39418',\n",
       " 'https://www.airbnb.com/rooms/41172',\n",
       " 'https://www.airbnb.com/rooms/41423',\n",
       " 'https://www.airbnb.com/rooms/42403',\n",
       " 'https://www.airbnb.com/rooms/42408',\n",
       " 'https://www.airbnb.com/rooms/42577',\n",
       " 'https://www.airbnb.com/rooms/47486',\n",
       " 'https://www.airbnb.com/rooms/47682',\n",
       " 'https://www.airbnb.com/rooms/51374',\n",
       " 'https://www.airbnb.com/rooms/51773',\n",
       " 'https://www.airbnb.com/rooms/53280',\n",
       " 'https://www.airbnb.com/rooms/54518',\n",
       " 'https://www.airbnb.com/rooms/54634',\n",
       " 'https://www.airbnb.com/rooms/55632',\n",
       " 'https://www.airbnb.com/rooms/55636',\n",
       " 'https://www.airbnb.com/rooms/56621',\n",
       " 'https://www.airbnb.com/rooms/57561',\n",
       " 'https://www.airbnb.com/rooms/59344',\n",
       " 'https://www.airbnb.com/rooms/59381',\n",
       " 'https://www.airbnb.com/rooms/59702',\n",
       " 'https://www.airbnb.com/rooms/59831',\n",
       " 'https://www.airbnb.com/rooms/62519',\n",
       " 'https://www.airbnb.com/rooms/64165',\n",
       " 'https://www.airbnb.com/rooms/66119',\n",
       " 'https://www.airbnb.com/rooms/66188',\n",
       " 'https://www.airbnb.com/rooms/66664',\n",
       " 'https://www.airbnb.com/rooms/69410',\n",
       " 'https://www.airbnb.com/rooms/69549',\n",
       " 'https://www.airbnb.com/rooms/69553',\n",
       " 'https://www.airbnb.com/rooms/69681',\n",
       " 'https://www.airbnb.com/rooms/71645',\n",
       " 'https://www.airbnb.com/rooms/71779',\n",
       " 'https://www.airbnb.com/rooms/73011',\n",
       " 'https://www.airbnb.com/rooms/74758',\n",
       " 'https://www.airbnb.com/rooms/75422',\n",
       " 'https://www.airbnb.com/rooms/75423',\n",
       " 'https://www.airbnb.com/rooms/77175',\n",
       " 'https://www.airbnb.com/rooms/77932',\n",
       " 'https://www.airbnb.com/rooms/81158',\n",
       " 'https://www.airbnb.com/rooms/81256',\n",
       " 'https://www.airbnb.com/rooms/83553',\n",
       " 'https://www.airbnb.com/rooms/84777',\n",
       " 'https://www.airbnb.com/rooms/87640',\n",
       " 'https://www.airbnb.com/rooms/91957',\n",
       " 'https://www.airbnb.com/rooms/96383',\n",
       " 'https://www.airbnb.com/rooms/105497',\n",
       " 'https://www.airbnb.com/rooms/109883',\n",
       " 'https://www.airbnb.com/rooms/110825',\n",
       " 'https://www.airbnb.com/rooms/128230',\n",
       " 'https://www.airbnb.com/rooms/134015',\n",
       " 'https://www.airbnb.com/rooms/134193',\n",
       " 'https://www.airbnb.com/rooms/137129',\n",
       " 'https://www.airbnb.com/rooms/137546',\n",
       " 'https://www.airbnb.com/rooms/137672',\n",
       " 'https://www.airbnb.com/rooms/138592',\n",
       " 'https://www.airbnb.com/rooms/142177',\n",
       " 'https://www.airbnb.com/rooms/144978',\n",
       " 'https://www.airbnb.com/rooms/147443',\n",
       " 'https://www.airbnb.com/rooms/148769',\n",
       " 'https://www.airbnb.com/rooms/150848',\n",
       " 'https://www.airbnb.com/rooms/162934',\n",
       " 'https://www.airbnb.com/rooms/164207',\n",
       " 'https://www.airbnb.com/rooms/176274',\n",
       " 'https://www.airbnb.com/rooms/183859',\n",
       " 'https://www.airbnb.com/rooms/189894',\n",
       " 'https://www.airbnb.com/rooms/199480',\n",
       " 'https://www.airbnb.com/rooms/201313',\n",
       " 'https://www.airbnb.com/rooms/207980',\n",
       " 'https://www.airbnb.com/rooms/208727',\n",
       " 'https://www.airbnb.com/rooms/216042',\n",
       " 'https://www.airbnb.com/rooms/217106',\n",
       " 'https://www.airbnb.com/rooms/221342',\n",
       " 'https://www.airbnb.com/rooms/224579',\n",
       " 'https://www.airbnb.com/rooms/231752',\n",
       " 'https://www.airbnb.com/rooms/232060',\n",
       " 'https://www.airbnb.com/rooms/238190',\n",
       " 'https://www.airbnb.com/rooms/238204',\n",
       " 'https://www.airbnb.com/rooms/252867',\n",
       " 'https://www.airbnb.com/rooms/271647',\n",
       " 'https://www.airbnb.com/rooms/273530',\n",
       " 'https://www.airbnb.com/rooms/274334',\n",
       " 'https://www.airbnb.com/rooms/280549',\n",
       " 'https://www.airbnb.com/rooms/284117',\n",
       " 'https://www.airbnb.com/rooms/286311',\n",
       " 'https://www.airbnb.com/rooms/287907',\n",
       " 'https://www.airbnb.com/rooms/292723',\n",
       " 'https://www.airbnb.com/rooms/295565',\n",
       " 'https://www.airbnb.com/rooms/306504',\n",
       " 'https://www.airbnb.com/rooms/307837',\n",
       " 'https://www.airbnb.com/rooms/314248',\n",
       " 'https://www.airbnb.com/rooms/314368',\n",
       " 'https://www.airbnb.com/rooms/317121',\n",
       " 'https://www.airbnb.com/rooms/329020',\n",
       " 'https://www.airbnb.com/rooms/334339',\n",
       " 'https://www.airbnb.com/rooms/334886',\n",
       " 'https://www.airbnb.com/rooms/338849',\n",
       " 'https://www.airbnb.com/rooms/344621',\n",
       " 'https://www.airbnb.com/rooms/351950',\n",
       " 'https://www.airbnb.com/rooms/351978',\n",
       " 'https://www.airbnb.com/rooms/352165',\n",
       " 'https://www.airbnb.com/rooms/364397',\n",
       " 'https://www.airbnb.com/rooms/366541',\n",
       " 'https://www.airbnb.com/rooms/377569',\n",
       " 'https://www.airbnb.com/rooms/379255',\n",
       " 'https://www.airbnb.com/rooms/379349',\n",
       " 'https://www.airbnb.com/rooms/379418',\n",
       " 'https://www.airbnb.com/rooms/392543',\n",
       " 'https://www.airbnb.com/rooms/394575',\n",
       " 'https://www.airbnb.com/rooms/408471',\n",
       " 'https://www.airbnb.com/rooms/409549',\n",
       " 'https://www.airbnb.com/rooms/409560',\n",
       " 'https://www.airbnb.com/rooms/413663',\n",
       " 'https://www.airbnb.com/rooms/424846',\n",
       " 'https://www.airbnb.com/rooms/437385',\n",
       " 'https://www.airbnb.com/rooms/442397',\n",
       " 'https://www.airbnb.com/rooms/444675',\n",
       " 'https://www.airbnb.com/rooms/455783',\n",
       " 'https://www.airbnb.com/rooms/457862',\n",
       " 'https://www.airbnb.com/rooms/465723',\n",
       " 'https://www.airbnb.com/rooms/467507',\n",
       " 'https://www.airbnb.com/rooms/474107',\n",
       " 'https://www.airbnb.com/rooms/479072',\n",
       " 'https://www.airbnb.com/rooms/482592',\n",
       " 'https://www.airbnb.com/rooms/485286',\n",
       " 'https://www.airbnb.com/rooms/487019',\n",
       " 'https://www.airbnb.com/rooms/488297',\n",
       " 'https://www.airbnb.com/rooms/493889',\n",
       " 'https://www.airbnb.com/rooms/494111',\n",
       " 'https://www.airbnb.com/rooms/504146',\n",
       " 'https://www.airbnb.com/rooms/505530',\n",
       " 'https://www.airbnb.com/rooms/515260',\n",
       " 'https://www.airbnb.com/rooms/516836',\n",
       " 'https://www.airbnb.com/rooms/517803',\n",
       " 'https://www.airbnb.com/rooms/530857',\n",
       " 'https://www.airbnb.com/rooms/531151',\n",
       " 'https://www.airbnb.com/rooms/533193',\n",
       " 'https://www.airbnb.com/rooms/545685',\n",
       " 'https://www.airbnb.com/rooms/555596',\n",
       " 'https://www.airbnb.com/rooms/561148',\n",
       " 'https://www.airbnb.com/rooms/567239',\n",
       " 'https://www.airbnb.com/rooms/568161',\n",
       " 'https://www.airbnb.com/rooms/571042',\n",
       " 'https://www.airbnb.com/rooms/576018',\n",
       " 'https://www.airbnb.com/rooms/585225',\n",
       " 'https://www.airbnb.com/rooms/585326',\n",
       " 'https://www.airbnb.com/rooms/589676',\n",
       " 'https://www.airbnb.com/rooms/598271',\n",
       " 'https://www.airbnb.com/rooms/602535',\n",
       " 'https://www.airbnb.com/rooms/604999',\n",
       " 'https://www.airbnb.com/rooms/627358',\n",
       " 'https://www.airbnb.com/rooms/631635',\n",
       " 'https://www.airbnb.com/rooms/631658',\n",
       " 'https://www.airbnb.com/rooms/631735',\n",
       " 'https://www.airbnb.com/rooms/632303',\n",
       " 'https://www.airbnb.com/rooms/633629',\n",
       " 'https://www.airbnb.com/rooms/644091',\n",
       " 'https://www.airbnb.com/rooms/647360',\n",
       " 'https://www.airbnb.com/rooms/648086',\n",
       " 'https://www.airbnb.com/rooms/651624',\n",
       " 'https://www.airbnb.com/rooms/654279',\n",
       " 'https://www.airbnb.com/rooms/654860',\n",
       " 'https://www.airbnb.com/rooms/655326',\n",
       " 'https://www.airbnb.com/rooms/677207',\n",
       " 'https://www.airbnb.com/rooms/678556',\n",
       " 'https://www.airbnb.com/rooms/687430',\n",
       " 'https://www.airbnb.com/rooms/715754',\n",
       " 'https://www.airbnb.com/rooms/719431',\n",
       " 'https://www.airbnb.com/rooms/720811',\n",
       " 'https://www.airbnb.com/rooms/725300',\n",
       " 'https://www.airbnb.com/rooms/727866',\n",
       " 'https://www.airbnb.com/rooms/727969',\n",
       " 'https://www.airbnb.com/rooms/728585',\n",
       " 'https://www.airbnb.com/rooms/728884',\n",
       " 'https://www.airbnb.com/rooms/738547',\n",
       " 'https://www.airbnb.com/rooms/746079',\n",
       " 'https://www.airbnb.com/rooms/760794',\n",
       " 'https://www.airbnb.com/rooms/766516',\n",
       " 'https://www.airbnb.com/rooms/767506',\n",
       " 'https://www.airbnb.com/rooms/776239',\n",
       " 'https://www.airbnb.com/rooms/783821',\n",
       " 'https://www.airbnb.com/rooms/786506',\n",
       " 'https://www.airbnb.com/rooms/794626',\n",
       " 'https://www.airbnb.com/rooms/797887',\n",
       " 'https://www.airbnb.com/rooms/802559',\n",
       " 'https://www.airbnb.com/rooms/808919',\n",
       " 'https://www.airbnb.com/rooms/815183',\n",
       " 'https://www.airbnb.com/rooms/819863',\n",
       " 'https://www.airbnb.com/rooms/833149',\n",
       " 'https://www.airbnb.com/rooms/840986',\n",
       " 'https://www.airbnb.com/rooms/845480',\n",
       " 'https://www.airbnb.com/rooms/845501',\n",
       " 'https://www.airbnb.com/rooms/848578',\n",
       " 'https://www.airbnb.com/rooms/859336',\n",
       " 'https://www.airbnb.com/rooms/862201',\n",
       " 'https://www.airbnb.com/rooms/867530',\n",
       " 'https://www.airbnb.com/rooms/883937',\n",
       " 'https://www.airbnb.com/rooms/884770',\n",
       " 'https://www.airbnb.com/rooms/900393',\n",
       " 'https://www.airbnb.com/rooms/900569',\n",
       " 'https://www.airbnb.com/rooms/900941',\n",
       " 'https://www.airbnb.com/rooms/902377',\n",
       " 'https://www.airbnb.com/rooms/905902',\n",
       " 'https://www.airbnb.com/rooms/911029',\n",
       " 'https://www.airbnb.com/rooms/915058',\n",
       " 'https://www.airbnb.com/rooms/923807',\n",
       " 'https://www.airbnb.com/rooms/929468',\n",
       " 'https://www.airbnb.com/rooms/930955',\n",
       " 'https://www.airbnb.com/rooms/934012',\n",
       " 'https://www.airbnb.com/rooms/943851',\n",
       " 'https://www.airbnb.com/rooms/945748',\n",
       " 'https://www.airbnb.com/rooms/950094',\n",
       " 'https://www.airbnb.com/rooms/964751',\n",
       " 'https://www.airbnb.com/rooms/975482',\n",
       " 'https://www.airbnb.com/rooms/982298',\n",
       " 'https://www.airbnb.com/rooms/992676',\n",
       " 'https://www.airbnb.com/rooms/1001415',\n",
       " 'https://www.airbnb.com/rooms/1003756',\n",
       " 'https://www.airbnb.com/rooms/1011292',\n",
       " 'https://www.airbnb.com/rooms/1011751',\n",
       " 'https://www.airbnb.com/rooms/1015336',\n",
       " 'https://www.airbnb.com/rooms/1016604',\n",
       " 'https://www.airbnb.com/rooms/1017799',\n",
       " 'https://www.airbnb.com/rooms/1023586',\n",
       " 'https://www.airbnb.com/rooms/1031899',\n",
       " 'https://www.airbnb.com/rooms/1033754',\n",
       " 'https://www.airbnb.com/rooms/1036860',\n",
       " 'https://www.airbnb.com/rooms/1037251',\n",
       " 'https://www.airbnb.com/rooms/1043282',\n",
       " 'https://www.airbnb.com/rooms/1069167',\n",
       " 'https://www.airbnb.com/rooms/1077444',\n",
       " 'https://www.airbnb.com/rooms/1083810',\n",
       " 'https://www.airbnb.com/rooms/1087427',\n",
       " 'https://www.airbnb.com/rooms/1104912',\n",
       " 'https://www.airbnb.com/rooms/1106534',\n",
       " 'https://www.airbnb.com/rooms/1107014',\n",
       " 'https://www.airbnb.com/rooms/1110001',\n",
       " 'https://www.airbnb.com/rooms/1110787',\n",
       " 'https://www.airbnb.com/rooms/1117813',\n",
       " 'https://www.airbnb.com/rooms/1121697',\n",
       " 'https://www.airbnb.com/rooms/1123125',\n",
       " 'https://www.airbnb.com/rooms/1125079',\n",
       " 'https://www.airbnb.com/rooms/1125115',\n",
       " 'https://www.airbnb.com/rooms/1133372',\n",
       " 'https://www.airbnb.com/rooms/1142101',\n",
       " 'https://www.airbnb.com/rooms/1159284',\n",
       " 'https://www.airbnb.com/rooms/1174214',\n",
       " 'https://www.airbnb.com/rooms/1174758',\n",
       " 'https://www.airbnb.com/rooms/1178281',\n",
       " 'https://www.airbnb.com/rooms/1182465',\n",
       " 'https://www.airbnb.com/rooms/1183521',\n",
       " 'https://www.airbnb.com/rooms/1200068',\n",
       " 'https://www.airbnb.com/rooms/1203172',\n",
       " 'https://www.airbnb.com/rooms/1203849',\n",
       " 'https://www.airbnb.com/rooms/1205031',\n",
       " 'https://www.airbnb.com/rooms/1209893',\n",
       " 'https://www.airbnb.com/rooms/1212513',\n",
       " 'https://www.airbnb.com/rooms/1212822',\n",
       " 'https://www.airbnb.com/rooms/1241029',\n",
       " 'https://www.airbnb.com/rooms/1245838',\n",
       " 'https://www.airbnb.com/rooms/1247160',\n",
       " 'https://www.airbnb.com/rooms/1261122',\n",
       " 'https://www.airbnb.com/rooms/1277771',\n",
       " 'https://www.airbnb.com/rooms/1281132',\n",
       " 'https://www.airbnb.com/rooms/1287889',\n",
       " 'https://www.airbnb.com/rooms/1290935',\n",
       " 'https://www.airbnb.com/rooms/1323983',\n",
       " 'https://www.airbnb.com/rooms/1326577',\n",
       " 'https://www.airbnb.com/rooms/1328186',\n",
       " 'https://www.airbnb.com/rooms/1335996',\n",
       " 'https://www.airbnb.com/rooms/1340755',\n",
       " 'https://www.airbnb.com/rooms/1344243',\n",
       " 'https://www.airbnb.com/rooms/1351626',\n",
       " 'https://www.airbnb.com/rooms/1351783',\n",
       " 'https://www.airbnb.com/rooms/1392204',\n",
       " 'https://www.airbnb.com/rooms/1393654',\n",
       " 'https://www.airbnb.com/rooms/1405046',\n",
       " 'https://www.airbnb.com/rooms/1421774',\n",
       " 'https://www.airbnb.com/rooms/1421937',\n",
       " 'https://www.airbnb.com/rooms/1428465',\n",
       " 'https://www.airbnb.com/rooms/1428553',\n",
       " 'https://www.airbnb.com/rooms/1429022',\n",
       " 'https://www.airbnb.com/rooms/1433011',\n",
       " 'https://www.airbnb.com/rooms/1433917',\n",
       " 'https://www.airbnb.com/rooms/1434314',\n",
       " 'https://www.airbnb.com/rooms/1438864',\n",
       " 'https://www.airbnb.com/rooms/1456153',\n",
       " 'https://www.airbnb.com/rooms/1460174',\n",
       " 'https://www.airbnb.com/rooms/1460628',\n",
       " 'https://www.airbnb.com/rooms/1470340',\n",
       " 'https://www.airbnb.com/rooms/1478708',\n",
       " 'https://www.airbnb.com/rooms/1487849',\n",
       " 'https://www.airbnb.com/rooms/1489175',\n",
       " 'https://www.airbnb.com/rooms/1489782',\n",
       " 'https://www.airbnb.com/rooms/1504826',\n",
       " 'https://www.airbnb.com/rooms/1510363',\n",
       " 'https://www.airbnb.com/rooms/1520938',\n",
       " 'https://www.airbnb.com/rooms/1524346',\n",
       " 'https://www.airbnb.com/rooms/1525137',\n",
       " 'https://www.airbnb.com/rooms/1547477',\n",
       " 'https://www.airbnb.com/rooms/1556680',\n",
       " 'https://www.airbnb.com/rooms/1578597',\n",
       " 'https://www.airbnb.com/rooms/1579304',\n",
       " 'https://www.airbnb.com/rooms/1614622',\n",
       " 'https://www.airbnb.com/rooms/1615088',\n",
       " 'https://www.airbnb.com/rooms/1615158',\n",
       " 'https://www.airbnb.com/rooms/1633126',\n",
       " 'https://www.airbnb.com/rooms/1633173',\n",
       " 'https://www.airbnb.com/rooms/1633225',\n",
       " 'https://www.airbnb.com/rooms/1641060',\n",
       " 'https://www.airbnb.com/rooms/1671260',\n",
       " 'https://www.airbnb.com/rooms/1676460',\n",
       " 'https://www.airbnb.com/rooms/1687330',\n",
       " 'https://www.airbnb.com/rooms/1696383',\n",
       " 'https://www.airbnb.com/rooms/1696666',\n",
       " 'https://www.airbnb.com/rooms/1711075',\n",
       " 'https://www.airbnb.com/rooms/1724819',\n",
       " 'https://www.airbnb.com/rooms/1725853',\n",
       " 'https://www.airbnb.com/rooms/1740537',\n",
       " 'https://www.airbnb.com/rooms/1747531',\n",
       " 'https://www.airbnb.com/rooms/1752371',\n",
       " 'https://www.airbnb.com/rooms/1768239',\n",
       " 'https://www.airbnb.com/rooms/1768673',\n",
       " 'https://www.airbnb.com/rooms/1769688',\n",
       " 'https://www.airbnb.com/rooms/1778650',\n",
       " 'https://www.airbnb.com/rooms/1785463',\n",
       " 'https://www.airbnb.com/rooms/1821543',\n",
       " 'https://www.airbnb.com/rooms/1827653',\n",
       " 'https://www.airbnb.com/rooms/1830541',\n",
       " 'https://www.airbnb.com/rooms/1844117',\n",
       " 'https://www.airbnb.com/rooms/1847664',\n",
       " 'https://www.airbnb.com/rooms/1855096',\n",
       " 'https://www.airbnb.com/rooms/1857226',\n",
       " 'https://www.airbnb.com/rooms/1864390',\n",
       " 'https://www.airbnb.com/rooms/1887206',\n",
       " 'https://www.airbnb.com/rooms/1898486',\n",
       " 'https://www.airbnb.com/rooms/1906323',\n",
       " 'https://www.airbnb.com/rooms/1906681',\n",
       " 'https://www.airbnb.com/rooms/1914841',\n",
       " 'https://www.airbnb.com/rooms/1920033',\n",
       " 'https://www.airbnb.com/rooms/1925206',\n",
       " 'https://www.airbnb.com/rooms/1926253',\n",
       " 'https://www.airbnb.com/rooms/1932019',\n",
       " 'https://www.airbnb.com/rooms/1945508',\n",
       " 'https://www.airbnb.com/rooms/1959880',\n",
       " 'https://www.airbnb.com/rooms/1960773',\n",
       " 'https://www.airbnb.com/rooms/1970257',\n",
       " 'https://www.airbnb.com/rooms/1970756',\n",
       " 'https://www.airbnb.com/rooms/1984709',\n",
       " 'https://www.airbnb.com/rooms/1992217',\n",
       " 'https://www.airbnb.com/rooms/2016198',\n",
       " 'https://www.airbnb.com/rooms/2022751',\n",
       " 'https://www.airbnb.com/rooms/2026910',\n",
       " 'https://www.airbnb.com/rooms/2042095',\n",
       " 'https://www.airbnb.com/rooms/2049955',\n",
       " 'https://www.airbnb.com/rooms/2063077',\n",
       " 'https://www.airbnb.com/rooms/2072133',\n",
       " 'https://www.airbnb.com/rooms/2074270',\n",
       " 'https://www.airbnb.com/rooms/2093695',\n",
       " 'https://www.airbnb.com/rooms/2096756',\n",
       " 'https://www.airbnb.com/rooms/2115503',\n",
       " 'https://www.airbnb.com/rooms/2119773',\n",
       " 'https://www.airbnb.com/rooms/2123469',\n",
       " 'https://www.airbnb.com/rooms/2124182',\n",
       " 'https://www.airbnb.com/rooms/2126868',\n",
       " 'https://www.airbnb.com/rooms/2139562',\n",
       " 'https://www.airbnb.com/rooms/2154122',\n",
       " 'https://www.airbnb.com/rooms/2160504',\n",
       " 'https://www.airbnb.com/rooms/2169208',\n",
       " 'https://www.airbnb.com/rooms/2172308',\n",
       " 'https://www.airbnb.com/rooms/2175930',\n",
       " 'https://www.airbnb.com/rooms/2177440',\n",
       " 'https://www.airbnb.com/rooms/2189514',\n",
       " 'https://www.airbnb.com/rooms/2203283',\n",
       " 'https://www.airbnb.com/rooms/2209353',\n",
       " 'https://www.airbnb.com/rooms/2210105',\n",
       " 'https://www.airbnb.com/rooms/2221057',\n",
       " 'https://www.airbnb.com/rooms/2233416',\n",
       " 'https://www.airbnb.com/rooms/2234256',\n",
       " 'https://www.airbnb.com/rooms/2238488',\n",
       " 'https://www.airbnb.com/rooms/2254431',\n",
       " 'https://www.airbnb.com/rooms/2263794',\n",
       " 'https://www.airbnb.com/rooms/2274353',\n",
       " 'https://www.airbnb.com/rooms/2277754',\n",
       " 'https://www.airbnb.com/rooms/2302408',\n",
       " 'https://www.airbnb.com/rooms/2305039',\n",
       " 'https://www.airbnb.com/rooms/2310518',\n",
       " 'https://www.airbnb.com/rooms/2311428',\n",
       " 'https://www.airbnb.com/rooms/2314849',\n",
       " 'https://www.airbnb.com/rooms/2315086',\n",
       " 'https://www.airbnb.com/rooms/2316478',\n",
       " 'https://www.airbnb.com/rooms/2326228',\n",
       " 'https://www.airbnb.com/rooms/2349483',\n",
       " 'https://www.airbnb.com/rooms/2356554',\n",
       " 'https://www.airbnb.com/rooms/2362619',\n",
       " 'https://www.airbnb.com/rooms/2374267',\n",
       " 'https://www.airbnb.com/rooms/2374361',\n",
       " 'https://www.airbnb.com/rooms/2387068',\n",
       " 'https://www.airbnb.com/rooms/2396847',\n",
       " 'https://www.airbnb.com/rooms/2397852',\n",
       " 'https://www.airbnb.com/rooms/2397858',\n",
       " 'https://www.airbnb.com/rooms/2404647',\n",
       " 'https://www.airbnb.com/rooms/2420887',\n",
       " 'https://www.airbnb.com/rooms/2432104',\n",
       " 'https://www.airbnb.com/rooms/2436213',\n",
       " 'https://www.airbnb.com/rooms/2455313',\n",
       " 'https://www.airbnb.com/rooms/2460904',\n",
       " 'https://www.airbnb.com/rooms/2465543',\n",
       " 'https://www.airbnb.com/rooms/2477787',\n",
       " 'https://www.airbnb.com/rooms/2482884',\n",
       " 'https://www.airbnb.com/rooms/2486953',\n",
       " 'https://www.airbnb.com/rooms/2488837',\n",
       " 'https://www.airbnb.com/rooms/2496086',\n",
       " 'https://www.airbnb.com/rooms/2496460',\n",
       " 'https://www.airbnb.com/rooms/2500662',\n",
       " 'https://www.airbnb.com/rooms/2509236',\n",
       " 'https://www.airbnb.com/rooms/2510224',\n",
       " 'https://www.airbnb.com/rooms/2516026',\n",
       " 'https://www.airbnb.com/rooms/2521327',\n",
       " 'https://www.airbnb.com/rooms/2538807',\n",
       " 'https://www.airbnb.com/rooms/2539953',\n",
       " 'https://www.airbnb.com/rooms/2550991',\n",
       " 'https://www.airbnb.com/rooms/2557977',\n",
       " 'https://www.airbnb.com/rooms/2614717',\n",
       " 'https://www.airbnb.com/rooms/2645189',\n",
       " 'https://www.airbnb.com/rooms/2670951',\n",
       " 'https://www.airbnb.com/rooms/2677273',\n",
       " 'https://www.airbnb.com/rooms/2683409',\n",
       " 'https://www.airbnb.com/rooms/2683857',\n",
       " 'https://www.airbnb.com/rooms/2694526',\n",
       " 'https://www.airbnb.com/rooms/2702606',\n",
       " 'https://www.airbnb.com/rooms/2706776',\n",
       " 'https://www.airbnb.com/rooms/2739477',\n",
       " 'https://www.airbnb.com/rooms/2742151',\n",
       " 'https://www.airbnb.com/rooms/2747383',\n",
       " 'https://www.airbnb.com/rooms/2770268',\n",
       " 'https://www.airbnb.com/rooms/2783251',\n",
       " 'https://www.airbnb.com/rooms/2802418',\n",
       " 'https://www.airbnb.com/rooms/2825966',\n",
       " 'https://www.airbnb.com/rooms/2904128',\n",
       " 'https://www.airbnb.com/rooms/2939849',\n",
       " 'https://www.airbnb.com/rooms/2942149',\n",
       " 'https://www.airbnb.com/rooms/2944843',\n",
       " 'https://www.airbnb.com/rooms/2948159',\n",
       " 'https://www.airbnb.com/rooms/2949071',\n",
       " 'https://www.airbnb.com/rooms/2950592',\n",
       " 'https://www.airbnb.com/rooms/2956406',\n",
       " 'https://www.airbnb.com/rooms/2968738',\n",
       " 'https://www.airbnb.com/rooms/2970253',\n",
       " 'https://www.airbnb.com/rooms/2980184',\n",
       " 'https://www.airbnb.com/rooms/3013427',\n",
       " 'https://www.airbnb.com/rooms/3013520',\n",
       " 'https://www.airbnb.com/rooms/3015450',\n",
       " 'https://www.airbnb.com/rooms/3031766',\n",
       " 'https://www.airbnb.com/rooms/3073038',\n",
       " 'https://www.airbnb.com/rooms/3081324',\n",
       " 'https://www.airbnb.com/rooms/3082327',\n",
       " 'https://www.airbnb.com/rooms/3093070',\n",
       " 'https://www.airbnb.com/rooms/3093543',\n",
       " 'https://www.airbnb.com/rooms/3105361',\n",
       " 'https://www.airbnb.com/rooms/3112427',\n",
       " 'https://www.airbnb.com/rooms/3116428',\n",
       " 'https://www.airbnb.com/rooms/3123536',\n",
       " 'https://www.airbnb.com/rooms/3124541',\n",
       " 'https://www.airbnb.com/rooms/3140113',\n",
       " 'https://www.airbnb.com/rooms/3157463',\n",
       " 'https://www.airbnb.com/rooms/3157541',\n",
       " 'https://www.airbnb.com/rooms/3168359',\n",
       " 'https://www.airbnb.com/rooms/3175769',\n",
       " 'https://www.airbnb.com/rooms/3200431',\n",
       " 'https://www.airbnb.com/rooms/3201044',\n",
       " 'https://www.airbnb.com/rooms/3205059',\n",
       " 'https://www.airbnb.com/rooms/3218306',\n",
       " 'https://www.airbnb.com/rooms/3221082',\n",
       " 'https://www.airbnb.com/rooms/3240016',\n",
       " 'https://www.airbnb.com/rooms/3256704',\n",
       " 'https://www.airbnb.com/rooms/3257979',\n",
       " 'https://www.airbnb.com/rooms/3262216',\n",
       " 'https://www.airbnb.com/rooms/3263219',\n",
       " 'https://www.airbnb.com/rooms/3292643',\n",
       " 'https://www.airbnb.com/rooms/3309722',\n",
       " 'https://www.airbnb.com/rooms/3311711',\n",
       " 'https://www.airbnb.com/rooms/3319447',\n",
       " 'https://www.airbnb.com/rooms/3325741',\n",
       " 'https://www.airbnb.com/rooms/3333870',\n",
       " 'https://www.airbnb.com/rooms/3343629',\n",
       " 'https://www.airbnb.com/rooms/3376512',\n",
       " 'https://www.airbnb.com/rooms/3376895',\n",
       " 'https://www.airbnb.com/rooms/3391368',\n",
       " 'https://www.airbnb.com/rooms/3394127',\n",
       " 'https://www.airbnb.com/rooms/3395051',\n",
       " 'https://www.airbnb.com/rooms/3415171',\n",
       " 'https://www.airbnb.com/rooms/3416013',\n",
       " 'https://www.airbnb.com/rooms/3433930',\n",
       " 'https://www.airbnb.com/rooms/3441517',\n",
       " 'https://www.airbnb.com/rooms/3442439',\n",
       " 'https://www.airbnb.com/rooms/3476601',\n",
       " 'https://www.airbnb.com/rooms/3486460',\n",
       " 'https://www.airbnb.com/rooms/3512817',\n",
       " 'https://www.airbnb.com/rooms/3522990',\n",
       " 'https://www.airbnb.com/rooms/3549398',\n",
       " 'https://www.airbnb.com/rooms/3563261',\n",
       " 'https://www.airbnb.com/rooms/3585034',\n",
       " 'https://www.airbnb.com/rooms/3613500',\n",
       " 'https://www.airbnb.com/rooms/3656251',\n",
       " 'https://www.airbnb.com/rooms/3689368',\n",
       " 'https://www.airbnb.com/rooms/3712976',\n",
       " 'https://www.airbnb.com/rooms/3720392',\n",
       " 'https://www.airbnb.com/rooms/3721927',\n",
       " 'https://www.airbnb.com/rooms/3743219',\n",
       " 'https://www.airbnb.com/rooms/3757966',\n",
       " 'https://www.airbnb.com/rooms/3759246',\n",
       " 'https://www.airbnb.com/rooms/3759368',\n",
       " 'https://www.airbnb.com/rooms/3775090',\n",
       " 'https://www.airbnb.com/rooms/3791003',\n",
       " 'https://www.airbnb.com/rooms/3792754',\n",
       " 'https://www.airbnb.com/rooms/3793678',\n",
       " 'https://www.airbnb.com/rooms/3808193',\n",
       " 'https://www.airbnb.com/rooms/3811916',\n",
       " 'https://www.airbnb.com/rooms/3812931',\n",
       " 'https://www.airbnb.com/rooms/3832296',\n",
       " 'https://www.airbnb.com/rooms/3852803',\n",
       " 'https://www.airbnb.com/rooms/3862478',\n",
       " 'https://www.airbnb.com/rooms/3870174',\n",
       " 'https://www.airbnb.com/rooms/3895335',\n",
       " 'https://www.airbnb.com/rooms/3924524',\n",
       " 'https://www.airbnb.com/rooms/3962831',\n",
       " 'https://www.airbnb.com/rooms/3994686',\n",
       " 'https://www.airbnb.com/rooms/4014209',\n",
       " 'https://www.airbnb.com/rooms/4023249',\n",
       " 'https://www.airbnb.com/rooms/4023585',\n",
       " 'https://www.airbnb.com/rooms/4026354',\n",
       " 'https://www.airbnb.com/rooms/4069838',\n",
       " 'https://www.airbnb.com/rooms/4075971',\n",
       " 'https://www.airbnb.com/rooms/4077186',\n",
       " 'https://www.airbnb.com/rooms/4093013',\n",
       " 'https://www.airbnb.com/rooms/4093807',\n",
       " 'https://www.airbnb.com/rooms/4093967',\n",
       " 'https://www.airbnb.com/rooms/4097700',\n",
       " 'https://www.airbnb.com/rooms/4100473',\n",
       " 'https://www.airbnb.com/rooms/4104344',\n",
       " 'https://www.airbnb.com/rooms/4105892',\n",
       " 'https://www.airbnb.com/rooms/4105958',\n",
       " 'https://www.airbnb.com/rooms/4121114',\n",
       " 'https://www.airbnb.com/rooms/4121691',\n",
       " 'https://www.airbnb.com/rooms/4122671',\n",
       " 'https://www.airbnb.com/rooms/4135201',\n",
       " 'https://www.airbnb.com/rooms/4157192',\n",
       " 'https://www.airbnb.com/rooms/4215907',\n",
       " 'https://www.airbnb.com/rooms/4243837',\n",
       " 'https://www.airbnb.com/rooms/4250927',\n",
       " 'https://www.airbnb.com/rooms/4252808',\n",
       " 'https://www.airbnb.com/rooms/4259418',\n",
       " 'https://www.airbnb.com/rooms/4280408',\n",
       " 'https://www.airbnb.com/rooms/4287481',\n",
       " 'https://www.airbnb.com/rooms/4305042',\n",
       " 'https://www.airbnb.com/rooms/4319230',\n",
       " 'https://www.airbnb.com/rooms/4330861',\n",
       " 'https://www.airbnb.com/rooms/4334560',\n",
       " 'https://www.airbnb.com/rooms/4359626',\n",
       " 'https://www.airbnb.com/rooms/4365969',\n",
       " 'https://www.airbnb.com/rooms/4372435',\n",
       " 'https://www.airbnb.com/rooms/4402199',\n",
       " 'https://www.airbnb.com/rooms/4416566',\n",
       " 'https://www.airbnb.com/rooms/4429527',\n",
       " 'https://www.airbnb.com/rooms/4445540',\n",
       " 'https://www.airbnb.com/rooms/4462326',\n",
       " 'https://www.airbnb.com/rooms/4463165',\n",
       " 'https://www.airbnb.com/rooms/4463263',\n",
       " 'https://www.airbnb.com/rooms/4470873',\n",
       " 'https://www.airbnb.com/rooms/4471474',\n",
       " 'https://www.airbnb.com/rooms/4476390',\n",
       " 'https://www.airbnb.com/rooms/4510968',\n",
       " 'https://www.airbnb.com/rooms/4517932',\n",
       " 'https://www.airbnb.com/rooms/4526608',\n",
       " 'https://www.airbnb.com/rooms/4533652',\n",
       " 'https://www.airbnb.com/rooms/4550843',\n",
       " 'https://www.airbnb.com/rooms/4576349',\n",
       " 'https://www.airbnb.com/rooms/4577224',\n",
       " 'https://www.airbnb.com/rooms/4594018',\n",
       " 'https://www.airbnb.com/rooms/4607282',\n",
       " 'https://www.airbnb.com/rooms/4614763',\n",
       " 'https://www.airbnb.com/rooms/4638176',\n",
       " 'https://www.airbnb.com/rooms/4638266',\n",
       " 'https://www.airbnb.com/rooms/4650391',\n",
       " 'https://www.airbnb.com/rooms/4653332',\n",
       " 'https://www.airbnb.com/rooms/4663060',\n",
       " 'https://www.airbnb.com/rooms/4663132',\n",
       " 'https://www.airbnb.com/rooms/4677343',\n",
       " 'https://www.airbnb.com/rooms/4678599',\n",
       " 'https://www.airbnb.com/rooms/4710280',\n",
       " 'https://www.airbnb.com/rooms/4718629',\n",
       " 'https://www.airbnb.com/rooms/4719139',\n",
       " 'https://www.airbnb.com/rooms/4760192',\n",
       " 'https://www.airbnb.com/rooms/4773944',\n",
       " 'https://www.airbnb.com/rooms/4774742',\n",
       " 'https://www.airbnb.com/rooms/4807817',\n",
       " 'https://www.airbnb.com/rooms/4808522',\n",
       " 'https://www.airbnb.com/rooms/4825026',\n",
       " 'https://www.airbnb.com/rooms/4832436',\n",
       " 'https://www.airbnb.com/rooms/4833101',\n",
       " 'https://www.airbnb.com/rooms/4841027',\n",
       " 'https://www.airbnb.com/rooms/4855194',\n",
       " 'https://www.airbnb.com/rooms/4855686',\n",
       " 'https://www.airbnb.com/rooms/4856290',\n",
       " 'https://www.airbnb.com/rooms/4875549',\n",
       " 'https://www.airbnb.com/rooms/4880695',\n",
       " 'https://www.airbnb.com/rooms/4880988',\n",
       " 'https://www.airbnb.com/rooms/4882295',\n",
       " 'https://www.airbnb.com/rooms/4896087',\n",
       " 'https://www.airbnb.com/rooms/4907924',\n",
       " 'https://www.airbnb.com/rooms/4921641',\n",
       " 'https://www.airbnb.com/rooms/4949779',\n",
       " 'https://www.airbnb.com/rooms/4956697',\n",
       " 'https://www.airbnb.com/rooms/4959980',\n",
       " 'https://www.airbnb.com/rooms/4962043',\n",
       " 'https://www.airbnb.com/rooms/5004303',\n",
       " 'https://www.airbnb.com/rooms/5027016',\n",
       " 'https://www.airbnb.com/rooms/5039206',\n",
       " 'https://www.airbnb.com/rooms/5068486',\n",
       " 'https://www.airbnb.com/rooms/5076251',\n",
       " 'https://www.airbnb.com/rooms/5094146',\n",
       " 'https://www.airbnb.com/rooms/5144482',\n",
       " 'https://www.airbnb.com/rooms/5151423',\n",
       " 'https://www.airbnb.com/rooms/5154227',\n",
       " 'https://www.airbnb.com/rooms/5154242',\n",
       " 'https://www.airbnb.com/rooms/5154367',\n",
       " 'https://www.airbnb.com/rooms/5162669',\n",
       " 'https://www.airbnb.com/rooms/5172959',\n",
       " 'https://www.airbnb.com/rooms/5174935',\n",
       " 'https://www.airbnb.com/rooms/5193689',\n",
       " 'https://www.airbnb.com/rooms/5194736',\n",
       " 'https://www.airbnb.com/rooms/5195922',\n",
       " 'https://www.airbnb.com/rooms/5196070',\n",
       " 'https://www.airbnb.com/rooms/5196116',\n",
       " 'https://www.airbnb.com/rooms/5196233',\n",
       " 'https://www.airbnb.com/rooms/5202841',\n",
       " 'https://www.airbnb.com/rooms/5212469',\n",
       " 'https://www.airbnb.com/rooms/5217164',\n",
       " 'https://www.airbnb.com/rooms/5242394',\n",
       " 'https://www.airbnb.com/rooms/5286779',\n",
       " 'https://www.airbnb.com/rooms/5317789',\n",
       " 'https://www.airbnb.com/rooms/5319588',\n",
       " 'https://www.airbnb.com/rooms/5325355',\n",
       " 'https://www.airbnb.com/rooms/5327231',\n",
       " 'https://www.airbnb.com/rooms/5345792',\n",
       " 'https://www.airbnb.com/rooms/5376278',\n",
       " 'https://www.airbnb.com/rooms/5406893',\n",
       " 'https://www.airbnb.com/rooms/5433133',\n",
       " 'https://www.airbnb.com/rooms/5443493',\n",
       " 'https://www.airbnb.com/rooms/5537718',\n",
       " 'https://www.airbnb.com/rooms/5547500',\n",
       " 'https://www.airbnb.com/rooms/5548977',\n",
       " 'https://www.airbnb.com/rooms/5550248',\n",
       " 'https://www.airbnb.com/rooms/5577516',\n",
       " 'https://www.airbnb.com/rooms/5581254',\n",
       " 'https://www.airbnb.com/rooms/5592675',\n",
       " 'https://www.airbnb.com/rooms/5592754',\n",
       " 'https://www.airbnb.com/rooms/5616609',\n",
       " 'https://www.airbnb.com/rooms/5632275',\n",
       " 'https://www.airbnb.com/rooms/5632452',\n",
       " 'https://www.airbnb.com/rooms/5697110',\n",
       " 'https://www.airbnb.com/rooms/5749181',\n",
       " 'https://www.airbnb.com/rooms/5749839',\n",
       " 'https://www.airbnb.com/rooms/5774490',\n",
       " 'https://www.airbnb.com/rooms/5785978',\n",
       " 'https://www.airbnb.com/rooms/5852066',\n",
       " 'https://www.airbnb.com/rooms/5853587',\n",
       " 'https://www.airbnb.com/rooms/5858973',\n",
       " 'https://www.airbnb.com/rooms/5861266',\n",
       " 'https://www.airbnb.com/rooms/5863674',\n",
       " 'https://www.airbnb.com/rooms/5882524',\n",
       " 'https://www.airbnb.com/rooms/5905163',\n",
       " 'https://www.airbnb.com/rooms/5918090',\n",
       " 'https://www.airbnb.com/rooms/5918432',\n",
       " 'https://www.airbnb.com/rooms/5919500',\n",
       " 'https://www.airbnb.com/rooms/5933430',\n",
       " 'https://www.airbnb.com/rooms/5970639',\n",
       " 'https://www.airbnb.com/rooms/5998790',\n",
       " 'https://www.airbnb.com/rooms/6006768',\n",
       " 'https://www.airbnb.com/rooms/6015077',\n",
       " 'https://www.airbnb.com/rooms/6016647',\n",
       " 'https://www.airbnb.com/rooms/6020579',\n",
       " 'https://www.airbnb.com/rooms/6072316',\n",
       " 'https://www.airbnb.com/rooms/6072767',\n",
       " 'https://www.airbnb.com/rooms/6080799',\n",
       " 'https://www.airbnb.com/rooms/6090316',\n",
       " 'https://www.airbnb.com/rooms/6091945',\n",
       " 'https://www.airbnb.com/rooms/6092049',\n",
       " 'https://www.airbnb.com/rooms/6103791',\n",
       " 'https://www.airbnb.com/rooms/6108439',\n",
       " 'https://www.airbnb.com/rooms/6117147',\n",
       " 'https://www.airbnb.com/rooms/6119086',\n",
       " 'https://www.airbnb.com/rooms/6120540',\n",
       " 'https://www.airbnb.com/rooms/6134800',\n",
       " 'https://www.airbnb.com/rooms/6145605',\n",
       " 'https://www.airbnb.com/rooms/6163821',\n",
       " 'https://www.airbnb.com/rooms/6188428',\n",
       " 'https://www.airbnb.com/rooms/6195258',\n",
       " 'https://www.airbnb.com/rooms/6224858',\n",
       " 'https://www.airbnb.com/rooms/6238514',\n",
       " 'https://www.airbnb.com/rooms/6245649',\n",
       " 'https://www.airbnb.com/rooms/6273036',\n",
       " 'https://www.airbnb.com/rooms/6316753',\n",
       " 'https://www.airbnb.com/rooms/6329340',\n",
       " 'https://www.airbnb.com/rooms/6329731',\n",
       " 'https://www.airbnb.com/rooms/6331695',\n",
       " 'https://www.airbnb.com/rooms/6335352',\n",
       " 'https://www.airbnb.com/rooms/6344096',\n",
       " 'https://www.airbnb.com/rooms/6348742',\n",
       " 'https://www.airbnb.com/rooms/6365956',\n",
       " 'https://www.airbnb.com/rooms/6374167',\n",
       " 'https://www.airbnb.com/rooms/6376338',\n",
       " 'https://www.airbnb.com/rooms/6423158',\n",
       " 'https://www.airbnb.com/rooms/6430646',\n",
       " 'https://www.airbnb.com/rooms/6453006',\n",
       " 'https://www.airbnb.com/rooms/6464280',\n",
       " 'https://www.airbnb.com/rooms/6494663',\n",
       " 'https://www.airbnb.com/rooms/6505426',\n",
       " 'https://www.airbnb.com/rooms/6512986',\n",
       " 'https://www.airbnb.com/rooms/6522477',\n",
       " 'https://www.airbnb.com/rooms/6523507',\n",
       " 'https://www.airbnb.com/rooms/6529234',\n",
       " 'https://www.airbnb.com/rooms/6552586',\n",
       " 'https://www.airbnb.com/rooms/6557736',\n",
       " 'https://www.airbnb.com/rooms/6587558',\n",
       " 'https://www.airbnb.com/rooms/6591405',\n",
       " 'https://www.airbnb.com/rooms/6600081',\n",
       " 'https://www.airbnb.com/rooms/6601749',\n",
       " 'https://www.airbnb.com/rooms/6609412',\n",
       " 'https://www.airbnb.com/rooms/6628985',\n",
       " 'https://www.airbnb.com/rooms/6629798',\n",
       " 'https://www.airbnb.com/rooms/6643496',\n",
       " 'https://www.airbnb.com/rooms/6648062',\n",
       " 'https://www.airbnb.com/rooms/6688004',\n",
       " 'https://www.airbnb.com/rooms/6691495',\n",
       " 'https://www.airbnb.com/rooms/6701045',\n",
       " 'https://www.airbnb.com/rooms/6727254',\n",
       " 'https://www.airbnb.com/rooms/6747672',\n",
       " 'https://www.airbnb.com/rooms/6748645',\n",
       " 'https://www.airbnb.com/rooms/6782479',\n",
       " 'https://www.airbnb.com/rooms/6793767',\n",
       " 'https://www.airbnb.com/rooms/6796392',\n",
       " 'https://www.airbnb.com/rooms/6798145',\n",
       " 'https://www.airbnb.com/rooms/6822070',\n",
       " 'https://www.airbnb.com/rooms/6835302',\n",
       " 'https://www.airbnb.com/rooms/6864929',\n",
       " 'https://www.airbnb.com/rooms/6870420',\n",
       " 'https://www.airbnb.com/rooms/6887081',\n",
       " 'https://www.airbnb.com/rooms/6934867',\n",
       " 'https://www.airbnb.com/rooms/6934874',\n",
       " 'https://www.airbnb.com/rooms/6936417',\n",
       " 'https://www.airbnb.com/rooms/6938818',\n",
       " 'https://www.airbnb.com/rooms/6940354',\n",
       " 'https://www.airbnb.com/rooms/6940448',\n",
       " 'https://www.airbnb.com/rooms/6957662',\n",
       " 'https://www.airbnb.com/rooms/6968158',\n",
       " 'https://www.airbnb.com/rooms/6970746',\n",
       " 'https://www.airbnb.com/rooms/6973383',\n",
       " 'https://www.airbnb.com/rooms/6974259',\n",
       " 'https://www.airbnb.com/rooms/6975064',\n",
       " 'https://www.airbnb.com/rooms/6985131',\n",
       " 'https://www.airbnb.com/rooms/7007759',\n",
       " 'https://www.airbnb.com/rooms/7009654',\n",
       " 'https://www.airbnb.com/rooms/7009791',\n",
       " 'https://www.airbnb.com/rooms/7009809',\n",
       " 'https://www.airbnb.com/rooms/7034114',\n",
       " 'https://www.airbnb.com/rooms/7035672',\n",
       " 'https://www.airbnb.com/rooms/7038488',\n",
       " 'https://www.airbnb.com/rooms/7054235',\n",
       " 'https://www.airbnb.com/rooms/7065335',\n",
       " 'https://www.airbnb.com/rooms/7065694',\n",
       " 'https://www.airbnb.com/rooms/7068804',\n",
       " 'https://www.airbnb.com/rooms/7093018',\n",
       " 'https://www.airbnb.com/rooms/7111861',\n",
       " 'https://www.airbnb.com/rooms/7140740',\n",
       " 'https://www.airbnb.com/rooms/7181279',\n",
       " 'https://www.airbnb.com/rooms/7182761',\n",
       " 'https://www.airbnb.com/rooms/7196412',\n",
       " 'https://www.airbnb.com/rooms/7227605',\n",
       " 'https://www.airbnb.com/rooms/7227910',\n",
       " 'https://www.airbnb.com/rooms/7228563',\n",
       " 'https://www.airbnb.com/rooms/7247351',\n",
       " 'https://www.airbnb.com/rooms/7259606',\n",
       " 'https://www.airbnb.com/rooms/7281346',\n",
       " 'https://www.airbnb.com/rooms/7292878',\n",
       " 'https://www.airbnb.com/rooms/7302136',\n",
       " 'https://www.airbnb.com/rooms/7323097',\n",
       " 'https://www.airbnb.com/rooms/7327920',\n",
       " 'https://www.airbnb.com/rooms/7341076',\n",
       " 'https://www.airbnb.com/rooms/7345468',\n",
       " 'https://www.airbnb.com/rooms/7348398',\n",
       " 'https://www.airbnb.com/rooms/7360699',\n",
       " 'https://www.airbnb.com/rooms/7386838',\n",
       " 'https://www.airbnb.com/rooms/7389541',\n",
       " 'https://www.airbnb.com/rooms/7402986',\n",
       " 'https://www.airbnb.com/rooms/7459197',\n",
       " 'https://www.airbnb.com/rooms/7478631',\n",
       " 'https://www.airbnb.com/rooms/7483031',\n",
       " 'https://www.airbnb.com/rooms/7493513',\n",
       " 'https://www.airbnb.com/rooms/7499793',\n",
       " 'https://www.airbnb.com/rooms/7514742',\n",
       " 'https://www.airbnb.com/rooms/7544803',\n",
       " 'https://www.airbnb.com/rooms/7549488',\n",
       " 'https://www.airbnb.com/rooms/7612118',\n",
       " 'https://www.airbnb.com/rooms/7618833',\n",
       " 'https://www.airbnb.com/rooms/7681228',\n",
       " 'https://www.airbnb.com/rooms/7696468',\n",
       " 'https://www.airbnb.com/rooms/7697503',\n",
       " 'https://www.airbnb.com/rooms/7699710',\n",
       " 'https://www.airbnb.com/rooms/7701360',\n",
       " 'https://www.airbnb.com/rooms/7726184',\n",
       " 'https://www.airbnb.com/rooms/7729217',\n",
       " 'https://www.airbnb.com/rooms/7810254',\n",
       " 'https://www.airbnb.com/rooms/7823272',\n",
       " 'https://www.airbnb.com/rooms/7840831',\n",
       " 'https://www.airbnb.com/rooms/7841744',\n",
       " 'https://www.airbnb.com/rooms/7856443',\n",
       " 'https://www.airbnb.com/rooms/7884875',\n",
       " 'https://www.airbnb.com/rooms/7886634',\n",
       " 'https://www.airbnb.com/rooms/7899085',\n",
       " 'https://www.airbnb.com/rooms/7902505',\n",
       " 'https://www.airbnb.com/rooms/7922690',\n",
       " 'https://www.airbnb.com/rooms/7923146',\n",
       " 'https://www.airbnb.com/rooms/7930461',\n",
       " 'https://www.airbnb.com/rooms/7933807',\n",
       " 'https://www.airbnb.com/rooms/7939511',\n",
       " 'https://www.airbnb.com/rooms/7949624',\n",
       " 'https://www.airbnb.com/rooms/7949668',\n",
       " 'https://www.airbnb.com/rooms/7950946',\n",
       " 'https://www.airbnb.com/rooms/7968598',\n",
       " 'https://www.airbnb.com/rooms/7968749',\n",
       " 'https://www.airbnb.com/rooms/7972067',\n",
       " 'https://www.airbnb.com/rooms/7975011',\n",
       " 'https://www.airbnb.com/rooms/7982082',\n",
       " 'https://www.airbnb.com/rooms/8018902',\n",
       " 'https://www.airbnb.com/rooms/8048653',\n",
       " 'https://www.airbnb.com/rooms/8049455',\n",
       " 'https://www.airbnb.com/rooms/8051735',\n",
       " 'https://www.airbnb.com/rooms/8053887',\n",
       " 'https://www.airbnb.com/rooms/8055632',\n",
       " 'https://www.airbnb.com/rooms/8085920',\n",
       " 'https://www.airbnb.com/rooms/8101619',\n",
       " 'https://www.airbnb.com/rooms/8102262',\n",
       " 'https://www.airbnb.com/rooms/8117174',\n",
       " 'https://www.airbnb.com/rooms/8125277',\n",
       " 'https://www.airbnb.com/rooms/8151772',\n",
       " 'https://www.airbnb.com/rooms/8151839',\n",
       " 'https://www.airbnb.com/rooms/8151907',\n",
       " 'https://www.airbnb.com/rooms/8151934',\n",
       " 'https://www.airbnb.com/rooms/8151985',\n",
       " 'https://www.airbnb.com/rooms/8152867',\n",
       " 'https://www.airbnb.com/rooms/8155586',\n",
       " 'https://www.airbnb.com/rooms/8167459',\n",
       " 'https://www.airbnb.com/rooms/8172628',\n",
       " 'https://www.airbnb.com/rooms/8187584',\n",
       " 'https://www.airbnb.com/rooms/8195090',\n",
       " 'https://www.airbnb.com/rooms/8195144',\n",
       " 'https://www.airbnb.com/rooms/8207665',\n",
       " 'https://www.airbnb.com/rooms/8209055',\n",
       " 'https://www.airbnb.com/rooms/8209591',\n",
       " 'https://www.airbnb.com/rooms/8221207',\n",
       " 'https://www.airbnb.com/rooms/8255072',\n",
       " 'https://www.airbnb.com/rooms/8272458',\n",
       " 'https://www.airbnb.com/rooms/8274904',\n",
       " 'https://www.airbnb.com/rooms/8275596',\n",
       " 'https://www.airbnb.com/rooms/8277718',\n",
       " 'https://www.airbnb.com/rooms/8336042',\n",
       " 'https://www.airbnb.com/rooms/8351923',\n",
       " 'https://www.airbnb.com/rooms/8352275',\n",
       " 'https://www.airbnb.com/rooms/8356380',\n",
       " 'https://www.airbnb.com/rooms/8382187',\n",
       " 'https://www.airbnb.com/rooms/8411606',\n",
       " 'https://www.airbnb.com/rooms/8441614',\n",
       " 'https://www.airbnb.com/rooms/8461190',\n",
       " 'https://www.airbnb.com/rooms/8464365',\n",
       " 'https://www.airbnb.com/rooms/8472927',\n",
       " 'https://www.airbnb.com/rooms/8474183',\n",
       " 'https://www.airbnb.com/rooms/8474452',\n",
       " 'https://www.airbnb.com/rooms/8487735',\n",
       " 'https://www.airbnb.com/rooms/8501670',\n",
       " 'https://www.airbnb.com/rooms/8520295',\n",
       " 'https://www.airbnb.com/rooms/8542873',\n",
       " 'https://www.airbnb.com/rooms/8568826',\n",
       " 'https://www.airbnb.com/rooms/8576907',\n",
       " 'https://www.airbnb.com/rooms/8590211',\n",
       " 'https://www.airbnb.com/rooms/8592609',\n",
       " 'https://www.airbnb.com/rooms/8595304',\n",
       " 'https://www.airbnb.com/rooms/8655125',\n",
       " 'https://www.airbnb.com/rooms/8717641',\n",
       " 'https://www.airbnb.com/rooms/8722927',\n",
       " 'https://www.airbnb.com/rooms/8733261',\n",
       " 'https://www.airbnb.com/rooms/8817059',\n",
       " 'https://www.airbnb.com/rooms/8848449',\n",
       " 'https://www.airbnb.com/rooms/8859249',\n",
       " 'https://www.airbnb.com/rooms/8864274',\n",
       " 'https://www.airbnb.com/rooms/8869066',\n",
       " 'https://www.airbnb.com/rooms/8889145',\n",
       " 'https://www.airbnb.com/rooms/8941317',\n",
       " 'https://www.airbnb.com/rooms/8943055',\n",
       " 'https://www.airbnb.com/rooms/8974563',\n",
       " 'https://www.airbnb.com/rooms/8987674',\n",
       " 'https://www.airbnb.com/rooms/9051457',\n",
       " 'https://www.airbnb.com/rooms/9075976',\n",
       " 'https://www.airbnb.com/rooms/9108108',\n",
       " 'https://www.airbnb.com/rooms/9110032',\n",
       " 'https://www.airbnb.com/rooms/9110654',\n",
       " 'https://www.airbnb.com/rooms/9110718',\n",
       " 'https://www.airbnb.com/rooms/9118962',\n",
       " 'https://www.airbnb.com/rooms/9119210',\n",
       " 'https://www.airbnb.com/rooms/9130888',\n",
       " 'https://www.airbnb.com/rooms/9150423',\n",
       " 'https://www.airbnb.com/rooms/9150562',\n",
       " 'https://www.airbnb.com/rooms/9188845',\n",
       " 'https://www.airbnb.com/rooms/9242011',\n",
       " 'https://www.airbnb.com/rooms/9259176',\n",
       " 'https://www.airbnb.com/rooms/9261548',\n",
       " 'https://www.airbnb.com/rooms/9280940',\n",
       " 'https://www.airbnb.com/rooms/9296524',\n",
       " 'https://www.airbnb.com/rooms/9298491',\n",
       " 'https://www.airbnb.com/rooms/9309449',\n",
       " 'https://www.airbnb.com/rooms/9346814',\n",
       " 'https://www.airbnb.com/rooms/9347891',\n",
       " 'https://www.airbnb.com/rooms/9416254',\n",
       " 'https://www.airbnb.com/rooms/9431997',\n",
       " 'https://www.airbnb.com/rooms/9435665',\n",
       " 'https://www.airbnb.com/rooms/9440164',\n",
       " 'https://www.airbnb.com/rooms/9462355',\n",
       " 'https://www.airbnb.com/rooms/9463113',\n",
       " 'https://www.airbnb.com/rooms/9464763',\n",
       " 'https://www.airbnb.com/rooms/9465008',\n",
       " 'https://www.airbnb.com/rooms/9471416',\n",
       " 'https://www.airbnb.com/rooms/9476010',\n",
       " 'https://www.airbnb.com/rooms/9476849',\n",
       " 'https://www.airbnb.com/rooms/9477823',\n",
       " 'https://www.airbnb.com/rooms/9489347',\n",
       " 'https://www.airbnb.com/rooms/9491760',\n",
       " 'https://www.airbnb.com/rooms/9525734',\n",
       " 'https://www.airbnb.com/rooms/9587361',\n",
       " 'https://www.airbnb.com/rooms/9611854',\n",
       " 'https://www.airbnb.com/rooms/9652136',\n",
       " 'https://www.airbnb.com/rooms/9695480',\n",
       " 'https://www.airbnb.com/rooms/9717679',\n",
       " 'https://www.airbnb.com/rooms/9735841',\n",
       " 'https://www.airbnb.com/rooms/9752333',\n",
       " 'https://www.airbnb.com/rooms/9752553',\n",
       " 'https://www.airbnb.com/rooms/9760014',\n",
       " 'https://www.airbnb.com/rooms/9792467',\n",
       " 'https://www.airbnb.com/rooms/9837993',\n",
       " 'https://www.airbnb.com/rooms/9844630',\n",
       " 'https://www.airbnb.com/rooms/9905129',\n",
       " 'https://www.airbnb.com/rooms/9926871',\n",
       " 'https://www.airbnb.com/rooms/9945149',\n",
       " 'https://www.airbnb.com/rooms/9972077',\n",
       " 'https://www.airbnb.com/rooms/9974744',\n",
       " 'https://www.airbnb.com/rooms/9990865',\n",
       " 'https://www.airbnb.com/rooms/9995426',\n",
       " 'https://www.airbnb.com/rooms/9996121',\n",
       " 'https://www.airbnb.com/rooms/9998508',\n",
       " 'https://www.airbnb.com/rooms/9998879',\n",
       " 'https://www.airbnb.com/rooms/10000431',\n",
       " 'https://www.airbnb.com/rooms/10000523',\n",
       " 'https://www.airbnb.com/rooms/10023678',\n",
       " 'https://www.airbnb.com/rooms/10137578',\n",
       " 'https://www.airbnb.com/rooms/10187948',\n",
       " 'https://www.airbnb.com/rooms/10193457',\n",
       " 'https://www.airbnb.com/rooms/10227655',\n",
       " 'https://www.airbnb.com/rooms/10273567',\n",
       " 'https://www.airbnb.com/rooms/10280888',\n",
       " 'https://www.airbnb.com/rooms/10315192',\n",
       " 'https://www.airbnb.com/rooms/10321776',\n",
       " 'https://www.airbnb.com/rooms/10333567',\n",
       " 'https://www.airbnb.com/rooms/10347570',\n",
       " 'https://www.airbnb.com/rooms/10362654',\n",
       " 'https://www.airbnb.com/rooms/10367010',\n",
       " 'https://www.airbnb.com/rooms/10369307',\n",
       " 'https://www.airbnb.com/rooms/10379560',\n",
       " 'https://www.airbnb.com/rooms/10379822',\n",
       " 'https://www.airbnb.com/rooms/10385321',\n",
       " 'https://www.airbnb.com/rooms/10409218',\n",
       " 'https://www.airbnb.com/rooms/10410858',\n",
       " 'https://www.airbnb.com/rooms/10418322',\n",
       " 'https://www.airbnb.com/rooms/10431578',\n",
       " 'https://www.airbnb.com/rooms/10454172',\n",
       " 'https://www.airbnb.com/rooms/10454632',\n",
       " 'https://www.airbnb.com/rooms/10455995',\n",
       " 'https://www.airbnb.com/rooms/10458279',\n",
       " 'https://www.airbnb.com/rooms/10469182',\n",
       " 'https://www.airbnb.com/rooms/10477793',\n",
       " 'https://www.airbnb.com/rooms/10502323',\n",
       " 'https://www.airbnb.com/rooms/10517693',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from ipynb.fs.full.my_functions import getAllAirbnbInCityThatAreNotNoisy\n",
    "\n",
    "import ipynb\n",
    "\n",
    "from ipynb.fs.defs.geospatial import getAllAirbnbInCityThatAreNotNoisy\n",
    "\n",
    "getAllAirbnbInCityThatAreNotNoisy()\n",
    "#mental model for building application\n",
    "#make 5 jupyter notebooks -> add like 100 functions that are cool\n",
    "#in english notebook -> call jupyternotebook functions \n",
    "#in english notebook -> call javascript UI components which call jupyter notebook functions \n",
    "#TODO - use codellama to generate and add functions to javascript UI + jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "402e9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rpc import crossReferenceAirbnb\n",
    "\n",
    "crossReferenceAirbnb(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8172a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get all tweets that have pizza\n",
    "order a pizza from instacart \n",
    "book flights to the pizzaria \n",
    "find all airbns that are close to the basketball stadium and have noise issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d413179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet bitsandbytes\n",
    "!pip install --quiet transformers \n",
    "!pip install --quiet accelerate\n",
    "!pip install scipy numpy\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    \n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "base_model_path=\"./huggingface/llama7B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.float16)\n",
    "\n",
    "#Save the model and the tokenizer to your PC\n",
    "model.save_pretrained(base_model_path, from_pt=True) \n",
    "tokenizer.save_pretrained(base_model_path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84f612d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencodings.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "json.load(open('encodings.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea8fc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = getEncodings(sentences)\n",
    "str(encodings[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4126e929",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(program_generator_cache, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodings.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m: program_generator_cache[encodings]}\n\u001b[0;32m---> 40\u001b[0m [getProgram(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n",
      "Cell \u001b[0;32mIn[88], line 40\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(program_generator_cache, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodings.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m: program_generator_cache[encodings]}\n\u001b[0;32m---> 40\u001b[0m [\u001b[43mgetProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n",
      "Cell \u001b[0;32mIn[88], line 37\u001b[0m, in \u001b[0;36mgetProgram\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encodings \u001b[38;5;129;01min\u001b[39;00m program_generator_cache: \u001b[38;5;28;01mreturn\u001b[39;00m program_generator_cache[encodings]\n\u001b[1;32m     36\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(program_generator_cache, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodings.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mprogram_generator_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencodings\u001b[49m\u001b[43m]\u001b[49m}\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "##have to go downstirs\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def getEncodings(sentences):\n",
    "    return model.encode(sentences, convert_to_tensor=True, device='cpu')\n",
    "\n",
    "\n",
    "import json \n",
    "\n",
    "sentences = [\"get all tweets that mention pizza if geolocation\",\n",
    " \n",
    " \"get all football games next year\",\n",
    " \n",
    " \"order flights for each one\",\n",
    " \n",
    " \"get all twitch comments\",\n",
    " \n",
    " \"cluster twitch comments into groups\",\n",
    "]\n",
    "\n",
    "def getPairs(documentOne, documentTwo):\n",
    "    pairs = []\n",
    "    cosine_scores = util.cos_sim(rhe[:664], pge)\n",
    "    for i in range(len(cosine_scores)-1):\n",
    "        for j in range(i+1, len(cosine_scores)):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})  \n",
    "#getPairs(encodings, )\n",
    "\n",
    "\n",
    "\n",
    "#keyed by encoding\n",
    "def getProgram(sentence, program, type):\n",
    "    encoding = getEncodings(sentence)\n",
    "    key = str(encoding[0].tolist())\n",
    "    program_generator_cache = json.load(open('encodings.json', 'r'))\n",
    "    if encodings in program_generator_cache: return program_generator_cache[encodings]\n",
    "    program_generator_cache[key] = program\n",
    "    #if cannot find hand written version -> generate one using codeLlama\n",
    "    #eventually -> decompose and generate smaller functions into larger ones that do what users want\n",
    "    json.dump(program_generator_cache, open('encodings.json', 'w'))\n",
    "    return {'fn': program_generator_cache[encodings]}\n",
    "\n",
    "#get all airbnbs + cross reference with 311 - currently impossible without coding in python \n",
    "#write program by hand\n",
    "#describe what it does\n",
    "#send description to encoder \n",
    "#use encoding to fetch program from database \n",
    "#then you can use this to finetune the program.\n",
    "[getProgram(sentence) for sentence in sentences]\n",
    "#write file to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f88af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'const puppeteer = require(\\'puppeteer\\');\\n\\n(async () => {\\n  // Launch a headless browser\\n  const browser = await puppeteer.launch({ headless: true });\\n  const page = await browser.newPage();\\n\\n  // Navigate to Twitter\\'s search page for \"pizza\"\\n  await page.goto(\\'https://twitter.com/search?q=pizza%20until%3A2023-09-06%20since%3A2023-09-05&src=typed_query\\');\\n\\n  // Wait for the tweets to load\\n  await page.waitForSelector(\\'article\\');\\n\\n  // Extract tweet information\\n  const tweets = await page.evaluate(() => {\\n    const tweetNodes = document.querySelectorAll(\\'article\\');\\n    const data = [];\\n\\n    tweetNodes.forEach((tweet) => {\\n      try {\\n        const tweetText = tweet.querySelector(\\'div[lang]\\').innerText;\\n        const tweetAuthor = tweet.querySelector(\\'div span span\\').innerText;\\n        data.push({ tweetText, tweetAuthor });\\n      } catch (e) {\\n        console.error(e);\\n      }\\n    });\\n\\n    return data;\\n  });\\n\\n  // Output the scraped tweets\\n  console.log(tweets);\\n\\n  await browser.close();\\n})();\\n\\n// use an encoding\\n//convert sentence to a matrix 538\\n//match with previously made code -> hand written or custom -> periodically look at custon generated code and clean-up improve and send back to algorithm\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('./fetchTwitter.js').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "db62cd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'12312323123': 'function () {}'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open('encodings.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c87da7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of './huggingface/llama7B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './huggingface/llama7B' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py:675\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:428\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './huggingface/llama7B'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  LlamaForCausalLM, LlamaTokenizer, pipeline\n\u001b[1;32m      3\u001b[0m base_model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./huggingface/llama7B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39mLlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py:2449\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2448\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2449\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2460\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_auto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_auto_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2461\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2465\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py:591\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 591\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    593\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    596\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py:620\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    622\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py:696\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    697\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the configuration of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    698\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of './huggingface/llama7B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './huggingface/llama7B' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import  LlamaForCausalLM, LlamaTokenizer, pipeline\n",
    "\n",
    "base_model_path=\"./huggingface/llama7B\"\n",
    "model = LlamaForCausalLM.from_pretrained(base_model_path)\n",
    "tokenizer =LlamaTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "base_model_path=\"./huggingface/llama7B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.float16)\n",
    "\n",
    "#Save the model and the tokenizer to your PC\n",
    "model.save_pretrained(base_model_path, from_pt=True) \n",
    "tokenizer.save_pretrained(base_model_path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1c514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6472f6615a854f8f826f71bc89ffe1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model = \"codellama/CodeLlama-7b-Instruct-hf\" #\"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "sequences = pipe(\n",
    "    'I liked \"Maneskin\" and \"Pink Floyd\". Do you have any recommendations of other groups I might like?\\n',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, token='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')\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07735c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up inference via HuggingFace\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"codellama/CodeLlama-7b-Instruct-hf\" #\"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "def sample_model(prompt):\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=1028,\n",
    "    )\n",
    "    return sequences[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# Hugging face repo name\n",
    "model = \"codellama/CodeLlama-7b-Instruct-hf\" #chat-hf (hugging face wrapper version)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" # if you have GPU\n",
    ")\n",
    "\n",
    "sequences = pipeline(\n",
    "    'write the fibonacci program',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    top_p = 0.9,\n",
    "    temperature = 0.2,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200, # can increase the length of sequence\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigcode/starcoder\"\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "inputs = tokenizer.encode(\"def print_hello_world():\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "sequences = pipeline(\n",
    "    'import socket\\n\\ndef ping_exponential_backoff(host: str):',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "from human_eval.data import write_jsonl, read_problems\n",
    "from tqdm import tqdm\n",
    "\n",
    "# initialize the model\n",
    "\n",
    "model_path = \"Phind/Phind-CodeLlama-34B-v1\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# HumanEval helper\n",
    "\n",
    "def generate_one_completion(prompt: str):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "\n",
    "    # Generate\n",
    "    generate_ids = model.generate(inputs.input_ids.to(\"cuda\"), max_new_tokens=256, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\n",
    "    completion = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    completion = completion.replace(prompt, \"\").split(\"\\n\\n\\n\")[0]\n",
    "\n",
    "    return completion\n",
    "\n",
    "# perform HumanEval\n",
    "problems = read_problems()\n",
    "\n",
    "num_samples_per_task = 1\n",
    "samples = [\n",
    "    dict(task_id=task_id, completion=generate_one_completion(problems[task_id][\"prompt\"]))\n",
    "    for task_id in tqdm(problems)\n",
    "    for _ in range(num_samples_per_task)\n",
    "]\n",
    "write_jsonl(\"samples.jsonl\", samples)\n",
    "\n",
    "# run `evaluate_functional_correctness samples.jsonl` in your HumanEval code sandbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03968c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"codellama/CodeLlama-34b-Instruct-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "sequences = pipeline(\n",
    "    'import socket\\n\\ndef ping_exponential_backoff(host: str):',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9f096e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tokenizer class CodeLlamaTokenizer does not exist or is not currently imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodellama/CodeLlama-13b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     12\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m sequences \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport socket\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdef ping_exponential_backoff(host: str):\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:724\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m         tokenizer_class \u001b[38;5;241m=\u001b[39m tokenizer_class_from_name(tokenizer_class_candidate)\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 724\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    725\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Tokenizer class CodeLlamaTokenizer does not exist or is not currently imported."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"codellama/CodeLlama-13b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "sequences = pipeline(\n",
    "    'import socket\\n\\ndef ping_exponential_backoff(host: str):',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1248189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve singleplayer \n",
    "\n",
    "#1. travel planning\n",
    "#2. collaboratively planning a garden with custom ferns - display an actual fasta, sgrna, pdbs and a ship to lab button based on an addres -> ask for address -> 200 lines of code away \n",
    "#3. literate programming for excel - write to an excel -> make a cool pattern like /r/place\n",
    "#4. assist with building communities -> automate repetitive tasks ->\n",
    "#5. assist with planning projects -> when code gets checked into github -> \n",
    "#6. teach people to code and have more fun learning math -> see the entire process can be used to do cool stuff -> trig -> hundred triangles becoming an origami crane\n",
    "#7. [check] make a gant chart for cooking dinner -> snickerdoodles\n",
    "\n",
    "0. make my robot clean my house every 3 days \n",
    "1. order these groceries every 3 days -> trader joes \n",
    "\n",
    "\n",
    "2. after an event -> write a 3 page article of everything you experienced and what questions you had \n",
    "-> write queries about text that transform the text into something that has an intersection with other peoples notes on the same event and then bundle and document everyones experience\n",
    "\n",
    "today i went to a concert, it was cool. my favorite part was the 2nd song\n",
    "my favorite part was the lights\n",
    "half users favorite was lights, half was 2nd song and half was unknown.\n",
    "\n",
    "\n",
    "\n",
    "#find intersection of two documents \n",
    "\n",
    "#encoding = 500 dimension that has no real meaning -> just used for statistical correlation within document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e38309",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#copy(Array.from(document.querySelectorAll()).map(el => el.textContent))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(soup)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mgetText\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m, in \u001b[0;36mgetText\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetText\u001b[39m(url):\n\u001b[0;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get the webpage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "url = 'https://www.twitch.tv/cohhcarnage'\n",
    "\n",
    "def getText(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to get the webpage\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    chat = soup.find_all('.chat-line__message')\n",
    "    #copy(Array.from(document.querySelectorAll()).map(el => el.textContent))\n",
    "    print(soup)\n",
    "getText(url)\n",
    "\n",
    "\n",
    "\n",
    "#make a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e07f160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#! pip install requests beautifulsoup4\n",
    "\n",
    "url = 'https://arxiv.org/list?archive=astro-ph&year=23&month=all&submit=Go'\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_arxiv():\n",
    "    response = requests.get(url)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to get the webpage\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #print(response.text)\n",
    "    links = []\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        #link = a_tag.get('href', None)\n",
    "        #print(a_tag)\n",
    "        if a_tag.get('title') == 'Download PDF':\n",
    "            links.append('https://arxiv.org' + a_tag.get('href'))\n",
    "            \n",
    "    return links\n",
    "\n",
    "def getText(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to get the webpage\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    body = soup.find('body')\n",
    "    \n",
    "    if body:\n",
    "        return body.get_text()\n",
    "\n",
    "\n",
    "article_links = scrape_paul_graham_articles()\n",
    "\n",
    "import json\n",
    "# with open('all_pg.txt', 'w') as file :\n",
    "#     json.dump([getText(link) for link in article_links], file)\n",
    "    \n",
    "    \n",
    "#json.dump(scrape_arxiv(), 'arxiv.json')\n",
    "arxiv = scrape_arxiv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8a4a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/pdf/2301.00010',\n",
       " 'https://arxiv.org/pdf/2301.00017',\n",
       " 'https://arxiv.org/pdf/2301.00022',\n",
       " 'https://arxiv.org/pdf/2301.00024',\n",
       " 'https://arxiv.org/pdf/2301.00027',\n",
       " 'https://arxiv.org/pdf/2301.00043',\n",
       " 'https://arxiv.org/pdf/2301.00056',\n",
       " 'https://arxiv.org/pdf/2301.00064',\n",
       " 'https://arxiv.org/pdf/2301.00113',\n",
       " 'https://arxiv.org/pdf/2301.00144',\n",
       " 'https://arxiv.org/pdf/2301.00172',\n",
       " 'https://arxiv.org/pdf/2301.00203',\n",
       " 'https://arxiv.org/pdf/2301.00223',\n",
       " 'https://arxiv.org/pdf/2301.00229',\n",
       " 'https://arxiv.org/pdf/2301.00259',\n",
       " 'https://arxiv.org/pdf/2301.00293',\n",
       " 'https://arxiv.org/pdf/2301.00313',\n",
       " 'https://arxiv.org/pdf/2301.00338',\n",
       " 'https://arxiv.org/pdf/2301.00347',\n",
       " 'https://arxiv.org/pdf/2301.00359',\n",
       " 'https://arxiv.org/pdf/2301.00373',\n",
       " 'https://arxiv.org/pdf/2301.00415',\n",
       " 'https://arxiv.org/pdf/2301.00450',\n",
       " 'https://arxiv.org/pdf/2301.00481',\n",
       " 'https://arxiv.org/pdf/2301.00490']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7ce441e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'entries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m jupyter_functions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairbnb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      2\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoll\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      3\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplant-trees\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfind places to plant trees nearby 20418 autumn shore drive\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#on client if colon -> substitute on client \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#search, encodings + similarity + who knows\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mjupyter_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentries\u001b[49m():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(v)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'entries'"
     ]
    }
   ],
   "source": [
    "jupyter_functions = {'airbnb': 1, \n",
    "                     'poll': 2,\n",
    "                     'plant-trees': 'find places to plant trees nearby 20418 autumn shore drive'\n",
    "}\n",
    "\n",
    "#on client if colon -> substitute on client \n",
    "\n",
    "\n",
    "    #search, encodings + similarity + who knows\n",
    "for k, v in jupyter_functions.entries():\n",
    "    if k in name:\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d5f4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "#for link in arxiv\n",
    "\n",
    "def getPdfContent(link):\n",
    "    papers = []\n",
    "    with pdfplumber.open(link) as pdf:\n",
    "        # Loop through each page\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            papers.append(text)\n",
    "            print(f'Content from page {i + 1}:\\n{text}')\n",
    "    return papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e09609f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2301.00010\n",
      "https://arxiv.org/pdf/2301.00017\n",
      "https://arxiv.org/pdf/2301.00022\n",
      "https://arxiv.org/pdf/2301.00024\n",
      "https://arxiv.org/pdf/2301.00027\n",
      "https://arxiv.org/pdf/2301.00043\n",
      "https://arxiv.org/pdf/2301.00056\n",
      "https://arxiv.org/pdf/2301.00064\n",
      "https://arxiv.org/pdf/2301.00113\n",
      "https://arxiv.org/pdf/2301.00144\n",
      "https://arxiv.org/pdf/2301.00172\n",
      "https://arxiv.org/pdf/2301.00203\n",
      "https://arxiv.org/pdf/2301.00223\n",
      "https://arxiv.org/pdf/2301.00229\n",
      "https://arxiv.org/pdf/2301.00259\n",
      "https://arxiv.org/pdf/2301.00293\n",
      "https://arxiv.org/pdf/2301.00313\n",
      "https://arxiv.org/pdf/2301.00338\n",
      "https://arxiv.org/pdf/2301.00347\n",
      "https://arxiv.org/pdf/2301.00359\n",
      "https://arxiv.org/pdf/2301.00373\n",
      "https://arxiv.org/pdf/2301.00415\n",
      "https://arxiv.org/pdf/2301.00450\n",
      "https://arxiv.org/pdf/2301.00481\n",
      "https://arxiv.org/pdf/2301.00490\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "files = []\n",
    "for idx, i in enumerate(arxiv):\n",
    "\n",
    "    print(i)\n",
    "    # URL of the PDF file\n",
    "    url = i\n",
    "\n",
    "    # Make a GET request to fetch the raw HTML content\n",
    "  \n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the PDF\n",
    "        url = f\"downloaded_file_{idx}.pdf\"\n",
    "        files.append(url)\n",
    "        with open(url, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download the PDF, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode()\n",
    "#given 10,000 papers\n",
    "#find links that are rising fastest -> date cited, get time series of date cited by month -> \n",
    "#citations_per_month = [0,0,0,1,2,4,11,24,32,64]\n",
    "#find link that could be really good but arent cited highly for some reason -> not general enough\n",
    "#thats why most people read papers \n",
    "#find any sentences that are in all of them.\n",
    "#given 30,000 papers a year -> automatically identify papers that might be highly cited before they do \n",
    "#without looking at the author -> look at their citations -> are they thoughtful and well chosen -> \n",
    "#50% of papers are not kept in the canon -> how to predict whether its thrown out or becomes highly citen\n",
    "#0 = thrown out - \n",
    "#1 = kept -\n",
    "#2 = highly cited -\n",
    "#have to match most cited papers -> find some numerical measure of quality \n",
    "#measure citations of their citations\n",
    "#NumCitationsOfReferences = papers with most citations of their references = good or bad ? \n",
    "#predicted_cool = make a dataset of 0,1,2\n",
    "#try to find statistical relevance between \n",
    "#does NumCitationsOfReferences predict numCool\n",
    "def GetMetaAnalysisAboutPapers(text):\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    # Find URLs in the text\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    citations = [getText(url) for url in urls]\n",
    "    return citations\n",
    "    timeSeries = {}\n",
    "    for citation in citations:\n",
    "        timeSeries[citation] = [0,0,0,0,0,0,0]\n",
    "        #get rate of change in citations -> get max rate of change 0\n",
    "    \n",
    "    return timeSeries\n",
    "    #get all citations \n",
    "    #get all links\n",
    "    #get a timseries for each link\n",
    "    #predict 2 and 1\n",
    "\n",
    "def findPapersThatAreGoodQualityButNotHighlyCited():\n",
    "    return 123\n",
    "    \n",
    "    \n",
    "#this predicts numCool\n",
    "def findReferencesThatAreRisingFastest():\n",
    "    #for each reference, get a time series\n",
    "    #for each time series, get the maximum change in a 3 month window\n",
    "    #identify top 10% of maximum changes\n",
    "    #lookup all citations \n",
    "    \n",
    "    \n",
    "    return {referenceTitle: timeSeries }\n",
    "    \n",
    "\n",
    "def findIntersection():\n",
    "    return 'pairwise similarity of all sentences in all documents '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 working demos - today\n",
    "#person writes sentence\n",
    "#sentence is matched w/ function\n",
    "#function has one parameter -> function\n",
    "#each function just has to be written with a specifc usecase and sentence in mind \n",
    "#once you have 100 of these, generaet 10,000 -> idea \n",
    "#each sentence builds a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "14c616cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./downloaded_file_7.pdf',\n",
       " './downloaded_file_14.pdf',\n",
       " './downloaded_file_15.pdf',\n",
       " './downloaded_file_6.pdf',\n",
       " './downloaded_file_4.pdf',\n",
       " './downloaded_file_17.pdf',\n",
       " './downloaded_file_16.pdf',\n",
       " './downloaded_file_5.pdf',\n",
       " './downloaded_file_12.pdf',\n",
       " './downloaded_file_1.pdf',\n",
       " './downloaded_file_0.pdf',\n",
       " './downloaded_file_13.pdf',\n",
       " './downloaded_file_11.pdf',\n",
       " './downloaded_file_2.pdf',\n",
       " './downloaded_file_3.pdf',\n",
       " './downloaded_file_10.pdf',\n",
       " './somefile.pdf',\n",
       " './downloaded_file_21.pdf',\n",
       " './downloaded_file_20.pdf',\n",
       " './downloaded_file_22.pdf',\n",
       " './downloaded_file_23.pdf',\n",
       " './downloaded_file_8.pdf',\n",
       " './downloaded_file_9.pdf',\n",
       " './downloaded_file_24.pdf',\n",
       " './downloaded_file_18.pdf',\n",
       " './downloaded_file_19.pdf']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#given 3 ingredients -> lookup all possible foods\n",
    "#given 3 ingredients -> create impossible foods \n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7061326",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdfplumber\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open the PDF file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexample.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Loop through each page\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf\u001b[38;5;241m.\u001b[39mpages):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Extract text from the page\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdfplumber/pdf.py:84\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, repair)\u001b[0m\n\u001b[1;32m     82\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m---> 84\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example.pdf'"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "# Open the PDF file\n",
    "import glob\n",
    "def getAllArxiv():\n",
    "    fileList = glob.glob('./*.pdf')\n",
    "    with pdfplumber.open(fileList) as pdf:\n",
    "        # Loop through each page\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "\n",
    "            print(f'Content from page {i + 1}:\\n{text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyPDF2\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "# Open the PDF file\n",
    "with open('example.pdf', 'rb') as file:\n",
    "    # Initialize a PDF reader object\n",
    "    reader = PyPDF2.PdfFileReader(file)\n",
    "    \n",
    "    # Loop through each page\n",
    "    for i in range(reader.getNumPages()):\n",
    "        # Get the page\n",
    "        page = reader.getPage(i)\n",
    "        \n",
    "        # Extract text from the page\n",
    "        text = page.extractText()\n",
    "        \n",
    "        print(f'Content from page {i + 1}:\\n{text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8772e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./database.txt') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1fe4299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: openai in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (0.27.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence-transformers in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/83/8d/f65f8138365462ace54458a9e164f4b28ce1141361970190eef36bdef986/transformers-4.32.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl.metadata (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: torchvision in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: fsspec in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
      "Requirement already satisfied: click in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Using cached torch-2.0.0-cp39-none-macosx_10_9_x86_64.whl (139.8 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: sympy in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "Installing collected packages: tokenizers, torch, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.9.4\n",
      "    Uninstalling tokenizers-0.9.4:\n",
      "      Successfully uninstalled tokenizers-0.9.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.2.2\n",
      "    Uninstalling transformers-4.2.2:\n",
      "      Successfully uninstalled transformers-4.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openai-whisper 20230314 requires numba, which is not installed.\n",
      "point-e 0.0.0 requires matplotlib, which is not installed.\n",
      "point-e 0.0.0 requires scikit-image, which is not installed.\n",
      "allennlp 1.5.0 requires torch<1.8.0,>=1.6.0, but you have torch 2.0.0 which is incompatible.\n",
      "allennlp 1.5.0 requires transformers<4.3,>=4.1, but you have transformers 4.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.13.3 torch-2.0.0 transformers-4.32.1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: WiktionaryParser in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (0.0.97)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from WiktionaryParser) (4.12.2)\n",
      "Requirement already satisfied: requests in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from WiktionaryParser) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->WiktionaryParser) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->WiktionaryParser) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->WiktionaryParser) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->WiktionaryParser) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->WiktionaryParser) (2023.7.22)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.65.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting faster-whisper\n",
      "  Obtaining dependency information for faster-whisper from https://files.pythonhosted.org/packages/5d/ef/a6afc7bcfec7bf7e647e315813c898ce031a3bb3a5baaac3a3bf7d9ecf7b/faster_whisper-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading faster_whisper-0.7.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting av==10.* (from faster-whisper)\n",
      "  Downloading av-10.0.0-cp39-cp39-macosx_10_9_x86_64.whl (26.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ctranslate2<4,>=3.17 (from faster-whisper)\n",
      "  Obtaining dependency information for ctranslate2<4,>=3.17 from https://files.pythonhosted.org/packages/58/97/e1e10bd003ab19b4b104849e18bbb5adcff42ad6e2618d616456a5902d90/ctranslate2-3.19.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading ctranslate2-3.19.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from faster-whisper) (0.16.4)\n",
      "Requirement already satisfied: tokenizers==0.13.* in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from faster-whisper) (0.13.3)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
      "  Obtaining dependency information for onnxruntime<2,>=1.14 from https://files.pythonhosted.org/packages/a5/95/cccadd11fb503f51743dc12705ff38a1a2990600c0bdcf2758011800e081/onnxruntime-1.15.1-cp39-cp39-macosx_10_15_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp39-cp39-macosx_10_15_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from ctranslate2<4,>=3.17->faster-whisper) (1.25.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from ctranslate2<4,>=3.17->faster-whisper) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.0.12)\n",
      "Requirement already satisfied: fsspec in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13->faster-whisper) (23.0)\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.23.4)\n",
      "Requirement already satisfied: sympy in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Downloading faster_whisper-0.7.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading ctranslate2-3.19.0-cp39-cp39-macosx_10_9_x86_64.whl (14.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.15.1-cp39-cp39-macosx_10_15_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: flatbuffers, av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
      "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.19.0 faster-whisper-0.7.1 flatbuffers-23.5.26 humanfriendly-10.0 onnxruntime-1.15.1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pronouncing in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from pronouncing) (1.0.13)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from cmudict>=0.4.0->pronouncing) (5.2.0)\n",
      "Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from cmudict>=0.4.0->pronouncing) (5.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/adnanwahab/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata<6.0.0,>=5.1.0->cmudict>=0.4.0->pronouncing) (3.11.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/whisper/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_audio, log_mel_spectrogram, pad_or_trim\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecodingOptions, DecodingResult, decode, detect_language\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelDimensions, Whisper\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranscribe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transcribe\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/whisper/model.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode \u001b[38;5;28;01mas\u001b[39;00m decode_function\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect_language \u001b[38;5;28;01mas\u001b[39;00m detect_language_function\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranscribe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transcribe \u001b[38;5;28;01mas\u001b[39;00m transcribe_function\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelDimensions\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     n_mels: \u001b[38;5;28mint\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/whisper/transcribe.py:20\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     FRAMES_PER_SECOND,\n\u001b[1;32m     12\u001b[0m     HOP_LENGTH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     pad_or_trim,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecodingOptions, DecodingResult\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtiming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_word_timestamps\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGUAGES, TO_LANGUAGE_CODE, get_tokenizer\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     exact_div,\n\u001b[1;32m     24\u001b[0m     format_timestamp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     str2bool,\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/whisper/timing.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, List\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install sentence-transformers\n",
    "! pip install datasets \n",
    "! pip install WiktionaryParser\n",
    "! pip install transformers\n",
    "!pip install faster-whisper\n",
    "\n",
    "!pip install pronouncing\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import time\n",
    "import transformers\n",
    "import os \n",
    "import whisper\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoplayback = '../data_sets/' + 'output.mp3'\n",
    "\n",
    "# model = whisper.load_model(\"base\")\n",
    "\n",
    "# # load audio and pad/trim it to fit 30 seconds\n",
    "# audio = whisper.load_audio(videoplayback)\n",
    "# #audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# # make log-Mel spectrogram and move to the same device as the model\n",
    "# mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# # detect the spoken language\n",
    "# _, probs = model.detect_language(mel)\n",
    "# print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# # decode the audio\n",
    "# options = whisper.DecodingOptions(fp16=False)\n",
    "# result = whisper.decode(model, mel, options)\n",
    "\n",
    "# # print the recognized text\n",
    "# print(result.text)\n",
    "# from faster_whisper import WhisperModel\n",
    "\n",
    "# model_size = \"large-v2\"\n",
    "\n",
    "# # Run on GPU with FP16\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# # or run on GPU with INT8\n",
    "# # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# # or run on CPU with INT8\n",
    "# # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "# segments, info = model.transcribe(videoplayback, beam_size=5)\n",
    "\n",
    "# print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "# for segment in segments:\n",
    "#     print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "#https://github.com/guillaumekln/faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cafe032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarity(sentences):\n",
    "    corpus_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    #print(corpus_embeddings, sentences)\n",
    "    clusters = util.community_detection(corpus_embeddings, min_community_size=2, threshold=0.55)\n",
    "    def process(item): return [sentences[i] for i in item]\n",
    "    result = [process(item) for item in clusters ]\n",
    "    # print(clusters)\n",
    "    print('result,result,result',result)\n",
    "    return result\n",
    "random.shuffle(getSimilarity(stream_comments))\n",
    "#if @ -> reply https://www.promptingguide.ai/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f16b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = []\n",
    "# with open('./archive/test_Arabic_tweets_negative_20190413.tsv') as f:\n",
    "#     for line in f:\n",
    "#         lines.append(line.split('\\t')[1])\n",
    "\n",
    "# openai.api_key = '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'\n",
    "# len(lines)\n",
    "\n",
    "# def translate_text(text, source_language, target_language):\n",
    "#     print('translating ' + text)\n",
    "#     prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n",
    "#     first = time.perf_counter()\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         max_tokens=150,\n",
    "#         n=1,\n",
    "#         stop=None,\n",
    "#         temperature=0.5,\n",
    "#     )\n",
    "#     second = time.perf_counter()\n",
    "#     print(second - first)\n",
    "#     translation = response.choices[0].message.content.strip()\n",
    "#     return translation\n",
    "\n",
    "# tweets = [translate_text(line, 'arabic', 'english') for line in lines[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(documentOne, documentTwo):\n",
    "    pairs = []\n",
    "    cosine_scores = util.cos_sim(rhe[:664], pge)\n",
    "    for i in range(len(cosine_scores)-1):\n",
    "        for j in range(i+1, len(cosine_scores)):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "#[ for tweet in tweets]\n",
    "\n",
    "\n",
    "#reduce 3 paul graham essay and a gwern article into common subset of sentences with most similarity \n",
    "#LSTM -> looks at 4 sentences at a time -> tracks \"meaning\" of sentence as a 584 column vector and then \n",
    "#summarizies them -> and then finds similar parts \n",
    "#two notes have to be intersecting to be mergable \n",
    "#start with two notes that are mostly intersecting\n",
    "#give everyone 90 minutes to write out everything they know about a topic - extemporaenous \n",
    "#merge notes \n",
    "#given n documents - reduce\n",
    "    #given two documents -> \n",
    "    #return a list of clusters and their rank\n",
    "        #rank each cluster by the relevance of each sentence to the title\n",
    "        # map - return clusterID\n",
    "        #within each cluster -> use NLTK to find the AST -> categorize as -> 'preposition, statement, question, jest, curiosity'\n",
    "        # pairwise match most similar sentences - merge - TBD or out of scope\n",
    "        \n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def encode(s1): return model.encode(s1, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb379cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the right training dataset -> 300million reddit comments = 2 million downloads + research papers \n",
    "#what is the right training data set for \"understanding twitch stream\"\n",
    "\n",
    "#sentiment analysis\n",
    "#rank by humor\n",
    "#rank by similarity \n",
    "#reorganize within topic\n",
    "#assuming there are 5 topics\n",
    "#person writes essay -> their essay is 'graded' or visualized as a venn diagram between theirs and nexus or their and all others \n",
    "#run spelling corrector uestionL how to find 300 non stream people to use app -> pay 300 students 5 dollars = 1500 \n",
    "#find them a deal on \n",
    "#write an essay for 5 minutes \n",
    "\n",
    "\n",
    "\n",
    "#subject of sentence = non-person verb acted upon\n",
    "#each classification has key structures that \n",
    "\n",
    "#theory -> i think\n",
    "#mockery = save scumming ? \n",
    "\n",
    "#use sentiment to categorize \n",
    "#use feature vector to categorize\n",
    "#use tags to categorize \n",
    "#see which one is more accurate\n",
    "import random\n",
    "\n",
    "\n",
    "tag_map = {\n",
    "  \"CC\": \"Coordinating conjunction\",\n",
    "  \"CD\": \"Cardinal number\",\n",
    "  \"DT\": \"Determiner\",\n",
    "  \"EX\": \"Existential there\",\n",
    "  \"FW\": \"Foreign word\",\n",
    "  \"IN\": \"Preposition or subordinating conjunction\",\n",
    "  \"JJ\": \"Adjective\",\n",
    "  \"JJR\": \"Adjective, comparative\",\n",
    "  \"JJS\": \"Adjective, superlative\",\n",
    "  \"LS\": \"List item marker\",\n",
    "  \"MD\": \"Modal\",\n",
    "  \"NN\": \"Noun, singular or mass\",\n",
    "  \"NNS\": \"Noun, plural\",\n",
    "  \"NNP\": \"Proper noun, singular\",\n",
    "  \"NNPS\": \"Proper noun, plural\",\n",
    "  \"PDT\": \"Predeterminer\",\n",
    "  \"POS\": \"Possessive ending\",\n",
    "  \"PRP\": \"Personal pronoun\",\n",
    "  \"PRP$\": \"Possessive pronoun\",\n",
    "  \"RB\": \"Adverb\",\n",
    "  \"RBR\": \"Adverb, comparative\",\n",
    "  \"RBS\": \"Adverb, superlative\",\n",
    "  \"RP\": \"Particle\",\n",
    "  \"SYM\": \"Symbol\",\n",
    "  \"TO\": \"to\",\n",
    "  \"UH\": \"Interjection\",\n",
    "  \"VB\": \"Verb, base form\",\n",
    "  \"VBD\": \"Verb, past tense\",\n",
    "  \"VBG\": \"Verb, gerund or present participle\",\n",
    "  \"VBN\": \"Verb, past participle\",\n",
    "  \"VBP\": \"Verb, non-3rd person singular present\",\n",
    "  \"VBZ\": \"Verb, 3rd person singular present\",\n",
    "  \"WDT\": \"Wh-determiner\",\n",
    "  \"WP\": \"Wh-pronoun\",\n",
    "  \"WP$\": \"Possessive wh-pronoun\",\n",
    "  \"WRB\": \"Wh-adverb\",\n",
    "    \".\": 'unknown_variable',\n",
    "    \",\": '',\n",
    "    ':': '',\n",
    "    '``': '',\n",
    "    \"''\": ''\n",
    "}\n",
    "def getClassification(string):\n",
    "    p = int(random.random() * 5)\n",
    "    nouns = findNouns(string)\n",
    "    verb_most_acted_on = nouns #findNouns(string)[0] if len(nouns) > 0 else ''\n",
    "    return f'{classifications[p]}:  {\" \".join(verb_most_acted_on)}'\n",
    "\n",
    "def processTag(tagged_sentence):\n",
    "    return [(orig,tag_map[actual_tag]) for (orig,actual_tag) in tagged_sentence if actual_tag in tag_map and 'noun']\n",
    "\n",
    "def findNouns(string):\n",
    "    return [noun for noun,tag in processTag(pos_tag(word_tokenize(string))) ]\n",
    "#food \n",
    "\n",
    "#[findNouns(string) for string in stream_comments]\n",
    "#within cluster -> tag topic by most common word if its that type of topic\n",
    "#processTag(pos_tag(word_tokenize(stream_comments[0])))\n",
    "\n",
    "[getClassification(string) for string in stream_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d5a8c0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9143ac24e424405b819283f797c167c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b47c8324f9a4de29e7afecfc53efb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1b8f9182fa4c5b8ce419f78c83e311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb70aa9c38744fb86ae935620583f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f22116c561460ea6484ada2fbb4c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' That chatter was wrong you can’t just pay something',\n",
       " 'labels': ['Commentary',\n",
       "  'observation',\n",
       "  'stament ',\n",
       "  'Objection',\n",
       "  'Expletive',\n",
       "  '',\n",
       "  'Clarification',\n",
       "  'Conclusion',\n",
       "  'Retraction',\n",
       "  'Explanation',\n",
       "  'Mockery',\n",
       "  'Suggestion',\n",
       "  'Continuation',\n",
       "  'Query',\n",
       "  'Recitation',\n",
       "  'Evaluation',\n",
       "  'Answer',\n",
       "  'Ammendment',\n",
       "  'Theory',\n",
       "  'Qualification '],\n",
       " 'scores': [0.15687057375907898,\n",
       "  0.11215373873710632,\n",
       "  0.10924730449914932,\n",
       "  0.09347198903560638,\n",
       "  0.056935880333185196,\n",
       "  0.05337909609079361,\n",
       "  0.05303404480218887,\n",
       "  0.05030188336968422,\n",
       "  0.04959076642990112,\n",
       "  0.04209166765213013,\n",
       "  0.03855651989579201,\n",
       "  0.034422166645526886,\n",
       "  0.03373663127422333,\n",
       "  0.027700986713171005,\n",
       "  0.020344629883766174,\n",
       "  0.01711978204548359,\n",
       "  0.015175099484622478,\n",
       "  0.01473050843924284,\n",
       "  0.014638352207839489,\n",
       "  0.006498449016362429]}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_comments = [\n",
    "    \"ZeroTepMusic: 12\",\n",
    "    \"lysinehd: crabs in a bucket\",\n",
    "    \"bouillabased: my life's biggest mistake was trusting my parents, especially when they told me education was the key to success.\",\n",
    "    \"kylanc6: Americas is full of so many people with fucking peasant brain\",\n",
    "    \"Replying to @spyderfrommars: btw, so many people have filed for bankruptcy and that used to mean having your debts forgiven. Probably many chatters parents have. SO MANY PEOPLE IN THE POLITICAL ARENA HAVE HAD THEIR DEBTS FORGIVEN. It's so stupid to use that arguementshainybug: and bankruptcy doesn't wipe student loans \",\n",
    "    \"MarIsMar: Corpa\",\n",
    "    \"IsThatSalem: I hate this\",\n",
    "    \"eronin37:   \",\n",
    "    \"v3sh_:  HYPERCLAP turn education into businesses\",\n",
    "    \"hondewberry: CHATTERS NO, LET'S DO FUN SHIT BABY WHAT YOU DOIN\",\n",
    "    \"JEZZ_7: Corpa\",\n",
    "    \"xTrashPandaKingx: @HasanAbi you dont understand they're like one or two lucky breaks from being the 1%\",\n",
    "    \"fearandrespect: Man that's a weird boot to be licking, chatter what the hell\",\n",
    "    \"PrettyKrazy: profit motive destroys humanity\",\n",
    "    \"Sutiibun_: \",\n",
    "    \"qwertyopsd2: Chatting really Hasan?\",\n",
    "    \"Tamarama02: \\\"I couldn't care less.\\\"\",\n",
    "    \"whitneythegoth: YEP LEECHES\",\n",
    "    \"FriedWaffles:  just don't get sick or hurt\",\n",
    "    \"redeyeink: gatekeeping and control over labor conditions\",\n",
    "    \"BigDddyNick: sugar dads in chat?\",\n",
    "    \"austrom: Corpa\",\n",
    "    \"HalalChad_: America is a massive corporation\",\n",
    "    \"russianspy619: Chatting I'm very smart\",\n",
    "    \"dankusdingus: hasCapital\",\n",
    "    \"dr_desu:  gimme gimme gimme\",\n",
    "    \"LateAndNever: Pivo . o O ( Corpa 🔫  )\",\n",
    "    \"phoneofff: @ashlynnicoleramirez report yourself as poor and never tell them anything ever again\",\n",
    "    \"ADK_215: they want to make money of your student loan debt how do you guys not see this\",\n",
    "    \"Leafy_Sh4de: Hey Hasan! My man! I know I longed for some twitch political commentary\",\n",
    "    \"WhyYouGotNecklace: YEP just looking for more capital avenues\",\n",
    "    \"meredyke: To profit in anyway imaginable\",\n",
    "    \"imLunchy: Corpa private prisons\",\n",
    "    \"thottopic666: YEP 󠀀\",\n",
    "    \"thelookoutshift: that chatter didn't pay their loan and the govt took back their degree via lobotomy @hasanabi\",\n",
    "    \"whataburgerfancyketchup: Knowledge is power Hasan. Its that simple. Keep people dumb, keep them powerless. @HasanAbi\",\n",
    "    \"aquamiguel: Chatting 󠀀\",\n",
    "    \"ya_plis: they need a controlled working force\",\n",
    "    \"ShakeN_Bake: Fuck them\",\n",
    "    \"moogerfooger_: can't get blood from a stone Crungo\",\n",
    "    \"sandsim: making 17 year olds take loans out OMEGALUL\",\n",
    "    \"stovetotheface: keep the masses dumb\",\n",
    "    \"Resubscribe: @luckypompom qalla_s modCheck\",\n",
    "    \"tr0piKEL1: I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills  they don’t report it to credit as long as you pay.\",\n",
    "    \"rentcontrolryan: just get a full ride scholarship EZ Chatting\",\n",
    "    \"shoriu_: chat is so annoying today\",\n",
    "    \"TheUh0hOreo:  HYPERCLAP\",\n",
    "    \"Replying to @ashlynnicoleramirez: income driven repayment plan and stay poor forevershainybug: me lmao\",\n",
    "    \"Shonnicus: paying a portion, you are still getting killed on the backend with interest. That's why they are fine with you not making full payments\",\n",
    "    \"catboy_rai: housing, food, etc.\",\n",
    "    \"YukiTsunoda__: \",\n",
    "    \"hashoe23: TATE\",\n",
    "    \"Faviahn: Because they're told they have to pay more in taxes and have less money when they're already struggling.\",\n",
    "    \"HerrosRevenge: ultimatley this argument boils down to \\\"its your fault for wanting to live and be happy\\\" most people dont want to go to school to work for the rest of their lives while paying to do so\",\n",
    "    \"seeayy: almost every aspect of higher education is profitable\",\n",
    "    \"TehAdamBomb: profit motives drive innocation \",\n",
    "    \"lordcharliesheen: YEE HAWWWW\",\n",
    "    \"HUGEGAMER96: Military YEP\",\n",
    "    \"clandestinie: Affordable but not always available\",\n",
    "    \"big_dykeenergy: i’m below the income threshold so i get a payment of zero. i should clarify that i WORK FOR THE GOVERNMENT and i’m not paid enough to meet the thresholds\",\n",
    "    \"aquamiguel: Corpa Clap\",\n",
    "    \"bignachysosa: Healthcare doesnt have to be free but it SHOULDNT be private\",\n",
    "    \"Cypres_warluckHyan8: americas kindaa fuked rn\",\n",
    "    \"ZuzieZozo: I literally had a free operation\",\n",
    "    \"quarantinewolf: Chatting Hasan @Hasanabi @Hasanthehun @Freedomeaglefuck\",\n",
    "    \"IgiveBluebells: Educaiton is overpriced in the US\",\n",
    "    \"librapelican: theres a reason my sociology class presented american exceptionalism as a form of propaganda\",\n",
    "    \"xygeek: @hasanabi allow for bankruptcy, then normalize bankruptcy at graduation. Problem solved. KEKW\",\n",
    "    \"Skill_Cylinder: YEP just join the military\",\n",
    "    \"Hagasha: \",\n",
    "    \"bigstephfan: and here healthcare is so fucking expensive.\",\n",
    "    \"BOATPARADE: can't have an educated proletariat\",\n",
    "    \"RoguePr1nc355: Now it is about political ideology\",\n",
    "    \"Zony66: you cant even have a fucking hobby without people asking you \\\"well how are you gunna make any money with that?\\\"\",\n",
    "    \"cas3_: no war but class war\",\n",
    "    \"Replying to @tr0piKEL1: I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills rhyzKEK they don’t report it to credit as long as you pay.aspiration89: YEP 󠀀\",\n",
    "    \"SimUser:  You want my number to not go up???\",\n",
    "     \"narjuh: more than South Korea?\",\n",
    "    \"punishedribcorn: Education isnt free for the same reason healthcare isnt free. Because you cant live without it @hasanabi\",\n",
    "    \"GanjarDanks: @hasanabi true reason that education isn't free and student loans reign supreme is slabs\",\n",
    "    \"ok_eevee:  Paywall the labor force @hasanabi\",\n",
    "    \"kintu: there are worse neoliberal hellholes out there Aware\",\n",
    "    \"esquerdomacho: I can get a free heart transplant in Brazil if I want MmmHmm\",\n",
    "    \"lagsanaglasscoke: Corpa hehe\",\n",
    "    \"ComradeCussy: Freedom ain't free brother @HasanAbi\",\n",
    "    \"eronin37:   💵\",\n",
    "    \"calimarx: It’s to maintain order\",\n",
    "    \"PrettyKrazy: profit motive deprives every successful system\",\n",
    "    \"SpanoNanoChano: even textbooks are a literal racket\",\n",
    "    \"bignachysosa: Federalize it let the government deal with paying hospitals and doctors\",\n",
    "    \"happppy_ant: YEP\",\n",
    "    \"lardball1: @HasanAbi an educated proletariat is dynamite, like that reagan advisor said\",\n",
    "    \"Replying to @ZuzieZozo: I literally had a free operationBurnzorr: You are one person\",\n",
    "    \"PoogDoog: HE SAID THE THING LETSGO\",\n",
    "    \"1337h4x: BALD POTATO PEELER OMEGALUL\",\n",
    "    \"cms100210: All these things exist in countries hence it can work\",\n",
    "    \"HVYHTTRS_: The biggest scam in college is the BOOKS, some good docs about it\",\n",
    "    \"Eevee_Sprinkle:  Keep on licking the boot, GED Andy's.\",\n",
    "    \"bakhtiari_veneco: Stupid question, is South Korea less capitalistic than America? @hasanabi\",\n",
    "    \"JaychanLive:  WineTime PROFIT FIRST  WineTime\",\n",
    "    \"whataburgerfancyketchup: Thats Me Pog\",\n",
    "    \"dumpster27: message deleted by a moderator.\",\n",
    "    \"moogerfooger_: like paying less than $15 min wage\",\n",
    "    \"happppy_ant: YEP control\",\n",
    "    \"Shroomie1707: Do you think you should be able to run for president if you are in jail @hasanabi\",\n",
    "    \"DavidTheDaybed: D:\",\n",
    "    \"Replying to @bignachysosa: Healthcare doesnt have to be free but it SHOULDNT be privateqwertyopsd2: it should be free\",\n",
    "    \"Zpectr3: I pay like 300 Euros for university every semester in germany , but like 250 are for public transport. This shit is insane in the us @HasanAbi\",\n",
    "    \"RamenBellic: @Baldpotatopeeler we just need to decommodify education.\",\n",
    "    \"dicesettle: Lol. Don't do that\",\n",
    "    \"mrbuddybuddy: KEKWait\",\n",
    "    \"RowdyRoran: bro has been following for 3 years and is asking this now?\",\n",
    "    \"sassoune: SORRY WE CAN BAIL OUT CMBS AT 30% purchase price - but when it comes to student loans we’re back to archaic - loan - predatory interest gurg payback or go die\",\n",
    "    \"Darksoul9669: @hasanabi yeah man it was my own actions that had every part of my schooling telling me to take out loans and go to college as the only option and there being basically no downside. Really interesting how high school blows right through how devastating these loans were gonna be during these discussions when i was fucking 17 YEARS OLD\",\n",
    "    \"Tetratera: university is free for everyone in argentina including foreigners, and you don't even have to take a standardized test, only have finished high school (and know upper intermediate spanish)\",\n",
    "    \"lysinehd: permanent desperate underclass\",\n",
    "    \"FALS3_g0D: crusing debt made to keep you a servant to the system\",\n",
    "    \"atsign_: literally other countries can do it for free. is america not exceptional enough to do it?\",\n",
    "    \"dumpster27: message deleted by a moderator.\",\n",
    "    \"Fossabot: @dumpster27, Excessive spamming [warning]\",\n",
    "    \"WeasleyLittleLiar: Did not used to cost that much\",\n",
    "    \"rex__havoc: @hasanabi Have you talked about the new IDR plan \\\"SAVE\\\"? you're payments can be as low as 0/month\",\n",
    "    \"thottopic666: every single aspect of this country was designed to suck the citizens dry as efficiently as possible\",\n",
    "    \"c_d1999: Ask that chatter why don’t we charge for public high school!??\",\n",
    "    \"thehappyparadox: YEP\",\n",
    "    \"Skill_Cylinder: YEP\",\n",
    "    \"kaimehra: yep\",\n",
    "    \"kait516: YEP YEP YEP\",\n",
    "    \"canola_oil: YEP\",\n",
    "    \"thottopic666: YEP\",\n",
    "    \"Hagasha: YEP\"\n",
    "]\n",
    "\n",
    "stream_comments += [\n",
    "    \"MER_AKI: bro thinks hes him lol\",\n",
    "    \"o7draco: ECO DEMON FRFR\",\n",
    "    \"tko0_: UR SO LUCKY\",\n",
    "    \"SparkYYY_123: SO LUCKY\",\n",
    "    \"extratiarestrial: EWWWW\",\n",
    "    \"tomas2brazy: Derke moment\",\n",
    "    \"abhi_142: ECO king\",\n",
    "    \"psygonnn: yeah yeah tarik we know you are going pro\",\n",
    "    \"autumn0999: LOL\",\n",
    "    \"betasimp42: Derke you was right Aware\",\n",
    "    \"grandpafroggys: eco demon\",\n",
    "    \"xDieWithPridex: whats his dpi and sens?\",\n",
    "    \"lowertaxrates: KEKW ur insane sometimes\",\n",
    "    \"PhanzGFX: A real one would get an ace there\",\n",
    "    \"gangliaa: he predicted this\",\n",
    "    \"MrKing8: KEKW\",\n",
    "    \"AyoJabo: ECOOOO FRAGGGGGGER\",\n",
    "    \"MandyLynx: calm down buddy\",\n",
    "    \"Neon_Phaser: derke said it\",\n",
    "    \"Fossabot: Hey, are you following tarik on Twitter? http://twitter.com/tarik\",\n",
    "    \"rishon26: STOP OVERPEEKING LMFAO\",\n",
    "    \"nopointgamer: eco frags\",\n",
    "    \"demon_sl4: any cs2 news?\",\n",
    "    \"aidenvovn420: overheat\",\n",
    "    \"danielmacttv: You are him\",\n",
    "    \"atinyspec: hallo\",\n",
    "    \"GorillaTangie: KEKW\",\n",
    "    \"ghost_khtab: KEKW\",\n",
    "    \"丁乚仨乂 (tlex): KLİİPPPPPPPP\",\n",
    "    \"oikawies: well ur consistent at overheating\",\n",
    "    \"ZqCyzreN: ecobra\",\n",
    "    \"ayoub_hh: ns\",\n",
    "    \"bearrynice: @tarik you can satchel? Since when Lil bro\",\n",
    "    \"KorHun_Official: kangkang gets 5 here @tarik\",\n",
    "    \"suus001: OHHHH SHIT\",\n",
    "    \"ub_zinio: overheaaat\",\n",
    "    \"ironman_ap: sup ? @Derke\",\n",
    "    \"Schabii97: DERKE W\",\n",
    "    \"Grediann: overpeak = die Shruge\",\n",
    "    \"jaybird1014: SIT DOWN PLS\",\n",
    "    \"ayswoosh: @Derke how were champs?\",\n",
    "    \"nishikoto: NASTY\",\n",
    "    \"thickymonster: !duo\",\n",
    "    \"wddcruz: 3King\",\n",
    "    \"sqawg: Lil bro humbled himself\",\n",
    "    \"Replying to @thickymonster: !duoFossabot: Asuna AYAYA\",\n",
    "    \"littlesmchallowen: do that next round kekw\",\n",
    "    \"davidakachuwy: COOKED then OVERPEEKED\",\n",
    "    \"MER_AKI: you are not himothy\",\n",
    "    \"lotace:     \",\n",
    "    \"ditt0o: we've got huge bets don't ROZA\",\n",
    "    \"gme16: that spray transfer was lit as\",\n",
    "    \"iicpr: overheat\",\n",
    "    \"daymare5: it was horrible\",\n",
    "    \"Sigfreed: NA BRAIN KEKW\",\n",
    "    \"samsaraeyess: that spray transfer made me ink\",\n",
    "    \"hwhevevsvb: no\",\n",
    "    \"suus001: TUROK TUROK TUROK\",\n",
    "    \"SilintNight: OMEGALUL\",\n",
    "    \"Derke: NO\",\n",
    "    \"mr_01ne: Derke knew it\",\n",
    "    \"Replying to @Derke: i told uQuanFuPanda: deadass\",\n",
    "    \"dioholic: terue\",\n",
    "    \"ta3sk1: THIS TEAM IS FUCKING GOATED TARIK/STEW/ASUNA GGZ\",\n",
    "    \"rue__s: heeey\",\n",
    "    \"abcdgwenchana: overheat on eco\",\n",
    "    \"AdderallBeforeBed: bet you can't do it again MmmHmm\",\n",
    "    \"sissimou: fax\",\n",
    "    \"xcrimsoncrookx: bro thinks the transfer was intentional AINTNOWAY\",\n",
    "    \"adityasanas001: Ecodemon\",\n",
    "    \"dioholic: true\",\n",
    "    \"Lefluu: stew did everything there @tarik\",\n",
    "    \"CosmicDeven: two eco frags and we start talking shit on derke KEKW\",\n",
    "    \"Benjjamin: If you get 3 you're allowed to throw\",\n",
    "    \"afor_f: its true\",\n",
    "    \"Derke: IF ITS 5V1\",\n",
    "    \"Harnasiek03: true\",\n",
    "    \"lowertaxrates: no?\",\n",
    "    \"ketosaiba11: replace jinggg no?\",\n",
    "    \"theak44: BLABBERING BLABBERING\",\n",
    "    \"Derke: AND I DIE FIRST\",\n",
    "    \"laiiiny: You should apply for observer in VCT\",\n",
    "    \"itsrawkus: wake up\",\n",
    "    \"tripharder: ahh yes the rule\",\n",
    "    \"shruggy8: TRUEING\",\n",
    "    \"autumn0999: nice fucking shots tho\",\n",
    "    \"Derke: ITS MY FAULT\",\n",
    "    \"rishon26: @Derke get this man on fnatic\",\n",
    "    \"OzGunAim: !sens\",\n",
    "    \"Fossabot: CSGO: 1.5 @ 800 DPI, VALORANT: .471 800 DPI\",\n",
    "    \"JRD_Nath: \",\n",
    "    \"xkillo147: True, NA rule\",\n",
    "    \"gentlecpu: KEKW if you get 1 it's not your fault\",\n",
    "    \"jinsoooo: if you get 2 you go for the ace\",\n",
    "    \"rightylucy: Lkekw\",\n",
    "    \"lionbrav3: C9 VIBEZ\",\n",
    "    \"emil__val: KEKW KEKW\",\n",
    "    \"maareeyyyy: !mouse\",\n",
    "    \"FarmerFelox: In NA if you get 1 go for 5\",\n",
    "    \"abcdgwenchana: eco frag\",\n",
    "    \"alirezathe1: !res\",\n",
    "    \"Fossabot: DeathAdder V3 Pro\",\n",
    "    \"Fossabot: Val 16:10 (1680x1050) - CSGO: 1280x960\",\n",
    "    \"CaliKillz3: TRUEING\",\n",
    "    \"rentr04: homie turned up cuz derke is watching. respect\",\n",
    "    \"hyp3r10n2: @tarik gets 3 wins round then overfaces and gets mad for it xD\",\n",
    "    \"rightylucy: KEKW\",\n",
    "    \"riyuoh: IF U GET 3 YOU CAN OVERHEAT 100%\",\n",
    "    \"PiquesGaming: thats facts tho\",\n",
    "    \"gkhn94: Dayi bi kere turkce konus be\",\n",
    "    \"Sigfreed: LOOK ITS A 1V1 NOW\",\n",
    "    \"丁乚仨乂 (tlex): KLİPPP\",\n",
    "    \"myinnerfaye: Himothy is that you?\",\n",
    "    \"Maximus6267: KEKW no way\",\n",
    "    \"tsylogy: @Derke 5V1 DSG Aware\",\n",
    "    \"ub_zinio: derkes fault\",\n",
    "    \"shruggy8: gonna lose PepeLaugh\",\n",
    "    \"Sigfreed: ITS A FUCKING 1V1 NOW\",\n",
    "    \"Replying to @lionbrav3: C9 VIBEZXeppaa: ?\",\n",
    "    \"ItsTavyy: maybe you need to peek more @tarik\",\n",
    "    \"danielmacttv: Its DERKE’s fault\",\n",
    "    \"dexterityCS: KEKW 󠀀\",\n",
    "    \"Rickz10K: KEKW KEKW KEKW KEKW\",\n",
    "    \"kaizo_rm: HUH 󠀀\",\n",
    "    \"slaxxxyyyy: Fair enuff\",\n",
    "    \"diipsy9: AYOO HH\",\n",
    "    \"h1k1k0_: HUH\",\n",
    "    \"m0gi08: !gekko\",\n",
    "    \"Apollo_Neptune: HUH\",\n",
    "    \"Fossabot: LilBro it's gekkin time ezz\",\n",
    "    \"siwa33: Close gamba mods\",\n",
    "    \"wahbi_79: HUH\",\n",
    "    \"xelzttv: HUH\",\n",
    "    \"emil__val: KEKW\",\n",
    "    \"ig5mindhacker: HUH\",\n",
    "    \"krasqu33: HUH\",\n",
    "    \"aqilus: HUH\",\n",
    "    \"Jordbaermelk: WOT\",\n",
    "    \"derkesdoormat: @derke OOO DERKE'S HERE HII\",\n",
    "    \"beepbopp11: HUH\",\n",
    "    \"cenk4k: HUH\",\n",
    "    \"mrsteallyourcat: HUH\",\n",
    "    \"xclaassic: true\",\n",
    "    \"Aethielle: HUH\",\n",
    "    \"cyb_eric: HUH\",\n",
    "    \"shruggy8: Sadge\",\n",
    "    \"mesme_R: HUH\"\n",
    "]\n",
    "stream_comments = [comment.split(':')[1] for comment in stream_comments]\n",
    "stream_comments = [comment for comment in stream_comments if len(comment.strip()) > 0]\n",
    "    \n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "#You can then use this pipeline to classify sequences into any of the class names you specify.\n",
    "classifications = \"\"\"Retraction\n",
    "Explanation\n",
    "Query\n",
    "Suggestion\n",
    "Ammendment\n",
    "Expletive\n",
    "Answer\n",
    "Recitation\n",
    "stament \n",
    "observation\n",
    "Commentary\n",
    "Conclusion\n",
    "Mockery\n",
    "Qualification \n",
    "Objection\n",
    "Theory\n",
    "Continuation\n",
    "Evaluation\n",
    "Clarification\n",
    "\"\"\".split('\\n')\n",
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = classifications\n",
    "classifier(stream_comments[0], candidate_labels)\n",
    "# with open('./stream-comments.json','r+') as file:\n",
    "#       # First we load existing data into a dict.\n",
    "#     file_data = json.load(file)\n",
    "#     # Join new_data with file_data inside emp_details\n",
    "#     file_data += stream_comments\n",
    "#     # Sets file's current position at offset.\n",
    "#     file.seek(0)\n",
    "#     # convert back to json.\n",
    "#     json.dump(file_data, file, indent = 4)\n",
    " \n",
    "#copy(Array.from(document.querySelectorAll('.chat-line__message')).map(el => el.textContent))\n",
    "\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\", device=0)\n",
    "# sequence_to_classify = \"Angela Merkel is a politician in Germany and leader of the CDU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "20cd6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are 300 cats in the neighborhood.']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "input_sentence = \"there are 300 cats in the neighborhood .\"\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "batch = tokenizer(input_sentence, return_tensors='pt')\n",
    "generated_ids = model.generate(batch['input_ids'])\n",
    "generated_sentence = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "print(generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30bf66fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': ' That chatter was wrong you can’t just pay something',\n",
       " 'labels': ['Commentary',\n",
       "  'Objection',\n",
       "  'observation',\n",
       "  'Retraction',\n",
       "  'Recitation',\n",
       "  'Mockery',\n",
       "  '',\n",
       "  'Explanation',\n",
       "  'Clarification',\n",
       "  'Expletive',\n",
       "  'Evaluation',\n",
       "  'Query',\n",
       "  'stament ',\n",
       "  'Continuation',\n",
       "  'Theory',\n",
       "  'Ammendment',\n",
       "  'Qualification ',\n",
       "  'Suggestion',\n",
       "  'Conclusion',\n",
       "  'Answer'],\n",
       " 'scores': [0.3218739330768585,\n",
       "  0.12368783354759216,\n",
       "  0.11010725796222687,\n",
       "  0.0929412841796875,\n",
       "  0.0642746165394783,\n",
       "  0.04800968989729881,\n",
       "  0.03449365124106407,\n",
       "  0.032560210675001144,\n",
       "  0.028999583795666695,\n",
       "  0.027890585362911224,\n",
       "  0.02410063147544861,\n",
       "  0.018279941752552986,\n",
       "  0.013321823440492153,\n",
       "  0.011183790862560272,\n",
       "  0.010250714607536793,\n",
       "  0.00916434358805418,\n",
       "  0.00787479430437088,\n",
       "  0.007707780227065086,\n",
       "  0.007357117719948292,\n",
       "  0.00592039292678237]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(stream_comments[0], classifications, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5964b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in [1, 8, 64, 256]:\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Streaming batch_size={batch_size}\")\n",
    "    for out in tqdm(pipe(dataset, batch_size=batch_size), total=len(dataset)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd497491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.920957326889038\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "one = time.time()\n",
    "isClassified = [classifier(seq, classifications, multi_label=False, batch_size=256) for seq in stream_comments[:20]]\n",
    "two = time.time()\n",
    "print(two - one)\n",
    "#260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e95bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': ' That chatter was wrong you can’t just pay something',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' 12', 'labels': [], 'scores': []},\n",
       " {'sequence': ' crabs in a bucket', 'labels': [], 'scores': []},\n",
       " {'sequence': \" my life's biggest mistake was trusting my parents, especially when they told me education was the key to success.\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Americas is full of so many people with fucking peasant brain',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" btw, so many people have filed for bankruptcy and that used to mean having your debts forgiven. Probably many chatters parents have. SO MANY PEOPLE IN THE POLITICAL ARENA HAVE HAD THEIR DEBTS FORGIVEN. It's so stupid to use that arguementshainybug\",\n",
       "  'labels': ['observation'],\n",
       "  'scores': [0.6428787708282471]},\n",
       " {'sequence': ' Corpa', 'labels': [], 'scores': []},\n",
       " {'sequence': ' I hate this', 'labels': [], 'scores': []},\n",
       " {'sequence': '  HYPERCLAP turn education into businesses',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" CHATTERS NO, LET'S DO FUN SHIT BABY WHAT YOU DOIN\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Corpa', 'labels': [], 'scores': []},\n",
       " {'sequence': \" @HasanAbi you dont understand they're like one or two lucky breaks from being the 1%\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" Man that's a weird boot to be licking, chatter what the hell\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' profit motive destroys humanity', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Chatting really Hasan?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' \"I couldn\\'t care less.\"', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP LEECHES', 'labels': [], 'scores': []},\n",
       " {'sequence': \"  just don't get sick or hurt\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' gatekeeping and control over labor conditions',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' sugar dads in chat?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Corpa', 'labels': [], 'scores': []},\n",
       " {'sequence': ' America is a massive corporation', 'labels': [], 'scores': []},\n",
       " {'sequence': \" Chatting I'm very smart\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' hasCapital', 'labels': [], 'scores': []},\n",
       " {'sequence': '  gimme gimme gimme', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Pivo . o O ( Corpa 🔫  )', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @ashlynnicoleramirez report yourself as poor and never tell them anything ever again',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' they want to make money of your student loan debt how do you guys not see this',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Hey Hasan! My man! I know I longed for some twitch political commentary',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' YEP just looking for more capital avenues',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' To profit in anyway imaginable', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Corpa private prisons', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP \\U000e0000', 'labels': [], 'scores': []},\n",
       " {'sequence': \" that chatter didn't pay their loan and the govt took back their degree via lobotomy @hasanabi\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Knowledge is power Hasan. Its that simple. Keep people dumb, keep them powerless. @HasanAbi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Chatting \\U000e0000', 'labels': [], 'scores': []},\n",
       " {'sequence': ' they need a controlled working force',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Fuck them', 'labels': [], 'scores': []},\n",
       " {'sequence': \" can't get blood from a stone Crungo\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' making 17 year olds take loans out OMEGALUL',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' keep the masses dumb', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @luckypompom qalla_s modCheck', 'labels': [], 'scores': []},\n",
       " {'sequence': ' I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills  they don’t report it to credit as long as you pay.',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' just get a full ride scholarship EZ Chatting',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' chat is so annoying today', 'labels': [], 'scores': []},\n",
       " {'sequence': '  HYPERCLAP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' income driven repayment plan and stay poor forevershainybug',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" paying a portion, you are still getting killed on the backend with interest. That's why they are fine with you not making full payments\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' housing, food, etc.', 'labels': [], 'scores': []},\n",
       " {'sequence': ' TATE', 'labels': [], 'scores': []},\n",
       " {'sequence': \" Because they're told they have to pay more in taxes and have less money when they're already struggling.\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' this country fucken sucks', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ultimatley this argument boils down to \"its your fault for wanting to live and be happy\" most people dont want to go to school to work for the rest of their lives while paying to do so',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' almost every aspect of higher education is profitable',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Daddy chill \\U0001fae0', 'labels': [], 'scores': []},\n",
       " {'sequence': ' profit motives drive innocation ', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEE HAWWWW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Military YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Affordable but not always available',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' i’m below the income threshold so i get a payment of zero. i should clarify that i WORK FOR THE GOVERNMENT and i’m not paid enough to meet the thresholds',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Corpa Clap', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Healthcare doesnt have to be free but it SHOULDNT be private',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' americas kindaa fuked rn', 'labels': [], 'scores': []},\n",
       " {'sequence': ' I literally had a free operation', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Chatting Hasan @Hasanabi @Hasanthehun @Freedomeaglefuck',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Educaiton is overpriced in the US',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' theres a reason my sociology class presented american exceptionalism as a form of propaganda',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' @hasanabi allow for bankruptcy, then normalize bankruptcy at graduation. Problem solved. KEKW',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' YEP just join the military', 'labels': [], 'scores': []},\n",
       " {'sequence': ' and here healthcare is so fucking expensive.',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" can't have an educated proletariat\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Now it is about political ideology',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' you cant even have a fucking hobby without people asking you \"well how are you gunna make any money with that?\"',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' no war but class war', 'labels': [], 'scores': []},\n",
       " {'sequence': ' I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills rhyzKEK they don’t report it to credit as long as you pay.aspiration89',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': '  You want my number to not go up???',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': '  dumb consumer slaves', 'labels': [], 'scores': []},\n",
       " {'sequence': ' more than South Korea?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Education isnt free for the same reason healthcare isnt free. Because you cant live without it @hasanabi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" @hasanabi true reason that education isn't free and student loans reign supreme is slabs\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': '  Paywall the labor force @hasanabi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' there are worse neoliberal hellholes out there Aware',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' I can get a free heart transplant in Brazil if I want MmmHmm',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Corpa hehe', 'labels': [], 'scores': []},\n",
       " {'sequence': \" Freedom ain't free brother @HasanAbi\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': '   💵', 'labels': [], 'scores': []},\n",
       " {'sequence': ' It’s to maintain order', 'labels': [], 'scores': []},\n",
       " {'sequence': ' profit motive deprives every successful system',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' even textbooks are a literal racket',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Federalize it let the government deal with paying hospitals and doctors',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @HasanAbi an educated proletariat is dynamite, like that reagan advisor said',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' I literally had a free operationBurnzorr',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' HE SAID THE THING LETSGO', 'labels': [], 'scores': []},\n",
       " {'sequence': ' BALD POTATO PEELER OMEGALUL', 'labels': [], 'scores': []},\n",
       " {'sequence': ' All these things exist in countries hence it can work',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' The biggest scam in college is the BOOKS, some good docs about it',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \"  Keep on licking the boot, GED Andy's.\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Stupid question, is South Korea less capitalistic than America? @hasanabi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': '  WineTime PROFIT FIRST  WineTime', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Thats Me Pog', 'labels': [], 'scores': []},\n",
       " {'sequence': ' message deleted by a moderator.',\n",
       "  'labels': ['Retraction'],\n",
       "  'scores': [0.6210706830024719]},\n",
       " {'sequence': ' like paying less than $15 min wage',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' YEP control', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Do you think you should be able to run for president if you are in jail @hasanabi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' D', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Healthcare doesnt have to be free but it SHOULDNT be privateqwertyopsd2',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' I pay like 300 Euros for university every semester in germany , but like 250 are for public transport. This shit is insane in the us @HasanAbi',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' @Baldpotatopeeler we just need to decommodify education.',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" Lol. Don't do that\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKWait', 'labels': [], 'scores': []},\n",
       " {'sequence': ' bro has been following for 3 years and is asking this now?',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' SORRY WE CAN BAIL OUT CMBS AT 30% purchase price - but when it comes to student loans we’re back to archaic - loan - predatory interest gurg payback or go die',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' @hasanabi yeah man it was my own actions that had every part of my schooling telling me to take out loans and go to college as the only option and there being basically no downside. Really interesting how high school blows right through how devastating these loans were gonna be during these discussions when i was fucking 17 YEARS OLD',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" university is free for everyone in argentina including foreigners, and you don't even have to take a standardized test, only have finished high school (and know upper intermediate spanish)\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' permanent desperate underclass', 'labels': [], 'scores': []},\n",
       " {'sequence': ' crusing debt made to keep you a servant to the system',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' literally scamming children', 'labels': [], 'scores': []},\n",
       " {'sequence': ' literally other countries can do it for free. is america not exceptional enough to do it?',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' message deleted by a moderator.',\n",
       "  'labels': ['Retraction'],\n",
       "  'scores': [0.6210706830024719]},\n",
       " {'sequence': ' @dumpster27, Excessive spamming [warning]',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Did not used to cost that much', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @hasanabi Have you talked about the new IDR plan \"SAVE\"? you\\'re payments can be as low as 0/month',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' every single aspect of this country was designed to suck the citizens dry as efficiently as possible',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Ask that chatter why don’t we charge for public high school!??',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' yep', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP YEP YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' YEP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' bro thinks hes him lol', 'labels': [], 'scores': []},\n",
       " {'sequence': ' That spray so mad u really him', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ECO DEMON FRFR', 'labels': [], 'scores': []},\n",
       " {'sequence': ' UR SO LUCKY', 'labels': [], 'scores': []},\n",
       " {'sequence': ' SO LUCKY', 'labels': [], 'scores': []},\n",
       " {'sequence': ' EWWWW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Derke moment', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ECO king', 'labels': [], 'scores': []},\n",
       " {'sequence': ' yeah yeah tarik we know you are going pro',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' LOL', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Derke you was right Aware', 'labels': [], 'scores': []},\n",
       " {'sequence': ' eco demon', 'labels': [], 'scores': []},\n",
       " {'sequence': ' whats his dpi and sens?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW ur insane sometimes', 'labels': [], 'scores': []},\n",
       " {'sequence': ' A real one would get an ace there',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' he predicted this', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ECOOOO FRAGGGGGGER', 'labels': [], 'scores': []},\n",
       " {'sequence': ' calm down buddy', 'labels': [], 'scores': []},\n",
       " {'sequence': ' derke said it', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Hey, are you following tarik on Twitter? http',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' STOP OVERPEEKING LMFAO', 'labels': [], 'scores': []},\n",
       " {'sequence': ' eco frags', 'labels': [], 'scores': []},\n",
       " {'sequence': ' any cs2 news?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' overheat', 'labels': [], 'scores': []},\n",
       " {'sequence': ' You are him', 'labels': [], 'scores': []},\n",
       " {'sequence': ' hallo', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KLİİPPPPPPPP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' well ur consistent at overheating',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' ecobra', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ns', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @tarik you can satchel? Since when Lil bro',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' kangkang gets 5 here @tarik', 'labels': [], 'scores': []},\n",
       " {'sequence': ' OHHHH SHIT', 'labels': [], 'scores': []},\n",
       " {'sequence': ' overheaaat', 'labels': [], 'scores': []},\n",
       " {'sequence': ' sup ? @Derke', 'labels': [], 'scores': []},\n",
       " {'sequence': ' DERKE W', 'labels': [], 'scores': []},\n",
       " {'sequence': ' overpeak = die Shruge', 'labels': [], 'scores': []},\n",
       " {'sequence': ' SIT DOWN PLS', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @Derke how were champs?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' NASTY', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !duo', 'labels': [], 'scores': []},\n",
       " {'sequence': ' 3King', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Lil bro humbled himself', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !duoFossabot', 'labels': [], 'scores': []},\n",
       " {'sequence': ' do that next round kekw', 'labels': [], 'scores': []},\n",
       " {'sequence': ' COOKED then OVERPEEKED', 'labels': [], 'scores': []},\n",
       " {'sequence': ' you are not himothy', 'labels': [], 'scores': []},\n",
       " {'sequence': \" we've got huge bets don't ROZA\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' that spray transfer was lit as', 'labels': [], 'scores': []},\n",
       " {'sequence': ' overheat', 'labels': [], 'scores': []},\n",
       " {'sequence': ' it was horrible', 'labels': [], 'scores': []},\n",
       " {'sequence': ' NA BRAIN KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' that spray transfer made me ink', 'labels': [], 'scores': []},\n",
       " {'sequence': ' no', 'labels': [], 'scores': []},\n",
       " {'sequence': ' TUROK TUROK TUROK', 'labels': [], 'scores': []},\n",
       " {'sequence': ' OMEGALUL', 'labels': [], 'scores': []},\n",
       " {'sequence': ' NO', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Derke knew it', 'labels': [], 'scores': []},\n",
       " {'sequence': ' i told uQuanFuPanda', 'labels': [], 'scores': []},\n",
       " {'sequence': ' terue', 'labels': [], 'scores': []},\n",
       " {'sequence': ' THIS TEAM IS FUCKING GOATED TARIK/STEW/ASUNA GGZ',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' heeey', 'labels': [], 'scores': []},\n",
       " {'sequence': ' overheat on eco', 'labels': [], 'scores': []},\n",
       " {'sequence': \" bet you can't do it again MmmHmm\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' fax', 'labels': [], 'scores': []},\n",
       " {'sequence': ' bro thinks the transfer was intentional AINTNOWAY',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Ecodemon', 'labels': [], 'scores': []},\n",
       " {'sequence': ' true', 'labels': [], 'scores': []},\n",
       " {'sequence': ' stew did everything there @tarik', 'labels': [], 'scores': []},\n",
       " {'sequence': ' two eco frags and we start talking shit on derke KEKW',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': \" If you get 3 you're allowed to throw\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' its true', 'labels': [], 'scores': []},\n",
       " {'sequence': ' IF ITS 5V1', 'labels': [], 'scores': []},\n",
       " {'sequence': ' true', 'labels': [], 'scores': []},\n",
       " {'sequence': ' no?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' replace jinggg no?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' BLABBERING BLABBERING', 'labels': [], 'scores': []},\n",
       " {'sequence': ' AND I DIE FIRST', 'labels': [], 'scores': []},\n",
       " {'sequence': ' You should apply for observer in VCT',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' wake up', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ahh yes the rule', 'labels': [], 'scores': []},\n",
       " {'sequence': ' TRUEING', 'labels': [], 'scores': []},\n",
       " {'sequence': ' nice fucking shots tho', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ITS MY FAULT', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @Derke get this man on fnatic', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !sens', 'labels': [], 'scores': []},\n",
       " {'sequence': ' CSGO', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @tarik UR BICEPS ARE HUGE!!!', 'labels': [], 'scores': []},\n",
       " {'sequence': ' True, NA rule', 'labels': [], 'scores': []},\n",
       " {'sequence': \" KEKW if you get 1 it's not your fault\",\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' if you get 2 you go for the ace', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Lkekw', 'labels': [], 'scores': []},\n",
       " {'sequence': ' C9 VIBEZ', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !mouse', 'labels': [], 'scores': []},\n",
       " {'sequence': ' In NA if you get 1 go for 5', 'labels': [], 'scores': []},\n",
       " {'sequence': ' eco frag', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !res', 'labels': [], 'scores': []},\n",
       " {'sequence': ' DeathAdder V3 Pro', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Val 16', 'labels': [], 'scores': []},\n",
       " {'sequence': ' TRUEING', 'labels': [], 'scores': []},\n",
       " {'sequence': ' homie turned up cuz derke is watching. respect',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' @tarik gets 3 wins round then overfaces and gets mad for it xD',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' IF U GET 3 YOU CAN OVERHEAT 100%', 'labels': [], 'scores': []},\n",
       " {'sequence': ' thats facts tho', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Dayi bi kere turkce konus be', 'labels': [], 'scores': []},\n",
       " {'sequence': ' LOOK ITS A 1V1 NOW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KLİPPP', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Himothy is that you?', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW no way', 'labels': [], 'scores': []},\n",
       " {'sequence': ' @Derke 5V1 DSG Aware', 'labels': [], 'scores': []},\n",
       " {'sequence': ' derkes fault', 'labels': [], 'scores': []},\n",
       " {'sequence': ' arabic blood', 'labels': [], 'scores': []},\n",
       " {'sequence': ' gonna lose PepeLaugh', 'labels': [], 'scores': []},\n",
       " {'sequence': ' ITS A FUCKING 1V1 NOW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' C9 VIBEZXeppaa', 'labels': [], 'scores': []},\n",
       " {'sequence': ' maybe you need to peek more @tarik',\n",
       "  'labels': [],\n",
       "  'scores': []},\n",
       " {'sequence': ' Its DERKE’s fault', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW \\U000e0000', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW KEKW KEKW KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH \\U000e0000', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Fair enuff', 'labels': [], 'scores': []},\n",
       " {'sequence': ' AYOO HH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' !gekko', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': \" LilBro it's gekkin time ezz\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' Close gamba mods', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' KEKW', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' WOT', 'labels': [], 'scores': []},\n",
       " {'sequence': \" @derke OOO DERKE'S HERE HII\", 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' true', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []},\n",
       " {'sequence': ' Sadge', 'labels': [], 'scores': []},\n",
       " {'sequence': ' HUH', 'labels': [], 'scores': []}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isClassified\n",
    "\n",
    "for i in isClassified:\n",
    "    i['labels'] = [s for index, s in enumerate(i['labels']) if i['scores'][index] > .5]\n",
    "    i['scores'] = [s for index, s in enumerate(i['scores']) if s > .5]\n",
    "\n",
    "            \n",
    "isClassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31ed1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awahab/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Angela Merkel is a politician in Germany and leader of the CDU', 'labels': ['politics', 'economy', 'environment', 'entertainment'], 'scores': [0.982321560382843, 0.007280202116817236, 0.005891879089176655, 0.004506275057792664]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "sequence_to_classify = \"Angela Merkel is a politician in Germany and leader of the CDU\"\n",
    "candidate_labels = [\"politics\", \"economy\", \"entertainment\", \"environment\"]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b8b56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,    260,  64817,  55118,    857,   1298,    260, 154064,    349,\n",
       "            282,  12556,    473,    260, 153067,    443,    260,  94867,      2,\n",
       "            260,  64708,  54272,    273,    340,    288,  13977,    305,   5264,\n",
       "              2]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input[\"input_ids\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "#torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "premise = \"Angela Merkel ist eine Politikerin in Deutschland und Vorsitzende der CDU\"\n",
    "hypothesis = \"Emmanuel Macron is the President of France\"\n",
    "\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to('cpu'))  # device = \"cuda:0\" or \"cpu\"\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cc9c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Angela Merkel is a politician in Germany and leader of the CDU', 'labels': ['politics', 'economy', 'environment', 'entertainment'], 'scores': [0.982321560382843, 0.007280202116817236, 0.005891879089176655, 0.004506275057792664]}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee83fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextInputSequence must be str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 303\u001b[0m\n\u001b[1;32m    300\u001b[0m hypothesis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis example is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# run through model pre-trained on MNLI\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpremise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monly_first\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m logits \u001b[38;5;241m=\u001b[39m nli_model(x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# we throw away \"neutral\" (dim 1) and take the probability of\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# \"entailment\" (2) as the probability of the label being true \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2373\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;129m@add_end_docstrings\u001b[39m(\n\u001b[1;32m   2337\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;124;03m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[1;32m   2360\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2371\u001b[0m \u001b[38;5;124;03m            method).\u001b[39;00m\n\u001b[1;32m   2372\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2373\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2781\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2772\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2773\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2774\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2778\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2779\u001b[0m )\n\u001b[0;32m-> 2781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2784\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/models/bart/tokenization_bart_fast.py:272\u001b[0m, in \u001b[0;36mBartTokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_split_into_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:517\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    497\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    516\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 517\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/models/bart/tokenization_bart_fast.py:261\u001b[0m, in \u001b[0;36mBartTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_split_into_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py465/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:445\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    438\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    439\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    443\u001b[0m )\n\u001b[0;32m--> 445\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    457\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    459\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    469\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextInputSequence must be str"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "stream_comments = [\n",
    "    \"its_pam_ela: That chatter was wrong you can’t just pay something\",\n",
    "    \"ZeroTepMusic: 12\",\n",
    "    \"lysinehd: crabs in a bucket\",\n",
    "    \"bouillabased: my life's biggest mistake was trusting my parents, especially when they told me education was the key to success.\",\n",
    "    \"kylanc6: Americas is full of so many people with fucking peasant brain\",\n",
    "    \"Replying to @spyderfrommars: btw, so many people have filed for bankruptcy and that used to mean having your debts forgiven. Probably many chatters parents have. SO MANY PEOPLE IN THE POLITICAL ARENA HAVE HAD THEIR DEBTS FORGIVEN. It's so stupid to use that arguementshainybug: and bankruptcy doesn't wipe student loans \",\n",
    "    \"MarIsMar: Corpa\",\n",
    "    \"IsThatSalem: I hate this\",\n",
    "    \"eronin37:   \",\n",
    "    \"v3sh_:  HYPERCLAP turn education into businesses\",\n",
    "    \"hondewberry: CHATTERS NO, LET'S DO FUN SHIT BABY WHAT YOU DOIN\",\n",
    "    \"JEZZ_7: Corpa\",\n",
    "    \"xTrashPandaKingx: @HasanAbi you dont understand they're like one or two lucky breaks from being the 1%\",\n",
    "    \"fearandrespect: Man that's a weird boot to be licking, chatter what the hell\",\n",
    "    \"PrettyKrazy: profit motive destroys humanity\",\n",
    "    \"Sutiibun_: \",\n",
    "    \"qwertyopsd2: Chatting really Hasan?\",\n",
    "    \"Tamarama02: \\\"I couldn't care less.\\\"\",\n",
    "    \"whitneythegoth: YEP LEECHES\",\n",
    "    \"FriedWaffles:  just don't get sick or hurt\",\n",
    "    \"redeyeink: gatekeeping and control over labor conditions\",\n",
    "    \"BigDddyNick: sugar dads in chat?\",\n",
    "    \"austrom: Corpa\",\n",
    "    \"HalalChad_: America is a massive corporation\",\n",
    "    \"russianspy619: Chatting I'm very smart\",\n",
    "    \"dankusdingus: hasCapital\",\n",
    "    \"dr_desu:  gimme gimme gimme\",\n",
    "    \"LateAndNever: Pivo . o O ( Corpa 🔫  )\",\n",
    "    \"phoneofff: @ashlynnicoleramirez report yourself as poor and never tell them anything ever again\",\n",
    "    \"ADK_215: they want to make money of your student loan debt how do you guys not see this\",\n",
    "    \"Leafy_Sh4de: Hey Hasan! My man! I know I longed for some twitch political commentary\",\n",
    "    \"WhyYouGotNecklace: YEP just looking for more capital avenues\",\n",
    "    \"meredyke: To profit in anyway imaginable\",\n",
    "    \"imLunchy: Corpa private prisons\",\n",
    "    \"thottopic666: YEP 󠀀\",\n",
    "    \"thelookoutshift: that chatter didn't pay their loan and the govt took back their degree via lobotomy @hasanabi\",\n",
    "    \"whataburgerfancyketchup: Knowledge is power Hasan. Its that simple. Keep people dumb, keep them powerless. @HasanAbi\",\n",
    "    \"aquamiguel: Chatting 󠀀\",\n",
    "    \"ya_plis: they need a controlled working force\",\n",
    "    \"ShakeN_Bake: Fuck them\",\n",
    "    \"moogerfooger_: can't get blood from a stone Crungo\",\n",
    "    \"sandsim: making 17 year olds take loans out OMEGALUL\",\n",
    "    \"stovetotheface: keep the masses dumb\",\n",
    "    \"Resubscribe: @luckypompom qalla_s modCheck\",\n",
    "    \"tr0piKEL1: I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills  they don’t report it to credit as long as you pay.\",\n",
    "    \"rentcontrolryan: just get a full ride scholarship EZ Chatting\",\n",
    "    \"shoriu_: chat is so annoying today\",\n",
    "    \"TheUh0hOreo:  HYPERCLAP\",\n",
    "    \"Replying to @ashlynnicoleramirez: income driven repayment plan and stay poor forevershainybug: me lmao\",\n",
    "    \"Shonnicus: paying a portion, you are still getting killed on the backend with interest. That's why they are fine with you not making full payments\",\n",
    "    \"catboy_rai: housing, food, etc.\",\n",
    "    \"YukiTsunoda__: \",\n",
    "    \"hashoe23: TATE\",\n",
    "    \"Faviahn: Because they're told they have to pay more in taxes and have less money when they're already struggling.\",\n",
    "    \"duskdeserter: this country fucken sucks\",\n",
    "    \"HerrosRevenge: ultimatley this argument boils down to \\\"its your fault for wanting to live and be happy\\\" most people dont want to go to school to work for the rest of their lives while paying to do so\",\n",
    "    \"seeayy: almost every aspect of higher education is profitable\",\n",
    "    \"chelseymakes: Daddy chill 🫠\",\n",
    "    \"TehAdamBomb: profit motives drive innocation \",\n",
    "    \"lordcharliesheen: YEE HAWWWW\",\n",
    "    \"HUGEGAMER96: Military YEP\",\n",
    "    \"clandestinie: Affordable but not always available\",\n",
    "    \"big_dykeenergy: i’m below the income threshold so i get a payment of zero. i should clarify that i WORK FOR THE GOVERNMENT and i’m not paid enough to meet the thresholds\",\n",
    "    \"aquamiguel: Corpa Clap\",\n",
    "    \"bignachysosa: Healthcare doesnt have to be free but it SHOULDNT be private\",\n",
    "    \"Cypres_warluckHyan8: americas kindaa fuked rn\",\n",
    "    \"ZuzieZozo: I literally had a free operation\",\n",
    "    \"quarantinewolf: Chatting Hasan @Hasanabi @Hasanthehun @Freedomeaglefuck\",\n",
    "    \"IgiveBluebells: Educaiton is overpriced in the US\",\n",
    "    \"librapelican: theres a reason my sociology class presented american exceptionalism as a form of propaganda\",\n",
    "    \"xygeek: @hasanabi allow for bankruptcy, then normalize bankruptcy at graduation. Problem solved. KEKW\",\n",
    "    \"Skill_Cylinder: YEP just join the military\",\n",
    "    \"Hagasha: \",\n",
    "    \"bigstephfan: and here healthcare is so fucking expensive.\",\n",
    "    \"BOATPARADE: can't have an educated proletariat\",\n",
    "    \"RoguePr1nc355: Now it is about political ideology\",\n",
    "    \"Zony66: you cant even have a fucking hobby without people asking you \\\"well how are you gunna make any money with that?\\\"\",\n",
    "    \"cas3_: no war but class war\",\n",
    "    \"Replying to @tr0piKEL1: I do that on medical bills as protest. I pay like $25/mo on $4,000 hospital bills rhyzKEK they don’t report it to credit as long as you pay.aspiration89: YEP 󠀀\",\n",
    "    \"SimUser:  You want my number to not go up???\",\n",
    "    \"politicsenjoyer:  dumb consumer slaves\",\n",
    "    \"narjuh: more than South Korea?\",\n",
    "    \"punishedribcorn: Education isnt free for the same reason healthcare isnt free. Because you cant live without it @hasanabi\",\n",
    "    \"GanjarDanks: @hasanabi true reason that education isn't free and student loans reign supreme is slabs\",\n",
    "    \"ok_eevee:  Paywall the labor force @hasanabi\",\n",
    "    \"kintu: there are worse neoliberal hellholes out there Aware\",\n",
    "    \"esquerdomacho: I can get a free heart transplant in Brazil if I want MmmHmm\",\n",
    "    \"lagsanaglasscoke: Corpa hehe\",\n",
    "    \"ComradeCussy: Freedom ain't free brother @HasanAbi\",\n",
    "    \"eronin37:   💵\",\n",
    "    \"calimarx: It’s to maintain order\",\n",
    "    \"PrettyKrazy: profit motive deprives every successful system\",\n",
    "    \"SpanoNanoChano: even textbooks are a literal racket\",\n",
    "    \"bignachysosa: Federalize it let the government deal with paying hospitals and doctors\",\n",
    "    \"happppy_ant: YEP\",\n",
    "    \"lardball1: @HasanAbi an educated proletariat is dynamite, like that reagan advisor said\",\n",
    "    \"Replying to @ZuzieZozo: I literally had a free operationBurnzorr: You are one person\",\n",
    "    \"PoogDoog: HE SAID THE THING LETSGO\",\n",
    "    \"1337h4x: BALD POTATO PEELER OMEGALUL\",\n",
    "    \"cms100210: All these things exist in countries hence it can work\",\n",
    "    \"HVYHTTRS_: The biggest scam in college is the BOOKS, some good docs about it\",\n",
    "    \"Eevee_Sprinkle:  Keep on licking the boot, GED Andy's.\",\n",
    "    \"bakhtiari_veneco: Stupid question, is South Korea less capitalistic than America? @hasanabi\",\n",
    "    \"JaychanLive:  WineTime PROFIT FIRST  WineTime\",\n",
    "    \"whataburgerfancyketchup: Thats Me Pog\",\n",
    "    \"dumpster27: message deleted by a moderator.\",\n",
    "    \"moogerfooger_: like paying less than $15 min wage\",\n",
    "    \"happppy_ant: YEP control\",\n",
    "    \"Shroomie1707: Do you think you should be able to run for president if you are in jail @hasanabi\",\n",
    "    \"DavidTheDaybed: D:\",\n",
    "    \"Replying to @bignachysosa: Healthcare doesnt have to be free but it SHOULDNT be privateqwertyopsd2: it should be free\",\n",
    "    \"Zpectr3: I pay like 300 Euros for university every semester in germany , but like 250 are for public transport. This shit is insane in the us @HasanAbi\",\n",
    "    \"RamenBellic: @Baldpotatopeeler we just need to decommodify education.\",\n",
    "    \"dicesettle: Lol. Don't do that\",\n",
    "    \"mrbuddybuddy: KEKWait\",\n",
    "    \"RowdyRoran: bro has been following for 3 years and is asking this now?\",\n",
    "    \"sassoune: SORRY WE CAN BAIL OUT CMBS AT 30% purchase price - but when it comes to student loans we’re back to archaic - loan - predatory interest gurg payback or go die\",\n",
    "    \"Darksoul9669: @hasanabi yeah man it was my own actions that had every part of my schooling telling me to take out loans and go to college as the only option and there being basically no downside. Really interesting how high school blows right through how devastating these loans were gonna be during these discussions when i was fucking 17 YEARS OLD\",\n",
    "    \"Tetratera: university is free for everyone in argentina including foreigners, and you don't even have to take a standardized test, only have finished high school (and know upper intermediate spanish)\",\n",
    "    \"lysinehd: permanent desperate underclass\",\n",
    "    \"FALS3_g0D: crusing debt made to keep you a servant to the system\",\n",
    "    \"sandsim: literally scamming children\",\n",
    "    \"atsign_: literally other countries can do it for free. is america not exceptional enough to do it?\",\n",
    "    \"dumpster27: message deleted by a moderator.\",\n",
    "    \"Fossabot: @dumpster27, Excessive spamming [warning]\",\n",
    "    \"WeasleyLittleLiar: Did not used to cost that much\",\n",
    "    \"rex__havoc: @hasanabi Have you talked about the new IDR plan \\\"SAVE\\\"? you're payments can be as low as 0/month\",\n",
    "    \"thottopic666: every single aspect of this country was designed to suck the citizens dry as efficiently as possible\",\n",
    "    \"c_d1999: Ask that chatter why don’t we charge for public high school!??\",\n",
    "    \"thehappyparadox: YEP\",\n",
    "    \"Skill_Cylinder: YEP\",\n",
    "    \"kaimehra: yep\",\n",
    "    \"kait516: YEP YEP YEP\",\n",
    "    \"canola_oil: YEP\",\n",
    "    \"thottopic666: YEP\",\n",
    "    \"Hagasha: YEP\"\n",
    "]\n",
    "\n",
    "stream_comments += [\n",
    "    \"MER_AKI: bro thinks hes him lol\",\n",
    "    \"xmas31: That spray so mad u really him\",\n",
    "    \"o7draco: ECO DEMON FRFR\",\n",
    "    \"tko0_: UR SO LUCKY\",\n",
    "    \"SparkYYY_123: SO LUCKY\",\n",
    "    \"extratiarestrial: EWWWW\",\n",
    "    \"tomas2brazy: Derke moment\",\n",
    "    \"abhi_142: ECO king\",\n",
    "    \"psygonnn: yeah yeah tarik we know you are going pro\",\n",
    "    \"autumn0999: LOL\",\n",
    "    \"betasimp42: Derke you was right Aware\",\n",
    "    \"grandpafroggys: eco demon\",\n",
    "    \"xDieWithPridex: whats his dpi and sens?\",\n",
    "    \"lowertaxrates: KEKW ur insane sometimes\",\n",
    "    \"PhanzGFX: A real one would get an ace there\",\n",
    "    \"gangliaa: he predicted this\",\n",
    "    \"MrKing8: KEKW\",\n",
    "    \"AyoJabo: ECOOOO FRAGGGGGGER\",\n",
    "    \"MandyLynx: calm down buddy\",\n",
    "    \"Neon_Phaser: derke said it\",\n",
    "    \"Fossabot: Hey, are you following tarik on Twitter? http://twitter.com/tarik\",\n",
    "    \"rishon26: STOP OVERPEEKING LMFAO\",\n",
    "    \"nopointgamer: eco frags\",\n",
    "    \"demon_sl4: any cs2 news?\",\n",
    "    \"aidenvovn420: overheat\",\n",
    "    \"danielmacttv: You are him\",\n",
    "    \"atinyspec: hallo\",\n",
    "    \"GorillaTangie: KEKW\",\n",
    "    \"ghost_khtab: KEKW\",\n",
    "    \"丁乚仨乂 (tlex): KLİİPPPPPPPP\",\n",
    "    \"oikawies: well ur consistent at overheating\",\n",
    "    \"ZqCyzreN: ecobra\",\n",
    "    \"ayoub_hh: ns\",\n",
    "    \"bearrynice: @tarik you can satchel? Since when Lil bro\",\n",
    "    \"KorHun_Official: kangkang gets 5 here @tarik\",\n",
    "    \"suus001: OHHHH SHIT\",\n",
    "    \"ub_zinio: overheaaat\",\n",
    "    \"ironman_ap: sup ? @Derke\",\n",
    "    \"Schabii97: DERKE W\",\n",
    "    \"Grediann: overpeak = die Shruge\",\n",
    "    \"jaybird1014: SIT DOWN PLS\",\n",
    "    \"ayswoosh: @Derke how were champs?\",\n",
    "    \"nishikoto: NASTY\",\n",
    "    \"thickymonster: !duo\",\n",
    "    \"wddcruz: 3King\",\n",
    "    \"sqawg: Lil bro humbled himself\",\n",
    "    \"Replying to @thickymonster: !duoFossabot: Asuna AYAYA\",\n",
    "    \"littlesmchallowen: do that next round kekw\",\n",
    "    \"davidakachuwy: COOKED then OVERPEEKED\",\n",
    "    \"MER_AKI: you are not himothy\",\n",
    "    \"lotace:     \",\n",
    "    \"ditt0o: we've got huge bets don't ROZA\",\n",
    "    \"gme16: that spray transfer was lit as\",\n",
    "    \"iicpr: overheat\",\n",
    "    \"daymare5: it was horrible\",\n",
    "    \"Sigfreed: NA BRAIN KEKW\",\n",
    "    \"samsaraeyess: that spray transfer made me ink\",\n",
    "    \"hwhevevsvb: no\",\n",
    "    \"suus001: TUROK TUROK TUROK\",\n",
    "    \"SilintNight: OMEGALUL\",\n",
    "    \"Derke: NO\",\n",
    "    \"mr_01ne: Derke knew it\",\n",
    "    \"Replying to @Derke: i told uQuanFuPanda: deadass\",\n",
    "    \"dioholic: terue\",\n",
    "    \"ta3sk1: THIS TEAM IS FUCKING GOATED TARIK/STEW/ASUNA GGZ\",\n",
    "    \"rue__s: heeey\",\n",
    "    \"abcdgwenchana: overheat on eco\",\n",
    "    \"AdderallBeforeBed: bet you can't do it again MmmHmm\",\n",
    "    \"sissimou: fax\",\n",
    "    \"xcrimsoncrookx: bro thinks the transfer was intentional AINTNOWAY\",\n",
    "    \"adityasanas001: Ecodemon\",\n",
    "    \"dioholic: true\",\n",
    "    \"Lefluu: stew did everything there @tarik\",\n",
    "    \"CosmicDeven: two eco frags and we start talking shit on derke KEKW\",\n",
    "    \"Benjjamin: If you get 3 you're allowed to throw\",\n",
    "    \"afor_f: its true\",\n",
    "    \"Derke: IF ITS 5V1\",\n",
    "    \"Harnasiek03: true\",\n",
    "    \"lowertaxrates: no?\",\n",
    "    \"ketosaiba11: replace jinggg no?\",\n",
    "    \"theak44: BLABBERING BLABBERING\",\n",
    "    \"Derke: AND I DIE FIRST\",\n",
    "    \"laiiiny: You should apply for observer in VCT\",\n",
    "    \"itsrawkus: wake up\",\n",
    "    \"tripharder: ahh yes the rule\",\n",
    "    \"shruggy8: TRUEING\",\n",
    "    \"autumn0999: nice fucking shots tho\",\n",
    "    \"Derke: ITS MY FAULT\",\n",
    "    \"rishon26: @Derke get this man on fnatic\",\n",
    "    \"OzGunAim: !sens\",\n",
    "    \"Fossabot: CSGO: 1.5 @ 800 DPI, VALORANT: .471 800 DPI\",\n",
    "    \"JRD_Nath: \",\n",
    "    \"xdpotatolord: @tarik UR BICEPS ARE HUGE!!!\",\n",
    "    \"xkillo147: True, NA rule\",\n",
    "    \"gentlecpu: KEKW if you get 1 it's not your fault\",\n",
    "    \"jinsoooo: if you get 2 you go for the ace\",\n",
    "    \"rightylucy: Lkekw\",\n",
    "    \"lionbrav3: C9 VIBEZ\",\n",
    "    \"emil__val: KEKW KEKW\",\n",
    "    \"maareeyyyy: !mouse\",\n",
    "    \"FarmerFelox: In NA if you get 1 go for 5\",\n",
    "    \"abcdgwenchana: eco frag\",\n",
    "    \"alirezathe1: !res\",\n",
    "    \"Fossabot: DeathAdder V3 Pro\",\n",
    "    \"Fossabot: Val 16:10 (1680x1050) - CSGO: 1280x960\",\n",
    "    \"CaliKillz3: TRUEING\",\n",
    "    \"rentr04: homie turned up cuz derke is watching. respect\",\n",
    "    \"hyp3r10n2: @tarik gets 3 wins round then overfaces and gets mad for it xD\",\n",
    "    \"rightylucy: KEKW\",\n",
    "    \"riyuoh: IF U GET 3 YOU CAN OVERHEAT 100%\",\n",
    "    \"PiquesGaming: thats facts tho\",\n",
    "    \"gkhn94: Dayi bi kere turkce konus be\",\n",
    "    \"Sigfreed: LOOK ITS A 1V1 NOW\",\n",
    "    \"丁乚仨乂 (tlex): KLİPPP\",\n",
    "    \"myinnerfaye: Himothy is that you?\",\n",
    "    \"Maximus6267: KEKW no way\",\n",
    "    \"tsylogy: @Derke 5V1 DSG Aware\",\n",
    "    \"ub_zinio: derkes fault\",\n",
    "    \"itzzero3: arabic blood\",\n",
    "    \"shruggy8: gonna lose PepeLaugh\",\n",
    "    \"Sigfreed: ITS A FUCKING 1V1 NOW\",\n",
    "    \"Replying to @lionbrav3: C9 VIBEZXeppaa: ?\",\n",
    "    \"ItsTavyy: maybe you need to peek more @tarik\",\n",
    "    \"danielmacttv: Its DERKE’s fault\",\n",
    "    \"dexterityCS: KEKW 󠀀\",\n",
    "    \"Rickz10K: KEKW KEKW KEKW KEKW\",\n",
    "    \"kaizo_rm: HUH 󠀀\",\n",
    "    \"slaxxxyyyy: Fair enuff\",\n",
    "    \"diipsy9: AYOO HH\",\n",
    "    \"h1k1k0_: HUH\",\n",
    "    \"m0gi08: !gekko\",\n",
    "    \"Apollo_Neptune: HUH\",\n",
    "    \"Fossabot: LilBro it's gekkin time ezz\",\n",
    "    \"siwa33: Close gamba mods\",\n",
    "    \"wahbi_79: HUH\",\n",
    "    \"xelzttv: HUH\",\n",
    "    \"emil__val: KEKW\",\n",
    "    \"ig5mindhacker: HUH\",\n",
    "    \"krasqu33: HUH\",\n",
    "    \"aqilus: HUH\",\n",
    "    \"Jordbaermelk: WOT\",\n",
    "    \"derkesdoormat: @derke OOO DERKE'S HERE HII\",\n",
    "    \"beepbopp11: HUH\",\n",
    "    \"cenk4k: HUH\",\n",
    "    \"mrsteallyourcat: HUH\",\n",
    "    \"xclaassic: true\",\n",
    "    \"Aethielle: HUH\",\n",
    "    \"cyb_eric: HUH\",\n",
    "    \"shruggy8: Sadge\",\n",
    "    \"mesme_R: HUH\"\n",
    "]\n",
    "stream_comments = [comment.split(':')[1] for comment in stream_comments]\n",
    "stream_comments = [comment for comment in stream_comments if len(comment.strip()) > 0]\n",
    "    \n",
    "premise = stream_comments[:10]\n",
    "label = 'cool'\n",
    "hypothesis = f'This example is {label}.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "logits = nli_model(x.to('cpu'))[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "prob_label_is_true = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_label_is_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "(summarizer(stream_comments, max_length=20, min_length=5, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fb3fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stream_comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m sequence_to_classify \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone day I will see the world\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m candidate_labels \u001b[38;5;241m=\u001b[39m classifications\n\u001b[0;32m---> 28\u001b[0m classifier(\u001b[43mstream_comments\u001b[49m[\u001b[38;5;241m0\u001b[39m], candidate_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stream_comments' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "sentiments = sentiment_pipeline(stream_comments)\n",
    "\n",
    "[f\"{stream_comments[i]}   {sentiments[i]['label']}  {sentiments[i]['score']}\" for i, char in enumerate(sentiments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "+from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
    "inputs = tokenizer(\"eat lots of green beans and black eyed \", return_tensors=\"pt\").input_ids\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)\n",
    "\n",
    "[tokenizer.decode(string, skip_special_tokens=True) for string in outputs]\n",
    "\n",
    "\n",
    "#get summary of them\n",
    "#organize by cluster\n",
    "    #sentiment\n",
    "    \n",
    "    \n",
    "#download clips https://youtu.be/HigmUsGEEww -> get transcript to provide tagging\n",
    "#download https://www.youtube.com/watch?v=HigmUsGEEww&feature=youtu.be&ab_channel=Joe-Astro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4101c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "## Setting to use the 0th GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "## Setting to use the bart-large-cnn model for summarization\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "## To use the t5-base model for summarization:\n",
    "## summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
    "text = \"\"\"One month after the United States began what has become a troubled rollout of a national COVID vaccination campaign, the effort is finally gathering real steam.\n",
    "Close to a million doses -- over 951,000, to be more exact -- made their way into the arms of Americans in the past 24 hours, the U.S. Centers for Disease Control and Prevention reported Wednesday. That's the largest number of shots given in one day since the rollout began and a big jump from the previous day, when just under 340,000 doses were given, CBS News reported.\n",
    "That number is likely to jump quickly after the federal government on Tuesday gave states the OK to vaccinate anyone over 65 and said it would release all the doses of vaccine it has available for distribution. Meanwhile, a number of states have now opened mass vaccination sites in an effort to get larger numbers of people inoculated, CBS News reported.\"\"\"\n",
    "#Summarize\n",
    "summary_text = summarizer('\\n'.join(stream_comments)[:1022], max_length=100, min_length=5, do_sample=False)[0]['summary_text']\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68091c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getClusters(sentences):\n",
    "    clusters = util.community_detection(encode(sentences), min_community_size=1, threshold=0.5)\n",
    "    clusters\n",
    "\n",
    "    def process(item): return [sentences[i] for i in item]\n",
    "    result = [process(item) for item in clusters ]\n",
    "    return result\n",
    "\n",
    "clusters = getClusters(stream_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dab9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiktionaryparser import WiktionaryParser\n",
    "\n",
    "parser = WiktionaryParser()\n",
    "word = parser.fetch('eating')\n",
    "#another_word = parser.fetch('test', 'french')\n",
    "# parser.set_default_language('french')\n",
    "# parser.exclude_part_of_speech('noun')\n",
    "# parser.include_relation('alternative forms')\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb40cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pre-trained Word2Vec model\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def generalize_word(word):\n",
    "    try:\n",
    "        similar_words = w2v_model.most_similar(positive=[word], topn=5)\n",
    "        generalized_word = similar_words[0][0]  # Get the most similar word\n",
    "        return generalized_word\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "word = \"cake\"\n",
    "generalized_word = generalize_word(word)\n",
    "if generalized_word:\n",
    "    print(f\"The generalized term for '{word}' is '{generalized_word}'.\")\n",
    "else:\n",
    "    print(f\"No generalization found for '{word}'.\")\n",
    "\n",
    "word = \"burger\"\n",
    "generalized_word = generalize_word(word)\n",
    "if generalized_word:\n",
    "    print(f\"The generalized term for '{word}' is '{generalized_word}'.\")\n",
    "else:\n",
    "    print(f\"No generalization found for '{word}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize heckling\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def generalize_word(word):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    \n",
    "    if not synsets:\n",
    "        return None\n",
    "    \n",
    "    # Get the first synset (most common meaning)\n",
    "    synset = synsets[0]\n",
    "    \n",
    "    # Find hypernyms (more general terms)\n",
    "    hypernyms = synset.hypernyms()\n",
    "    \n",
    "    if not hypernyms:\n",
    "        return None\n",
    "    \n",
    "    # Get the first hypernym (more general term)\n",
    "    hypernym = hypernyms[0]\n",
    "    \n",
    "    # Extract the lemma name of the hypernym\n",
    "    generalized_word = hypernym.lemmas()[0].name()\n",
    "    \n",
    "    return generalized_word\n",
    "\n",
    "word = \"toast\"\n",
    "generalized_word = generalize_word(word)\n",
    "if generalized_word:\n",
    "    print(f\"The generalized term for '{word}' is '{generalized_word}'.\")\n",
    "else:\n",
    "    print(f\"No generalization found for '{word}'.\")\n",
    "\n",
    "word = \"hamburger\"\n",
    "generalized_word = generalize_word(word)\n",
    "if generalized_word:\n",
    "    print(f\"The generalized term for '{word}' is '{generalized_word}'.\")\n",
    "else:\n",
    "    print(f\"No generalization found for '{word}'.\")\n",
    "    \n",
    "    \n",
    "t = wordnet.synsets('popcorn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b4ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicTitle(text):\n",
    "    print('translating ' + text)\n",
    "    prompt = f\"How would you classify '{text}' as a topic?\"\n",
    "    first = time.perf_counter()\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    second = time.perf_counter()\n",
    "    print(second - first)\n",
    "    translation = response.choices[0].message.content.strip()\n",
    "    return translation\n",
    "\n",
    "getTopicTitle(stream_comments[10])\n",
    "\n",
    "stream_comments[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc60c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rh= \"\"\"Talk at Bellcore, 7 March 1986\n",
    "\n",
    "The title of my talk is \"You and Your Research.\" It is not about managing research, it is about how you individually do your research. I could give a talk on the other subject — but it's not, it's about you. I'm not talking about ordinary run-of-the-mill research; I'm talking about great research. And for the sake of describing great research I'll occasionally say Nobel-Prize type of work. It doesn't have to gain the Nobel Prize, but I mean those kinds of things which we perceive are significant things. Relativity, if you want, Shannon's information theory, any number of outstanding theories — that's the kind of thing I'm talking about.\n",
    "\n",
    "Now, how did I come to do this study? At Los Alamos I was brought in to run the computing machines which other people had got going, so those scientists and physicists could get back to business. I saw I was a stooge. I saw that although physically I was the same, they were different. And to put the thing bluntly, I was envious. I wanted to know why they were so different from me. I saw Feynman up close. I saw Fermi and Teller. I saw Oppenheimer. I saw Hans Bethe: he was my boss. I saw quite a few very capable people. I became very interested in the difference between those who do and those who might have done.\n",
    "\n",
    "When I came to Bell Labs, I came into a very productive department. Bode was the department head at the time; Shannon was there, and there were other people. I continued examining the questions, \"Why?\" and \"What is the difference?\" I continued subsequently by reading biographies, autobiographies, asking people questions such as: \"How did you come to do this?\" I tried to find out what are the differences. And that's what this talk is about.\n",
    "\n",
    "Now, why is this talk important? I think it is important because, as far as I know, each of you has one life to live. Even if you believe in reincarnation it doesn't do you any good from one life to the next! Why shouldn't you do significant things in this one life, however you define significant? I'm not going to define it — you know what I mean. I will talk mainly about science because that is what I have studied. But so far as I know, and I've been told by others, much of what I say applies to many fields. Outstanding work is characterized very much the same way in most fields, but I will confine myself to science.\n",
    "\n",
    "In order to get at you individually, I must talk in the first person. I have to get you to drop modesty and say to yourself, \"Yes, I would like to do first-class work.\" Our society frowns on people who set out to do really good work. You're not supposed to; luck is supposed to descend on you and you do great things by chance. Well, that's a kind of dumb thing to say. I say, why shouldn't you set out to do something significant. You don't have to tell other people, but shouldn't you say to yourself, \"Yes, I would like to do something significant.\"\n",
    "\n",
    "In order to get to the second stage, I have to drop modesty and talk in the first person about what I've seen, what I've done, and what I've heard. I'm going to talk about people, some of whom you know, and I trust that when we leave, you won't quote me as saying some of the things I said.\n",
    "\n",
    "Let me start not logically, but psychologically. I find that the major objection is that people think great science is done by luck. It's all a matter of luck. Well, consider Einstein. Note how many different things he did that were good. Was it all luck? Wasn't it a little too repetitive? Consider Shannon. He didn't do just information theory. Several years before, he did some other good things and some which are still locked up in the security of cryptography. He did many good things.\n",
    "\n",
    "You see again and again that it is more than one thing from a good person. Once in a while a person does only one thing in his whole life, and we'll talk about that later, but a lot of times there is repetition. I claim that luck will not cover everything. And I will cite Pasteur who said, \"Luck favors the prepared mind.\" And I think that says it the way I believe it. There is indeed an element of luck, and no, there isn't. The prepared mind sooner or later finds something important and does it. So yes, it is luck. The particular thing you do is luck, but that you do something is not.\n",
    "\n",
    "For example, when I came to Bell Labs, I shared an office for a while with Shannon. At the same time he was doing information theory, I was doing coding theory. It is suspicious that the two of us did it at the same place and at the same time — it was in the atmosphere. And you can say, \"Yes, it was luck.\" On the other hand you can say, \"But why of all the people in Bell Labs then were those the two who did it?\" Yes, it is partly luck, and partly it is the prepared mind; but \"partly\" is the other thing I'm going to talk about. So, although I'll come back several more times to luck, I want to dispose of this matter of luck as being the sole criterion whether you do great work or not. I claim you have some, but not total, control over it. And I will quote, finally, Newton on the matter. Newton said, \"If others would think as hard as I did, then they would get similar results.\"\n",
    "\n",
    "One of the characteristics you see, and many people have it including great scientists, is that usually when they were young they had independent thoughts and had the courage to pursue them. For example, Einstein, somewhere around 12 or 14, asked himself the question, \"What would a light wave look like if I went with the velocity of light to look at it?\" Now he knew that electromagnetic theory says you cannot have a stationary local maximum. But if he moved along with the velocity of light, he would see a local maximum. He could see a contradiction at the age of 12, 14, or somewhere around there, that everything was not right and that the velocity of light had something peculiar. Is it luck that he finally created special relativity? Early on, he had laid down some of the pieces by thinking of the fragments. Now that's the necessary but not sufficient condition. All of these items I will talk about are both luck and not luck.\n",
    "\n",
    "How about having lots of brains? It sounds good. Most of you in this room probably have more than enough brains to do first-class work. But great work is something else than mere brains. Brains are measured in various ways. In mathematics, theoretical physics, astrophysics, typically brains correlates to a great extent with the ability to manipulate symbols. And so the typical IQ test is apt to score them fairly high. On the other hand, in other fields it is something different. For example, Bill Pfann, the fellow who did zone melting, came into my office one day. He had this idea dimly in his mind about what he wanted and he had some equations. It was pretty clear to me that this man didn't know much mathematics and he wasn't really articulate. His problem seemed interesting so I took it home and did a little work. I finally showed him how to run computers so he could compute his own answers. I gave him the power to compute. He went ahead, with negligible recognition from his own department, but ultimately he has collected all the prizes in the field. Once he got well started, his shyness, his awkwardness, his inarticulateness, fell away and he became much more productive in many other ways. Certainly he became much more articulate.\n",
    "\n",
    "And I can cite another person in the same way. I trust he isn't in the audience, i.e. a fellow named Clogston. I met him when I was working on a problem with John Pierce's group and I didn't think he had much. I asked my friends who had been with him at school, \"Was he like that in graduate school?\" \"Yes,\" they replied. Well I would have fired the fellow, but J. R. Pierce was smart and kept him on. Clogston finally did the Clogston cable. After that there was a steady stream of good ideas. One success brought him confidence and courage.\n",
    "\n",
    "One of the characteristics of successful scientists is having courage. Once you get your courage up and believe that you can do important problems, then you can. If you think you can't, almost surely you are not going to. Courage is one of the things that Shannon had supremely. You have only to think of his major theorem. He wants to create a method of coding, but he doesn't know what to do so he makes a random code. Then he is stuck. And then he asks the impossible question, \"What would the average random code do?\" He then proves that the average code is arbitrarily good, and that therefore there must be at least one good code. Who but a man of infinite courage could have dared to think those thoughts? That is the characteristic of great scientists; they have courage. They will go forward under incredible circumstances; they think and continue to think.\n",
    "\n",
    "Age is another factor which the physicists particularly worry about. They always are saying that you have got to do it when you are young or you will never do it. Einstein did things very early, and all the quantum mechanic fellows were disgustingly young when they did their best work. Most mathematicians, theoretical physicists, and astrophysicists do what we consider their best work when they are young. It is not that they don't do good work in their old age but what we value most is often what they did early. On the other hand, in music, politics and literature, often what we consider their best work was done late. I don't know how whatever field you are in fits this scale, but age has some effect.\n",
    "\n",
    "But let me say why age seems to have the effect it does. In the first place if you do some good work you will find yourself on all kinds of committees and unable to do any more work. You may find yourself as I saw Brattain when he got a Nobel Prize. The day the prize was announced we all assembled in Arnold Auditorium; all three winners got up and made speeches. The third one, Brattain, practically with tears in his eyes, said, \"I know about this Nobel-Prize effect and I am not going to let it affect me; I am going to remain good old Walter Brattain.\" Well I said to myself, \"That is nice.\" But in a few weeks I saw it was affecting him. Now he could only work on great problems.\n",
    "\n",
    "When you are famous it is hard to work on small problems. This is what did Shannon in. After information theory, what do you do for an encore? The great scientists often make this error. They fail to continue to plant the little acorns from which the mighty oak trees grow. They try to get the big thing right off. And that isn't the way things go. So that is another reason why you find that when you get early recognition it seems to sterilize you. In fact I will give you my favorite quotation of many years. The Institute for Advanced Study in Princeton, in my opinion, has ruined more good scientists than any institution has created, judged by what they did before they came and judged by what they did after. Not that they weren't good afterwards, but they were superb before they got there and were only good afterwards.\n",
    "\n",
    "This brings up the subject, out of order perhaps, of working conditions. What most people think are the best working conditions, are not. Very clearly they are not because people are often most productive when working conditions are bad. One of the better times of the Cambridge Physical Laboratories was when they had practically shacks — they did some of the best physics ever.\n",
    "\n",
    "I give you a story from my own private life. Early on it became evident to me that Bell Laboratories was not going to give me the conventional acre of programming people to program computing machines in absolute binary. It was clear they weren't going to. But that was the way everybody did it. I could go to the West Coast and get a job with the airplane companies without any trouble, but the exciting people were at Bell Labs and the fellows out there in the airplane companies were not. I thought for a long while about, \"Did I want to go or not?\" and I wondered how I could get the best of two possible worlds. I finally said to myself, \"Hamming, you think the machines can do practically everything. Why can't you make them write programs?\" What appeared at first to me as a defect forced me into automatic programming very early. What appears to be a fault, often, by a change of viewpoint, turns out to be one of the greatest assets you can have. But you are not likely to think that when you first look the thing and say, \"Gee, I'm never going to get enough programmers, so how can I ever do any great programming?\"\n",
    "\n",
    "And there are many other stories of the same kind; Grace Hopper has similar ones. I think that if you look carefully you will see that often the great scientists, by turning the problem around a bit, changed a defect to an asset. For example, many scientists when they found they couldn't do a problem finally began to study why not. They then turned it around the other way and said, \"But of course, this is what it is\" and got an important result. So ideal working conditions are very strange. The ones you want aren't always the best ones for you.\n",
    "\n",
    "Now for the matter of drive. You observe that most great scientists have tremendous drive. I worked for ten years with John Tukey at Bell Labs. He had tremendous drive. One day about three or four years after I joined, I discovered that John Tukey was slightly younger than I was. John was a genius and I clearly was not. Well I went storming into Bode's office and said, \"How can anybody my age know as much as John Tukey does?\" He leaned back in his chair, put his hands behind his head, grinned slightly, and said, \"You would be surprised Hamming, how much you would know if you worked as hard as he did that many years.\" I simply slunk out of the office!\n",
    "\n",
    "What Bode was saying was this: Knowledge and productivity are like compound interest. Given two people of approximately the same ability and one person who works ten percent more than the other, the latter will more than twice outproduce the former. The more you know, the more you learn; the more you learn, the more you can do; the more you can do, the more the opportunity — it is very much like compound interest. I don't want to give you a rate, but it is a very high rate. Given two people with exactly the same ability, the one person who manages day in and day out to get in one more hour of thinking will be tremendously more productive over a lifetime. I took Bode's remark to heart; I spent a good deal more of my time for some years trying to work a bit harder and I found, in fact, I could get more work done. I don't like to say it in front of my wife, but I did sort of neglect her sometimes; I needed to study. You have to neglect things if you intend to get what you want done. There's no question about this.\n",
    "\n",
    "On this matter of drive Edison says, \"Genius is 99% perspiration and 1% inspiration.\" He may have been exaggerating, but the idea is that solid work, steadily applied, gets you surprisingly far. The steady application of effort with a little bit more work, intelligently applied is what does it. That's the trouble; drive, misapplied, doesn't get you anywhere. I've often wondered why so many of my good friends at Bell Labs who worked as hard or harder than I did, didn't have so much to show for it. The misapplication of effort is a very serious matter. Just hard work is not enough - it must be applied sensibly.\n",
    "\n",
    "There's another trait on the side which I want to talk about; that trait is ambiguity. It took me a while to discover its importance. Most people like to believe something is or is not true. Great scientists tolerate ambiguity very well. They believe the theory enough to go ahead; they doubt it enough to notice the errors and faults so they can step forward and create the new replacement theory. If you believe too much you'll never notice the flaws; if you doubt too much you won't get started. It requires a lovely balance. But most great scientists are well aware of why their theories are true and they are also well aware of some slight misfits which don't quite fit and they don't forget it. Darwin writes in his autobiography that he found it necessary to write down every piece of evidence which appeared to contradict his beliefs because otherwise they would disappear from his mind. When you find apparent flaws you've got to be sensitive and keep track of those things, and keep an eye out for how they can be explained or how the theory can be changed to fit them. Those are often the great contributions. Great contributions are rarely done by adding another decimal place. It comes down to an emotional commitment. Most great scientists are completely committed to their problem. Those who don't become committed seldom produce outstanding, first-class work.\n",
    "\n",
    "Now again, emotional commitment is not enough. It is a necessary condition apparently. And I think I can tell you the reason why. Everybody who has studied creativity is driven finally to saying, \"creativity comes out of your subconscious.\" Somehow, suddenly, there it is. It just appears. Well, we know very little about the subconscious; but one thing you are pretty well aware of is that your dreams also come out of your subconscious. And you're aware your dreams are, to a fair extent, a reworking of the experiences of the day. If you are deeply immersed and committed to a topic, day after day after day, your subconscious has nothing to do but work on your problem. And so you wake up one morning, or on some afternoon, and there's the answer. For those who don't get committed to their current problem, the subconscious goofs off on other things and doesn't produce the big result. So the way to manage yourself is that when you have a real important problem you don't let anything else get the center of your attention — you keep your thoughts on the problem. Keep your subconscious starved so it has to work on your problem, so you can sleep peacefully and get the answer in the morning, free.\n",
    "\n",
    "Now Alan Chynoweth mentioned that I used to eat at the physics table. I had been eating with the mathematicians and I found out that I already knew a fair amount of mathematics; in fact, I wasn't learning much. The physics table was, as he said, an exciting place, but I think he exaggerated on how much I contributed. It was very interesting to listen to Shockley, Brattain, Bardeen, J. B. Johnson, Ken McKay and other people, and I was learning a lot. But unfortunately a Nobel Prize came, and a promotion came, and what was left was the dregs. Nobody wanted what was left. Well, there was no use eating with them!\n",
    "\n",
    "Over on the other side of the dining hall was a chemistry table. I had worked with one of the fellows, Dave McCall; furthermore he was courting our secretary at the time. I went over and said, \"Do you mind if I join you?\" They can't say no, so I started eating with them for a while. And I started asking, \"What are the important problems of your field?\" And after a week or so, \"What important problems are you working on?\" And after some more time I came in one day and said, \"If what you are doing is not important, and if you don't think it is going to lead to something important, why are you at Bell Labs working on it?\" I wasn't welcomed after that; I had to find somebody else to eat with! That was in the spring.\n",
    "\n",
    "In the fall, Dave McCall stopped me in the hall and said, \"Hamming, that remark of yours got underneath my skin. I thought about it all summer, i.e. what were the important problems in my field. I haven't changed my research,\" he says, \"but I think it was well worthwhile.\" And I said, \"Thank you Dave,\" and went on. I noticed a couple of months later he was made the head of the department. I noticed the other day he was a Member of the National Academy of Engineering. I noticed he has succeeded. I have never heard the names of any of the other fellows at that table mentioned in science and scientific circles. They were unable to ask themselves, \"What are the important problems in my field?\"\n",
    "\n",
    "If you do not work on an important problem, it's unlikely you'll do important work. It's perfectly obvious. Great scientists have thought through, in a careful way, a number of important problems in their field, and they keep an eye on wondering how to attack them. Let me warn you, \"important problem\" must be phrased carefully. The three outstanding problems in physics, in a certain sense, were never worked on while I was at Bell Labs. By important I mean guaranteed a Nobel Prize and any sum of money you want to mention. We didn't work on (1) time travel, (2) teleportation, and (3) antigravity. They are not important problems because we do not have an attack. It's not the consequence that makes a problem important, it is that you have a reasonable attack. That is what makes a problem important. When I say that most scientists don't work on important problems, I mean it in that sense. The average scientist, so far as I can make out, spends almost all his time working on problems which he believes will not be important and he also doesn't believe that they will lead to important problems.\n",
    "\n",
    "I spoke earlier about planting acorns so that oaks will grow. You can't always know exactly where to be, but you can keep active in places where something might happen. And even if you believe that great science is a matter of luck, you can stand on a mountain top where lightning strikes; you don't have to hide in the valley where you're safe. But the average scientist does routine safe work almost all the time and so he (or she) doesn't produce much. It's that simple. If you want to do great work, you clearly must work on important problems, and you should have an idea.\n",
    "\n",
    "Along those lines at some urging from John Tukey and others, I finally adopted what I called \"Great Thoughts Time.\" When I went to lunch Friday noon, I would only discuss great thoughts after that. By great thoughts I mean ones like: \"What will be the role of computers in all of AT&T?\", \"How will computers change science?\" For example, I came up with the observation at that time that nine out of ten experiments were done in the lab and one in ten on the computer. I made a remark to the vice presidents one time, that it would be reversed, i.e. nine out of ten experiments would be done on the computer and one in ten in the lab. They knew I was a crazy mathematician and had no sense of reality. I knew they were wrong and they've been proved wrong while I have been proved right. They built laboratories when they didn't need them. I saw that computers were transforming science because I spent a lot of time asking \"What will be the impact of computers on science and how can I change it?\" I asked myself, \"How is it going to change Bell Labs?\" I remarked one time, in the same address, that more than one-half of the people at Bell Labs will be interacting closely with computing machines before I leave. Well, you all have terminals now. I thought hard about where was my field going, where were the opportunities, and what were the important things to do. Let me go there so there is a chance I can do important things.\n",
    "\n",
    "Most great scientists know many important problems. They have something between 10 and 20 important problems for which they are looking for an attack. And when they see a new idea come up, one hears them say \"Well that bears on this problem.\" They drop all the other things and get after it. Now I can tell you a horror story that was told to me but I can't vouch for the truth of it. I was sitting in an airport talking to a friend of mine from Los Alamos about how it was lucky that the fission experiment occurred over in Europe when it did because that got us working on the atomic bomb here in the US. He said \"No; at Berkeley we had gathered a bunch of data; we didn't get around to reducing it because we were building some more equipment, but if we had reduced that data we would have found fission.\" They had it in their hands and they didn't pursue it. They came in second!\n",
    "\n",
    "The great scientists, when an opportunity opens up, get after it and they pursue it. They drop all other things. They get rid of other things and they get after an idea because they had already thought the thing through. Their minds are prepared; they see the opportunity and they go after it. Now of course lots of times it doesn't work out, but you don't have to hit many of them to do some great science. It's kind of easy. One of the chief tricks is to live a long time!\n",
    "\n",
    "Another trait, it took me a while to notice. I noticed the following facts about people who work with the door open or the door closed. I notice that if you have the door to your office closed, you get more work done today and tomorrow, and you are more productive than most. But 10 years later somehow you don't know quite know what problems are worth working on; all the hard work you do is sort of tangential in importance. He who works with the door open gets all kinds of interruptions, but he also occasionally gets clues as to what the world is and what might be important. Now I cannot prove the cause and effect sequence because you might say, \"The closed door is symbolic of a closed mind.\" I don't know. But I can say there is a pretty good correlation between those who work with the doors open and those who ultimately do important things, although people who work with doors closed often work harder. Somehow they seem to work on slightly the wrong thing — not much, but enough that they miss fame.\n",
    "\n",
    "I want to talk on another topic. It is based on the song which I think many of you know, \"It ain't what you do, it's the way that you do it.\" I'll start with an example of my own. I was conned into doing on a digital computer, in the absolute binary days, a problem which the best analog computers couldn't do. And I was getting an answer. When I thought carefully and said to myself, \"You know, Hamming, you're going to have to file a report on this military job; after you spend a lot of money you're going to have to account for it and every analog installation is going to want the report to see if they can't find flaws in it.\" I was doing the required integration by a rather crummy method, to say the least, but I was getting the answer. And I realized that in truth the problem was not just to get the answer; it was to demonstrate for the first time, and beyond question, that I could beat the analog computer on its own ground with a digital machine. I reworked the method of solution, created a theory which was nice and elegant, and changed the way we computed the answer; the results were no different. The published report had an elegant method which was later known for years as \"Hamming's Method of Integrating Differential Equations.\" It is somewhat obsolete now, but for a while it was a very good method. By changing the problem slightly, I did important work rather than trivial work.\n",
    "\n",
    "In the same way, when using the machine up in the attic in the early days, I was solving one problem after another after another; a fair number were successful and there were a few failures. I went home one Friday after finishing a problem, and curiously enough I wasn't happy; I was depressed. I could see life being a long sequence of one problem after another after another. After quite a while of thinking I decided, \"No, I should be in the mass production of a variable product. I should be concerned with all of next year's problems, not just the one in front of my face.\" By changing the question I still got the same kind of results or better, but I changed things and did important work. I attacked the major problem — How do I conquer machines and do all of next year's problems when I don't know what they are going to be? How do I prepare for it? How do I do this one so I'll be on top of it? How do I obey Newton's rule? He said, \"If I have seen further than others, it is because I've stood on the shoulders of giants.\" These days we stand on each other's feet!\n",
    "\n",
    "You should do your job in such a fashion that others can build on top of it, so they will indeed say, \"Yes, I've stood on so and so's shoulders and I saw further.\" The essence of science is cumulative. By changing a problem slightly you can often do great work rather than merely good work. Instead of attacking isolated problems, I made the resolution that I would never again solve an isolated problem except as characteristic of a class.\n",
    "\n",
    "Now if you are much of a mathematician you know that the effort to generalize often means that the solution is simple. Often by stopping and saying, \"This is the problem he wants but this is characteristic of so and so. Yes, I can attack the whole class with a far superior method than the particular one because I was earlier embedded in needless detail.\" The business of abstraction frequently makes things simple. Furthermore, I filed away the methods and prepared for the future problems.\n",
    "\n",
    "To end this part, I'll remind you, \"It is a poor workman who blames his tools — the good man gets on with the job, given what he's got, and gets the best answer he can.\" And I suggest that by altering the problem, by looking at the thing differently, you can make a great deal of difference in your final productivity because you can either do it in such a fashion that people can indeed build on what you've done, or you can do it in such a fashion that the next person has to essentially duplicate again what you've done. It isn't just a matter of the job, it's the way you write the report, the way you write the paper, the whole attitude. It's just as easy to do a broad, general job as one very special case. And it's much more satisfying and rewarding!\n",
    "\n",
    "I have now come down to a topic which is very distasteful; it is not sufficient to do a job, you have to sell it. \"Selling\" to a scientist is an awkward thing to do. It's very ugly; you shouldn't have to do it. The world is supposed to be waiting, and when you do something great, they should rush out and welcome it. But the fact is everyone is busy with their own work. You must present it so well that they will set aside what they are doing, look at what you've done, read it, and come back and say, \"Yes, that was good.\" I suggest that when you open a journal, as you turn the pages, you ask why you read some articles and not others. You had better write your report so when it is published in the Physical Review, or wherever else you want it, as the readers are turning the pages they won't just turn your pages but they will stop and read yours. If they don't stop and read it, you won't get credit.\n",
    "\n",
    "There are three things you have to do in selling. You have to learn to write clearly and well so that people will read it, you must learn to give reasonably formal talks, and you also must learn to give informal talks. We had a lot of so-called `back room scientists.' In a conference, they would keep quiet. Three weeks later after a decision was made they filed a report saying why you should do so and so. Well, it was too late. They would not stand up right in the middle of a hot conference, in the middle of activity, and say, \"We should do this for these reasons.\" You need to master that form of communication as well as prepared speeches.\n",
    "\n",
    "When I first started, I got practically physically ill while giving a speech, and I was very, very nervous. I realized I either had to learn to give speeches smoothly or I would essentially partially cripple my whole career. The first time IBM asked me to give a speech in New York one evening, I decided I was going to give a really good speech, a speech that was wanted, not a technical one but a broad one, and at the end if they liked it, I'd quietly say, \"Any time you want one I'll come in and give you one.\" As a result, I got a great deal of practice giving speeches to a limited audience and I got over being afraid. Furthermore, I could also then study what methods were effective and what were ineffective.\n",
    "\n",
    "While going to meetings I had already been studying why some papers are remembered and most are not. The technical person wants to give a highly limited technical talk. Most of the time the audience wants a broad general talk and wants much more survey and background than the speaker is willing to give. As a result, many talks are ineffective. The speaker names a topic and suddenly plunges into the details he's solved. Few people in the audience may follow. You should paint a general picture to say why it's important, and then slowly give a sketch of what was done. Then a larger number of people will say, \"Yes, Joe has done that,\" or \"Mary has done that; I really see where it is; yes, Mary really gave a good talk; I understand what Mary has done.\" The tendency is to give a highly restricted, safe talk; this is usually ineffective. Furthermore, many talks are filled with far too much information. So I say this idea of selling is obvious.\n",
    "\n",
    "Let me summarize. You've got to work on important problems. I deny that it is all luck, but I admit there is a fair element of luck. I subscribe to Pasteur's \"Luck favors the prepared mind.\" I favor heavily what I did. Friday afternoons for years — great thoughts only — means that I committed 10% of my time trying to understand the bigger problems in the field, i.e. what was and what was not important. I found in the early days I had believed `this' and yet had spent all week marching in `that' direction. It was kind of foolish. If I really believe the action is over there, why do I march in this direction? I either had to change my goal or change what I did. So I changed something I did and I marched in the direction I thought was important. It's that easy.\n",
    "\n",
    "Now you might tell me you haven't got control over what you have to work on. Well, when you first begin, you may not. But once you're moderately successful, there are more people asking for results than you can deliver and you have some power of choice, but not completely. I'll tell you a story about that, and it bears on the subject of educating your boss. I had a boss named Schelkunoff; he was, and still is, a very good friend of mine. Some military person came to me and demanded some answers by Friday. Well, I had already dedicated my computing resources to reducing data on the fly for a group of scientists; I was knee deep in short, small, important problems. This military person wanted me to solve his problem by the end of the day on Friday. I said, \"No, I'll give it to you Monday. I can work on it over the weekend. I'm not going to do it now.\" He goes down to my boss, Schelkunoff, and Schelkunoff says, \"You must run this for him; he's got to have it by Friday.\" I tell him, \"Why do I?\" He says, \"You have to.\" I said, \"Fine, Sergei, but you're sitting in your office Friday afternoon catching the late bus home to watch as this fellow walks out that door.\" I gave the military person the answers late Friday afternoon. I then went to Schelkunoff's office and sat down; as the man goes out I say, \"You see Schelkunoff, this fellow has nothing under his arm; but I gave him the answers.\" On Monday morning Schelkunoff called him up and said, \"Did you come in to work over the weekend?\" I could hear, as it were, a pause as the fellow ran through his mind of what was going to happen; but he knew he would have had to sign in, and he'd better not say he had when he hadn't, so he said he hadn't. Ever after that Schelkunoff said, \"You set your deadlines; you can change them.\"\n",
    "\n",
    "One lesson was sufficient to educate my boss as to why I didn't want to do big jobs that displaced exploratory research and why I was justified in not doing crash jobs which absorb all the research computing facilities. I wanted instead to use the facilities to compute a large number of small problems. Again, in the early days, I was limited in computing capacity and it was clear, in my area, that a \"mathematician had no use for machines.\" But I needed more machine capacity. Every time I had to tell some scientist in some other area, \"No I can't; I haven't the machine capacity,\" he complained. I said \"Go tell your Vice President that Hamming needs more computing capacity.\" After a while I could see what was happening up there at the top; many people said to my Vice President, \"Your man needs more computing capacity.\" I got it!\n",
    "\n",
    "I also did a second thing. When I loaned what little programming power we had to help in the early days of computing, I said, \"We are not getting the recognition for our programmers that they deserve. When you publish a paper you will thank that programmer or you aren't getting any more help from me. That programmer is going to be thanked by name; she's worked hard.\" I waited a couple of years. I then went through a year of BSTJ articles and counted what fraction thanked some programmer. I took it into the boss and said, \"That's the central role computing is playing in Bell Labs; if the BSTJ is important, that's how important computing is.\" He had to give in. You can educate your bosses. It's a hard job. In this talk I'm only viewing from the bottom up; I'm not viewing from the top down. But I am telling you how you can get what you want in spite of top management. You have to sell your ideas there also.\n",
    "\n",
    "Well I now come down to the topic, \"Is the effort to be a great scientist worth it?\" To answer this, you must ask people. When you get beyond their modesty, most people will say, \"Yes, doing really first-class work, and knowing it, is as good as wine, women and song put together,\" or if it's a woman she says, \"It is as good as wine, men and song put together.\" And if you look at the bosses, they tend to come back or ask for reports, trying to participate in those moments of discovery. They're always in the way. So evidently those who have done it, want to do it again. But it is a limited survey. I have never dared to go out and ask those who didn't do great work how they felt about the matter. It's a biased sample, but I still think it is worth the struggle. I think it is very definitely worth the struggle to try and do first-class work because the truth is, the value is in the struggle more than it is in the result. The struggle to make something of yourself seems to be worthwhile in itself. The success and fame are sort of dividends, in my opinion.\n",
    "\n",
    "I've told you how to do it. It is so easy, so why do so many people, with all their talents, fail? For example, my opinion, to this day, is that there are in the mathematics department at Bell Labs quite a few people far more able and far better endowed than I, but they didn't produce as much. Some of them did produce more than I did; Shannon produced more than I did, and some others produced a lot, but I was highly productive against a lot of other fellows who were better equipped. Why is it so? What happened to them? Why do so many of the people who have great promise, fail?\n",
    "\n",
    "Well, one of the reasons is drive and commitment. The people who do great work with less ability but who are committed to it, get more done that those who have great skill and dabble in it, who work during the day and go home and do other things and come back and work the next day. They don't have the deep commitment that is apparently necessary for really first-class work. They turn out lots of good work, but we were talking, remember, about first-class work. There is a difference. Good people, very talented people, almost always turn out good work. We're talking about the outstanding work, the type of work that gets the Nobel Prize and gets recognition.\n",
    "\n",
    "The second thing is, I think, the problem of personality defects. Now I'll cite a fellow whom I met out in Irvine. He had been the head of a computing center and he was temporarily on assignment as a special assistant to the president of the university. It was obvious he had a job with a great future. He took me into his office one time and showed me his method of getting letters done and how he took care of his correspondence. He pointed out how inefficient the secretary was. He kept all his letters stacked around there; he knew where everything was. And he would, on his word processor, get the letter out. He was bragging how marvelous it was and how he could get so much more work done without the secretary's interference. Well, behind his back, I talked to the secretary. The secretary said, \"Of course I can't help him; I don't get his mail. He won't give me the stuff to log in; I don't know where he puts it on the floor. Of course I can't help him.\" So I went to him and said, \"Look, if you adopt the present method and do what you can do single-handedly, you can go just that far and no farther than you can do single-handedly. If you will learn to work with the system, you can go as far as the system will support you.\" And, he never went any further. He had his personality defect of wanting total control and was not willing to recognize that you need the support of the system.\n",
    "\n",
    "You find this happening again and again; good scientists will fight the system rather than learn to work with the system and take advantage of all the system has to offer. It has a lot, if you learn how to use it. It takes patience, but you can learn how to use the system pretty well, and you can learn how to get around it. After all, if you want a decision `No', you just go to your boss and get a `No' easy. If you want to do something, don't ask, do it. Present him with an accomplished fact. Don't give him a chance to tell you `No'. But if you want a `No', it's easy to get a `No'.\n",
    "\n",
    "Another personality defect is ego assertion and I'll speak in this case of my own experience. I came from Los Alamos and in the early days I was using a machine in New York at 590 Madison Avenue where we merely rented time. I was still dressing in western clothes, big slash pockets, a bolo and all those things. I vaguely noticed that I was not getting as good service as other people. So I set out to measure. You came in and you waited for your turn; I felt I was not getting a fair deal. I said to myself, \"Why? No Vice President at IBM said, `Give Hamming a bad time'. It is the secretaries at the bottom who are doing this. When a slot appears, they'll rush to find someone to slip in, but they go out and find somebody else. Now, why? I haven't mistreated them.\" Answer: I wasn't dressing the way they felt somebody in that situation should. It came down to just that — I wasn't dressing properly. I had to make the decision — was I going to assert my ego and dress the way I wanted to and have it steadily drain my effort from my professional life, or was I going to appear to conform better? I decided I would make an effort to appear to conform properly. The moment I did, I got much better service. And now, as an old colorful character, I get better service than other people.\n",
    "\n",
    "You should dress according to the expectations of the audience spoken to. If I am going to give an address at the MIT computer center, I dress with a bolo and an old corduroy jacket or something else. I know enough not to let my clothes, my appearance, my manners get in the way of what I care about. An enormous number of scientists feel they must assert their ego and do their thing their way. They have got to be able to do this, that, or the other thing, and they pay a steady price.\n",
    "\n",
    "John Tukey almost always dressed very casually. He would go into an important office and it would take a long time before the other fellow realized that this is a first-class man and he had better listen. For a long time John has had to overcome this kind of hostility. It's wasted effort! I didn't say you should conform; I said \"The appearance of conforming gets you a long way.\" If you chose to assert your ego in any number of ways, \"I am going to do it my way,\" you pay a small steady price throughout the whole of your professional career. And this, over a whole lifetime, adds up to an enormous amount of needless trouble.\n",
    "\n",
    "By taking the trouble to tell jokes to the secretaries and being a little friendly, I got superb secretarial help. For instance, one time for some idiot reason all the reproducing services at Murray Hill were tied up. Don't ask me how, but they were. I wanted something done. My secretary called up somebody at Holmdel, hopped the company car, made the hour-long trip down and got it reproduced, and then came back. It was a payoff for the times I had made an effort to cheer her up, tell her jokes and be friendly; it was that little extra work that later paid off for me. By realizing you have to use the system and studying how to get the system to do your work, you learn how to adapt the system to your desires. Or you can fight it steadily, as a small undeclared war, for the whole of your life.\n",
    "\n",
    "And I think John Tukey paid a terrible price needlessly. He was a genius anyhow, but I think it would have been far better, and far simpler, had he been willing to conform a little bit instead of ego asserting. He is going to dress the way he wants all of the time. It applies not only to dress but to a thousand other things; people will continue to fight the system. Not that you shouldn't occasionally!\n",
    "\n",
    "When they moved the library from the middle of Murray Hill to the far end, a friend of mine put in a request for a bicycle. Well, the organization was not dumb. They waited awhile and sent back a map of the grounds saying, \"Will you please indicate on this map what paths you are going to take so we can get an insurance policy covering you.\" A few more weeks went by. They then asked, \"Where are you going to store the bicycle and how will it be locked so we can do so and so.\" He finally realized that of course he was going to be red-taped to death so he gave in. He rose to be the President of Bell Laboratories.\n",
    "\n",
    "Barney Oliver was a good man. He wrote a letter one time to the IEEE. At that time the official shelf space at Bell Labs was so much and the height of the IEEE Proceedings at that time was larger; and since you couldn't change the size of the official shelf space he wrote this letter to the IEEE Publication person saying, since so many IEEE members were at Bell Labs and since the official space was so high the journal size should be changed. He sent it for his boss's signature. Back came a carbon with his signature, but he still doesn't know whether the original was sent or not. I am not saying you shouldn't make gestures of reform. I am saying that my study of able people is that they don't get themselves committed to that kind of warfare. They play it a little bit and drop it and get on with their work.\n",
    "\n",
    "Many a second-rate fellow gets caught up in some little twitting of the system, and carries it through to warfare. He expends his energy in a foolish project. Now you are going to tell me that somebody has to change the system. I agree; somebody's has to. Which do you want to be? The person who changes the system or the person who does first-class science? Which person is it that you want to be? Be clear, when you fight the system and struggle with it, what you are doing, how far to go out of amusement, and how much to waste your effort fighting the system. My advice is to let somebody else do it and you get on with becoming a first-class scientist. Very few of you have the ability to both reform the system and become a first-class scientist.\n",
    "\n",
    "On the other hand, we can't always give in. There are times when a certain amount of rebellion is sensible. I have observed almost all scientists enjoy a certain amount of twitting the system for the sheer love of it. What it comes down to basically is that you cannot be original in one area without having originality in others. Originality is being different. You can't be an original scientist without having some other original characteristics. But many a scientist has let his quirks in other places make him pay a far higher price than is necessary for the ego satisfaction he or she gets. I'm not against all ego assertion; I'm against some.\n",
    "\n",
    "Another fault is anger. Often a scientist becomes angry, and this is no way to handle things. Amusement, yes, anger, no. Anger is misdirected. You should follow and cooperate rather than struggle against the system all the time.\n",
    "\n",
    "Another thing you should look for is the positive side of things instead of the negative. I have already given you several examples, and there are many, many more; how, given the situation, by changing the way I looked at it, I converted what was apparently a defect to an asset. I'll give you another example. I am an egotistical person; there is no doubt about it. I knew that most people who took a sabbatical to write a book, didn't finish it on time. So before I left, I told all my friends that when I come back, that book was going to be done! Yes, I would have it done — I'd have been ashamed to come back without it! I used my ego to make myself behave the way I wanted to. I bragged about something so I'd have to perform. I found out many times, like a cornered rat in a real trap, I was surprisingly capable. I have found that it paid to say, ``Oh yes, I'll get the answer for you Tuesday,'' not having any idea how to do it. By Sunday night I was really hard thinking on how I was going to deliver by Tuesday. I often put my pride on the line and sometimes I failed, but as I said, like a cornered rat I'm surprised how often I did a good job. I think you need to learn to use yourself. I think you need to know how to convert a situation from one view to another which would increase the chance of success.\n",
    "\n",
    "Now self-delusion in humans is very, very common. There are innumerable ways of you changing a thing and kidding yourself and making it look some other way. When you ask, \"Why didn't you do such and such,\" the person has a thousand alibis. If you look at the history of science, usually these days there are ten people right there ready, and we pay off for the person who is there first. The other nine fellows say, \"Well, I had the idea but I didn't do it and so on and so on.\" There are so many alibis. Why weren't you first? Why didn't you do it right? Don't try an alibi. Don't try and kid yourself. You can tell other people all the alibis you want. I don't mind. But to yourself try to be honest.\n",
    "\n",
    "If you really want to be a first-class scientist you need to know yourself, your weaknesses, your strengths, and your bad faults, like my egotism. How can you convert a fault to an asset? How can you convert a situation where you haven't got enough manpower to move into a direction when that's exactly what you need to do? I say again that I have seen, as I studied the history, the successful scientist changed the viewpoint and what was a defect became an asset.\n",
    "\n",
    "In summary, I claim that some of the reasons why so many people who have greatness within their grasp don't succeed are: they don't work on important problems, they don't become emotionally involved, they don't try and change what is difficult to some other situation which is easily done but is still important, and they keep giving themselves alibis why they don't. They keep saying that it is a matter of luck. I've told you how easy it is; furthermore I've told you how to reform. Therefore, go forth and become great scientists!\n",
    "\n",
    "\n",
    "\n",
    "Questions and Answers\n",
    "\n",
    "A. G. Chynoweth: Well that was 50 minutes of concentrated wisdom and observations accumulated over a fantastic career; I lost track of all the observations that were striking home. Some of them are very very timely. One was the plea for more computer capacity; I was hearing nothing but that this morning from several people, over and over again. So that was right on the mark today even though here we are 20 – 30 years after when you were making similar remarks, Dick. I can think of all sorts of lessons that all of us can draw from your talk. And for one, as I walk around the halls in the future I hope I won't see as many closed doors in Bellcore. That was one observation I thought was very intriguing.\n",
    "\n",
    "Thank you very, very much indeed Dick; that was a wonderful recollection. I'll now open it up for questions. I'm sure there are many people who would like to take up on some of the points that Dick was making.\n",
    "\n",
    "Hamming: First let me respond to Alan Chynoweth about computing. I had computing in research and for 10 years I kept telling my management, ``Get that !&@#% machine out of research. We are being forced to run problems all the time. We can't do research because were too busy operating and running the computing machines.'' Finally the message got through. They were going to move computing out of research to someplace else. I was persona non grata to say the least and I was surprised that people didn't kick my shins because everybody was having their toy taken away from them. I went in to Ed David's office and said, ``Look Ed, you've got to give your researchers a machine. If you give them a great big machine, we'll be back in the same trouble we were before, so busy keeping it going we can't think. Give them the smallest machine you can because they are very able people. They will learn how to do things on a small machine instead of mass computing.'' As far as I'm concerned, that's how UNIX arose. We gave them a moderately small machine and they decided to make it do great things. They had to come up with a system to do it on. It is called UNIX!\n",
    "\n",
    "A. G. Chynoweth: I just have to pick up on that one. In our present environment, Dick, while we wrestle with some of the red tape attributed to, or required by, the regulators, there is one quote that one exasperated AVP came up with and I've used it over and over again. He growled that, \"UNIX was never a deliverable!\"\n",
    "\n",
    "Question: What about personal stress? Does that seem to make a difference?\n",
    "\n",
    "Hamming: Yes, it does. If you don't get emotionally involved, it doesn't. I had incipient ulcers most of the years that I was at Bell Labs. I have since gone off to the Naval Postgraduate School and laid back somewhat, and now my health is much better. But if you want to be a great scientist you're going to have to put up with stress. You can lead a nice life; you can be a nice guy or you can be a great scientist. But nice guys end last, is what Leo Durocher said. If you want to lead a nice happy life with a lot of recreation and everything else, you'll lead a nice life.\n",
    "\n",
    "Question: The remarks about having courage, no one could argue with; but those of us who have gray hairs or who are well established don't have to worry too much. But what I sense among the young people these days is a real concern over the risk taking in a highly competitive environment. Do you have any words of wisdom on this?\n",
    "\n",
    "Hamming: I'll quote Ed David more. Ed David was concerned about the general loss of nerve in our society. It does seem to me that we've gone through various periods. Coming out of the war, coming out of Los Alamos where we built the bomb, coming out of building the radars and so on, there came into the mathematics department, and the research area, a group of people with a lot of guts. They've just seen things done; they've just won a war which was fantastic. We had reasons for having courage and therefore we did a great deal. I can't arrange that situation to do it again. I cannot blame the present generation for not having it, but I agree with what you say; I just cannot attach blame to it. It doesn't seem to me they have the desire for greatness; they lack the courage to do it. But we had, because we were in a favorable circumstance to have it; we just came through a tremendously successful war. In the war we were looking very, very bad for a long while; it was a very desperate struggle as you well know. And our success, I think, gave us courage and self confidence; that's why you see, beginning in the late forties through the fifties, a tremendous productivity at the labs which was stimulated from the earlier times. Because many of us were earlier forced to learn other things — we were forced to learn the things we didn't want to learn, we were forced to have an open door — and then we could exploit those things we learned. It is true, and I can't do anything about it; I cannot blame the present generation either. It's just a fact.\n",
    "\n",
    "Question: Is there something management could or should do?\n",
    "\n",
    "Hamming: Management can do very little. If you want to talk about managing research, that's a totally different talk. I'd take another hour doing that. This talk is about how the individual gets very successful research done in spite of anything the management does or in spite of any other opposition. And how do you do it? Just as I observe people doing it. It's just that simple and that hard!\n",
    "\n",
    "Question: Is brainstorming a daily process?\n",
    "\n",
    "Hamming: Once that was a very popular thing, but it seems not to have paid off. For myself I find it desirable to talk to other people; but a session of brainstorming is seldom worthwhile. I do go in to strictly talk to somebody and say, \"Look, I think there has to be something here. Here's what I think I see ...\" and then begin talking back and forth. But you want to pick capable people. To use another analogy, you know the idea called the `critical mass.' If you have enough stuff you have critical mass. There is also the idea I used to call `sound absorbers'. When you get too many sound absorbers, you give out an idea and they merely say, \"Yes, yes, yes.\" What you want to do is get that critical mass in action; \"Yes, that reminds me of so and so,\" or, \"Have you thought about that or this?\" When you talk to other people, you want to get rid of those sound absorbers who are nice people but merely say, \"Oh yes,\" and to find those who will stimulate you right back.\n",
    "\n",
    "For example, you couldn't talk to John Pierce without being stimulated very quickly. There were a group of other people I used to talk with. For example there was Ed Gilbert; I used to go down to his office regularly and ask him questions and listen and come back stimulated. I picked my people carefully with whom I did or whom I didn't brainstorm because the sound absorbers are a curse. They are just nice guys; they fill the whole space and they contribute nothing except they absorb ideas and the new ideas just die away instead of echoing on. Yes, I find it necessary to talk to people. I think people with closed doors fail to do this so they fail to get their ideas sharpened, such as \"Did you ever notice something over here?\" I never knew anything about it — I can go over and look. Somebody points the way. On my visit here, I have already found several books that I must read when I get home. I talk to people and ask questions when I think they can answer me and give me clues that I do not know about. I go out and look!\n",
    "\n",
    "Question: What kind of tradeoffs did you make in allocating your time for reading and writing and actually doing research?\n",
    "\n",
    "Hamming: I believed, in my early days, that you should spend at least as much time in the polish and presentation as you did in the original research. Now at least 50% of the time must go for the presentation. It's a big, big number.\n",
    "\n",
    "Question: How much effort should go into library work?\n",
    "\n",
    "Hamming: It depends upon the field. I will say this about it. There was a fellow at Bell Labs, a very, very, smart guy. He was always in the library; he read everything. If you wanted references, you went to him and he gave you all kinds of references. But in the middle of forming these theories, I formed a proposition: there would be no effect named after him in the long run. He is now retired from Bell Labs and is an Adjunct Professor. He was very valuable; I'm not questioning that. He wrote some very good Physical Review articles; but there's no effect named after him because he read too much. If you read all the time what other people have done you will think the way they thought. If you want to think new thoughts that are different, then do what a lot of creative people do — get the problem reasonably clear and then refuse to look at any answers until you've thought the problem through carefully how you would do it, how you could slightly change the problem to be the correct one. So yes, you need to keep up. You need to keep up more to find out what the problems are than to read to find the solutions. The reading is necessary to know what is going on and what is possible. But reading to get the solutions does not seem to be the way to do great research. So I'll give you two answers. You read; but it is not the amount, it is the way you read that counts.\n",
    "\n",
    "Question: How do you get your name attached to things?\n",
    "\n",
    "Hamming: By doing great work. I'll tell you the hamming window one. I had given Tukey a hard time, quite a few times, and I got a phone call from him from Princeton to me at Murray Hill. I knew that he was writing up power spectra and he asked me if I would mind if he called a certain window a \"hamming window.\" And I said to him, \"Come on, John; you know perfectly well I did only a small part of the work but you also did a lot.\" He said, \"Yes, Hamming, but you contributed a lot of small things; you're entitled to some credit.\" So he called it the hamming window. Now, let me go on. I had twitted John frequently about true greatness. I said true greatness is when your name is like ampere, watt, and fourier — when it's spelled with a lower case letter. That's how the hamming window came about.\n",
    "\n",
    "Question: Dick, would you care to comment on the relative effectiveness between giving talks, writing papers, and writing books?\n",
    "\n",
    "Hamming: In the short-haul, papers are very important if you want to stimulate someone tomorrow. If you want to get recognition long-haul, it seems to me writing books is more contribution because most of us need orientation. In this day of practically infinite knowledge, we need orientation to find our way. Let me tell you what infinite knowledge is. Since from the time of Newton to now, we have come close to doubling knowledge every 17 years, more or less. And we cope with that, essentially, by specialization. In the next 340 years at that rate, there will be 20 doublings, i.e. a million, and there will be a million fields of specialty for every one field now. It isn't going to happen. The present growth of knowledge will choke itself off until we get different tools. I believe that books which try to digest, coordinate, get rid of the duplication, get rid of the less fruitful methods and present the underlying ideas clearly of what we know now, will be the things the future generations will value. Public talks are necessary; private talks are necessary; written papers are necessary. But I am inclined to believe that, in the long-haul, books which leave out what's not essential are more important than books which tell you everything because you don't want to know everything. I don't want to know that much about penguins is the usual reply. You just want to know the essence.\n",
    "\n",
    "Question: You mentioned the problem of the Nobel Prize and the subsequent notoriety of what was done to some of the careers. Isn't that kind of a much more broad problem of fame? What can one do?\n",
    "\n",
    "Hamming: Some things you could do are the following. Somewhere around every seven years make a significant, if not complete, shift in your field. Thus, I shifted from numerical analysis, to hardware, to software, and so on, periodically, because you tend to use up your ideas. When you go to a new field, you have to start over as a baby. You are no longer the big mukity muk and you can start back there and you can start planting those acorns which will become the giant oaks. Shannon, I believe, ruined himself. In fact when he left Bell Labs, I said, \"That's the end of Shannon's scientific career.\" I received a lot of flak from my friends who said that Shannon was just as smart as ever. I said, \"Yes, he'll be just as smart, but that's the end of his scientific career,\" and I truly believe it was.\n",
    "\n",
    "You have to change. You get tired after a while; you use up your originality in one field. You need to get something nearby. I'm not saying that you shift from music to theoretical physics to English literature; I mean within your field you should shift areas so that you don't go stale. You couldn't get away with forcing a change every seven years, but if you could, I would require a condition for doing research, being that you will change your field of research every seven years with a reasonable definition of what it means, or at the end of 10 years, management has the right to compel you to change. I would insist on a change because I'm serious. What happens to the old fellows is that they get a technique going; they keep on using it. They were marching in that direction which was right then, but the world changes. There's the new direction; but the old fellows are still marching in their former direction.\n",
    "\n",
    "You need to get into a new field to get new viewpoints, and before you use up all the old ones. You can do something about this, but it takes effort and energy. It takes courage to say, ``Yes, I will give up my great reputation.'' For example, when error correcting codes were well launched, having these theories, I said, \"Hamming, you are going to quit reading papers in the field; you are going to ignore it completely; you are going to try and do something else other than coast on that.\" I deliberately refused to go on in that field. I wouldn't even read papers to try to force myself to have a chance to do something else. I managed myself, which is what I'm preaching in this whole talk. Knowing many of my own faults, I manage myself. I have a lot of faults, so I've got a lot of problems, i.e. a lot of possibilities of management.\n",
    "\n",
    "Question: Would you compare research and management?\n",
    "\n",
    "Hamming: If you want to be a great researcher, you won't make it being president of the company. If you want to be president of the company, that's another thing. I'm not against being president of the company. I just don't want to be. I think Ian Ross does a good job as President of Bell Labs. I'm not against it; but you have to be clear on what you want. Furthermore, when you're young, you may have picked wanting to be a great scientist, but as you live longer, you may change your mind. For instance, I went to my boss, Bode, one day and said, \"Why did you ever become department head? Why didn't you just be a good scientist?\" He said, \"Hamming, I had a vision of what mathematics should be in Bell Laboratories. And I saw if that vision was going to be realized, I had to make it happen; I had to be department head.\" When your vision of what you want to do is what you can do single-handedly, then you should pursue it. The day your vision, what you think needs to be done, is bigger than what you can do single-handedly, then you have to move toward management. And the bigger the vision is, the farther in management you have to go. If you have a vision of what the whole laboratory should be, or the whole Bell System, you have to get there to make it happen. You can't make it happen from the bottom very easily. It depends upon what goals and what desires you have. And as they change in life, you have to be prepared to change. I chose to avoid management because I preferred to do what I could do single-handedly. But that's the choice that I made, and it is biased. Each person is entitled to their choice. Keep an open mind. But when you do choose a path, for heaven's sake be aware of what you have done and the choice you have made. Don't try to do both sides.\n",
    "\n",
    "Question: How important is one's own expectation or how important is it to be in a group or surrounded by people who expect great work from you?\n",
    "\n",
    "Hamming: At Bell Labs everyone expected good work from me — it was a big help. Everybody expects you to do a good job, so you do, if you've got pride. I think it's very valuable to have first-class people around. I sought out the best people. The moment that physics table lost the best people, I left. The moment I saw that the same was true of the chemistry table, I left. I tried to go with people who had great ability so I could learn from them and who would expect great results out of me. By deliberately managing myself, I think I did much better than laissez faire.\n",
    "\n",
    "Question: You, at the outset of your talk, minimized or played down luck; but you seemed also to gloss over the circumstances that got you to Los Alamos, that got you to Chicago, that got you to Bell Laboratories.\n",
    "\n",
    "Hamming: There was some luck. On the other hand I don't know the alternate branches. Until you can say that the other branches would not have been equally or more successful, I can't say. Is it luck the particular thing you do? For example, when I met Feynman at Los Alamos, I knew he was going to get a Nobel Prize. I didn't know what for. But I knew darn well he was going to do great work. No matter what directions came up in the future, this man would do great work. And sure enough, he did do great work. It isn't that you only do a little great work at this circumstance and that was luck, there are many opportunities sooner or later. There are a whole pail full of opportunities, of which, if you're in this situation, you seize one and you're great over there instead of over here. There is an element of luck, yes and no. Luck favors a prepared mind; luck favors a prepared person. It is not guaranteed; I don't guarantee success as being absolutely certain. I'd say luck changes the odds, but there is some definite control on the part of the individual.\n",
    "\n",
    "Go forth, then, and do great work!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "pg = \"\"\"If you collected lists of techniques for doing great work in a lot of different fields, what would the intersection look like? I decided to find out by making it.\n",
    "\n",
    "Partly my goal was to create a guide that could be used by someone working in any field. But I was also curious about the shape of the intersection. And one thing this exercise shows is that it does have a definite shape; it's not just a point labelled \"work hard.\"\n",
    "\n",
    "The following recipe assumes you're very ambitious.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The first step is to decide what to work on. The work you choose needs to have three qualities: it has to be something you have a natural aptitude for, that you have a deep interest in, and that offers scope to do great work.\n",
    "\n",
    "In practice you don't have to worry much about the third criterion. Ambitious people are if anything already too conservative about it. So all you need to do is find something you have an aptitude for and great interest in. [1]\n",
    "\n",
    "That sounds straightforward, but it's often quite difficult. When you're young you don't know what you're good at or what different kinds of work are like. Some kinds of work you end up doing may not even exist yet. So while some people know what they want to do at 14, most have to figure it out.\n",
    "\n",
    "The way to figure out what to work on is by working. If you're not sure what to work on, guess. But pick something and get going. You'll probably guess wrong some of the time, but that's fine. It's good to know about multiple things; some of the biggest discoveries come from noticing connections between different fields.\n",
    "\n",
    "Develop a habit of working on your own projects. Don't let \"work\" mean something other people tell you to do. If you do manage to do great work one day, it will probably be on a project of your own. It may be within some bigger project, but you'll be driving your part of it.\n",
    "\n",
    "What should your projects be? Whatever seems to you excitingly ambitious. As you grow older and your taste in projects evolves, exciting and important will converge. At 7 it may seem excitingly ambitious to build huge things out of Lego, then at 14 to teach yourself calculus, till at 21 you're starting to explore unanswered questions in physics. But always preserve excitingness.\n",
    "\n",
    "There's a kind of excited curiosity that's both the engine and the rudder of great work. It will not only drive you, but if you let it have its way, will also show you what to work on.\n",
    "\n",
    "What are you excessively curious about — curious to a degree that would bore most other people? That's what you're looking for.\n",
    "\n",
    "Once you've found something you're excessively interested in, the next step is to learn enough about it to get you to one of the frontiers of knowledge. Knowledge expands fractally, and from a distance its edges look smooth, but once you learn enough to get close to one, they turn out to be full of gaps.\n",
    "\n",
    "The next step is to notice them. This takes some skill, because your brain wants to ignore such gaps in order to make a simpler model of the world. Many discoveries have come from asking questions about things that everyone else took for granted. [2]\n",
    "\n",
    "If the answers seem strange, so much the better. Great work often has a tincture of strangeness. You see this from painting to math. It would be affected to try to manufacture it, but if it appears, embrace it.\n",
    "\n",
    "Boldly chase outlier ideas, even if other people aren't interested in them — in fact, especially if they aren't. If you're excited about some possibility that everyone else ignores, and you have enough expertise to say precisely what they're all overlooking, that's as good a bet as you'll find. [3]\n",
    "\n",
    "Four steps: choose a field, learn enough to get to the frontier, notice gaps, explore promising ones. This is how practically everyone who's done great work has done it, from painters to physicists.\n",
    "\n",
    "Steps two and four will require hard work. It may not be possible to prove that you have to work hard to do great things, but the empirical evidence is on the scale of the evidence for mortality. That's why it's essential to work on something you're deeply interested in. Interest will drive you to work harder than mere diligence ever could.\n",
    "\n",
    "The three most powerful motives are curiosity, delight, and the desire to do something impressive. Sometimes they converge, and that combination is the most powerful of all.\n",
    "\n",
    "The big prize is to discover a new fractal bud. You notice a crack in the surface of knowledge, pry it open, and there's a whole world inside.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's talk a little more about the complicated business of figuring out what to work on. The main reason it's hard is that you can't tell what most kinds of work are like except by doing them. Which means the four steps overlap: you may have to work at something for years before you know how much you like it or how good you are at it. And in the meantime you're not doing, and thus not learning about, most other kinds of work. So in the worst case you choose late based on very incomplete information. [4]\n",
    "\n",
    "The nature of ambition exacerbates this problem. Ambition comes in two forms, one that precedes interest in the subject and one that grows out of it. Most people who do great work have a mix, and the more you have of the former, the harder it will be to decide what to do.\n",
    "\n",
    "The educational systems in most countries pretend it's easy. They expect you to commit to a field long before you could know what it's really like. And as a result an ambitious person on an optimal trajectory will often read to the system as an instance of breakage.\n",
    "\n",
    "It would be better if they at least admitted it — if they admitted that the system not only can't do much to help you figure out what to work on, but is designed on the assumption that you'll somehow magically guess as a teenager. They don't tell you, but I will: when it comes to figuring out what to work on, you're on your own. Some people get lucky and do guess correctly, but the rest will find themselves scrambling diagonally across tracks laid down on the assumption that everyone does.\n",
    "\n",
    "What should you do if you're young and ambitious but don't know what to work on? What you should not do is drift along passively, assuming the problem will solve itself. You need to take action. But there is no systematic procedure you can follow. When you read biographies of people who've done great work, it's remarkable how much luck is involved. They discover what to work on as a result of a chance meeting, or by reading a book they happen to pick up. So you need to make yourself a big target for luck, and the way to do that is to be curious. Try lots of things, meet lots of people, read lots of books, ask lots of questions. [5]\n",
    "\n",
    "When in doubt, optimize for interestingness. Fields change as you learn more about them. What mathematicians do, for example, is very different from what you do in high school math classes. So you need to give different types of work a chance to show you what they're like. But a field should become increasingly interesting as you learn more about it. If it doesn't, it's probably not for you.\n",
    "\n",
    "Don't worry if you find you're interested in different things than other people. The stranger your tastes in interestingness, the better. Strange tastes are often strong ones, and a strong taste for work means you'll be productive. And you're more likely to find new things if you're looking where few have looked before.\n",
    "\n",
    "One sign that you're suited for some kind of work is when you like even the parts that other people find tedious or frightening.\n",
    "\n",
    "But fields aren't people; you don't owe them any loyalty. If in the course of working on one thing you discover another that's more exciting, don't be afraid to switch.\n",
    "\n",
    "If you're making something for people, make sure it's something they actually want. The best way to do this is to make something you yourself want. Write the story you want to read; build the tool you want to use. Since your friends probably have similar interests, this will also get you your initial audience.\n",
    "\n",
    "This should follow from the excitingness rule. Obviously the most exciting story to write will be the one you want to read. The reason I mention this case explicitly is that so many people get it wrong. Instead of making what they want, they try to make what some imaginary, more sophisticated audience wants. And once you go down that route, you're lost. [6]\n",
    "\n",
    "There are a lot of forces that will lead you astray when you're trying to figure out what to work on. Pretentiousness, fashion, fear, money, politics, other people's wishes, eminent frauds. But if you stick to what you find genuinely interesting, you'll be proof against all of them. If you're interested, you're not astray.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Following your interests may sound like a rather passive strategy, but in practice it usually means following them past all sorts of obstacles. You usually have to risk rejection and failure. So it does take a good deal of boldness.\n",
    "\n",
    "But while you need boldness, you don't usually need much planning. In most cases the recipe for doing great work is simply: work hard on excitingly ambitious projects, and something good will come of it. Instead of making a plan and then executing it, you just try to preserve certain invariants.\n",
    "\n",
    "The trouble with planning is that it only works for achievements you can describe in advance. You can win a gold medal or get rich by deciding to as a child and then tenaciously pursuing that goal, but you can't discover natural selection that way.\n",
    "\n",
    "I think for most people who want to do great work, the right strategy is not to plan too much. At each stage do whatever seems most interesting and gives you the best options for the future. I call this approach \"staying upwind.\" This is how most people who've done great work seem to have done it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Even when you've found something exciting to work on, working on it is not always straightforward. There will be times when some new idea makes you leap out of bed in the morning and get straight to work. But there will also be plenty of times when things aren't like that.\n",
    "\n",
    "You don't just put out your sail and get blown forward by inspiration. There are headwinds and currents and hidden shoals. So there's a technique to working, just as there is to sailing.\n",
    "\n",
    "For example, while you must work hard, it's possible to work too hard, and if you do that you'll find you get diminishing returns: fatigue will make you stupid, and eventually even damage your health. The point at which work yields diminishing returns depends on the type. Some of the hardest types you might only be able to do for four or five hours a day.\n",
    "\n",
    "Ideally those hours will be contiguous. To the extent you can, try to arrange your life so you have big blocks of time to work in. You'll shy away from hard tasks if you know you might be interrupted.\n",
    "\n",
    "It will probably be harder to start working than to keep working. You'll often have to trick yourself to get over that initial threshold. Don't worry about this; it's the nature of work, not a flaw in your character. Work has a sort of activation energy, both per day and per project. And since this threshold is fake in the sense that it's higher than the energy required to keep going, it's ok to tell yourself a lie of corresponding magnitude to get over it.\n",
    "\n",
    "It's usually a mistake to lie to yourself if you want to do great work, but this is one of the rare cases where it isn't. When I'm reluctant to start work in the morning, I often trick myself by saying \"I'll just read over what I've got so far.\" Five minutes later I've found something that seems mistaken or incomplete, and I'm off.\n",
    "\n",
    "Similar techniques work for starting new projects. It's ok to lie to yourself about how much work a project will entail, for example. Lots of great things began with someone saying \"How hard could it be?\"\n",
    "\n",
    "This is one case where the young have an advantage. They're more optimistic, and even though one of the sources of their optimism is ignorance, in this case ignorance can sometimes beat knowledge.\n",
    "\n",
    "Try to finish what you start, though, even if it turns out to be more work than you expected. Finishing things is not just an exercise in tidiness or self-discipline. In many projects a lot of the best work happens in what was meant to be the final stage.\n",
    "\n",
    "Another permissible lie is to exaggerate the importance of what you're working on, at least in your own mind. If that helps you discover something new, it may turn out not to have been a lie after all. [7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Since there are two senses of starting work — per day and per project — there are also two forms of procrastination. Per-project procrastination is far the more dangerous. You put off starting that ambitious project from year to year because the time isn't quite right. When you're procrastinating in units of years, you can get a lot not done. [8]\n",
    "\n",
    "One reason per-project procrastination is so dangerous is that it usually camouflages itself as work. You're not just sitting around doing nothing; you're working industriously on something else. So per-project procrastination doesn't set off the alarms that per-day procrastination does. You're too busy to notice it.\n",
    "\n",
    "The way to beat it is to stop occasionally and ask yourself: Am I working on what I most want to work on? When you're young it's ok if the answer is sometimes no, but this gets increasingly dangerous as you get older. [9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Great work usually entails spending what would seem to most people an unreasonable amount of time on a problem. You can't think of this time as a cost, or it will seem too high. You have to find the work sufficiently engaging as it's happening.\n",
    "\n",
    "There may be some jobs where you have to work diligently for years at things you hate before you get to the good part, but this is not how great work happens. Great work happens by focusing consistently on something you're genuinely interested in. When you pause to take stock, you're surprised how far you've come.\n",
    "\n",
    "The reason we're surprised is that we underestimate the cumulative effect of work. Writing a page a day doesn't sound like much, but if you do it every day you'll write a book a year. That's the key: consistency. People who do great things don't get a lot done every day. They get something done, rather than nothing.\n",
    "\n",
    "If you do work that compounds, you'll get exponential growth. Most people who do this do it unconsciously, but it's worth stopping to think about. Learning, for example, is an instance of this phenomenon: the more you learn about something, the easier it is to learn more. Growing an audience is another: the more fans you have, the more new fans they'll bring you.\n",
    "\n",
    "The trouble with exponential growth is that the curve feels flat in the beginning. It isn't; it's still a wonderful exponential curve. But we can't grasp that intuitively, so we underrate exponential growth in its early stages.\n",
    "\n",
    "Something that grows exponentially can become so valuable that it's worth making an extraordinary effort to get it started. But since we underrate exponential growth early on, this too is mostly done unconsciously: people push through the initial, unrewarding phase of learning something new because they know from experience that learning new things always takes an initial push, or they grow their audience one fan at a time because they have nothing better to do. If people consciously realized they could invest in exponential growth, many more would do it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Work doesn't just happen when you're trying to. There's a kind of undirected thinking you do when walking or taking a shower or lying in bed that can be very powerful. By letting your mind wander a little, you'll often solve problems you were unable to solve by frontal attack.\n",
    "\n",
    "You have to be working hard in the normal way to benefit from this phenomenon, though. You can't just walk around daydreaming. The daydreaming has to be interleaved with deliberate work that feeds it questions. [10]\n",
    "\n",
    "Everyone knows to avoid distractions at work, but it's also important to avoid them in the other half of the cycle. When you let your mind wander, it wanders to whatever you care about most at that moment. So avoid the kind of distraction that pushes your work out of the top spot, or you'll waste this valuable type of thinking on the distraction instead. (Exception: Don't avoid love.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Consciously cultivate your taste in the work done in your field. Until you know which is the best and what makes it so, you don't know what you're aiming for.\n",
    "\n",
    "And that is what you're aiming for, because if you don't try to be the best, you won't even be good. This observation has been made by so many people in so many different fields that it might be worth thinking about why it's true. It could be because ambition is a phenomenon where almost all the error is in one direction — where almost all the shells that miss the target miss by falling short. Or it could be because ambition to be the best is a qualitatively different thing from ambition to be good. Or maybe being good is simply too vague a standard. Probably all three are true. [11]\n",
    "\n",
    "Fortunately there's a kind of economy of scale here. Though it might seem like you'd be taking on a heavy burden by trying to be the best, in practice you often end up net ahead. It's exciting, and also strangely liberating. It simplifies things. In some ways it's easier to try to be the best than to try merely to be good.\n",
    "\n",
    "One way to aim high is to try to make something that people will care about in a hundred years. Not because their opinions matter more than your contemporaries', but because something that still seems good in a hundred years is more likely to be genuinely good.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't try to work in a distinctive style. Just try to do the best job you can; you won't be able to help doing it in a distinctive way.\n",
    "\n",
    "Style is doing things in a distinctive way without trying to. Trying to is affectation.\n",
    "\n",
    "Affectation is in effect to pretend that someone other than you is doing the work. You adopt an impressive but fake persona, and while you're pleased with the impressiveness, the fakeness is what shows in the work. [12]\n",
    "\n",
    "The temptation to be someone else is greatest for the young. They often feel like nobodies. But you never need to worry about that problem, because it's self-solving if you work on sufficiently ambitious projects. If you succeed at an ambitious project, you're not a nobody; you're the person who did it. So just do the work and your identity will take care of itself.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"Avoid affectation\" is a useful rule so far as it goes, but how would you express this idea positively? How would you say what to be, instead of what not to be? The best answer is earnest. If you're earnest you avoid not just affectation but a whole set of similar vices.\n",
    "\n",
    "The core of being earnest is being intellectually honest. We're taught as children to be honest as an unselfish virtue — as a kind of sacrifice. But in fact it's a source of power too. To see new ideas, you need an exceptionally sharp eye for the truth. You're trying to see more truth than others have seen so far. And how can you have a sharp eye for the truth if you're intellectually dishonest?\n",
    "\n",
    "One way to avoid intellectual dishonesty is to maintain a slight positive pressure in the opposite direction. Be aggressively willing to admit that you're mistaken. Once you've admitted you were mistaken about something, you're free. Till then you have to carry it. [13]\n",
    "\n",
    "Another more subtle component of earnestness is informality. Informality is much more important than its grammatically negative name implies. It's not merely the absence of something. It means focusing on what matters instead of what doesn't.\n",
    "\n",
    "What formality and affectation have in common is that as well as doing the work, you're trying to seem a certain way as you're doing it. But any energy that goes into how you seem comes out of being good. That's one reason nerds have an advantage in doing great work: they expend little effort on seeming anything. In fact that's basically the definition of a nerd.\n",
    "\n",
    "Nerds have a kind of innocent boldness that's exactly what you need in doing great work. It's not learned; it's preserved from childhood. So hold onto it. Be the one who puts things out there rather than the one who sits back and offers sophisticated-sounding criticisms of them. \"It's easy to criticize\" is true in the most literal sense, and the route to great work is never easy.\n",
    "\n",
    "There may be some jobs where it's an advantage to be cynical and pessimistic, but if you want to do great work it's an advantage to be optimistic, even though that means you'll risk looking like a fool sometimes. There's an old tradition of doing the opposite. The Old Testament says it's better to keep quiet lest you look like a fool. But that's advice for seeming smart. If you actually want to discover new things, it's better to take the risk of telling people your ideas.\n",
    "\n",
    "Some people are naturally earnest, and with others it takes a conscious effort. Either kind of earnestness will suffice. But I doubt it would be possible to do great work without being earnest. It's so hard to do even if you are. You don't have enough margin for error to accommodate the distortions introduced by being affected, intellectually dishonest, orthodox, fashionable, or cool. [14]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Great work is consistent not only with who did it, but with itself. It's usually all of a piece. So if you face a decision in the middle of working on something, ask which choice is more consistent.\n",
    "\n",
    "You may have to throw things away and redo them. You won't necessarily have to, but you have to be willing to. And that can take some effort; when there's something you need to redo, status quo bias and laziness will combine to keep you in denial about it. To beat this ask: If I'd already made the change, would I want to revert to what I have now?\n",
    "\n",
    "Have the confidence to cut. Don't keep something that doesn't fit just because you're proud of it, or because it cost you a lot of effort.\n",
    "\n",
    "Indeed, in some kinds of work it's good to strip whatever you're doing to its essence. The result will be more concentrated; you'll understand it better; and you won't be able to lie to yourself about whether there's anything real there.\n",
    "\n",
    "Mathematical elegance may sound like a mere metaphor, drawn from the arts. That's what I thought when I first heard the term \"elegant\" applied to a proof. But now I suspect it's conceptually prior — that the main ingredient in artistic elegance is mathematical elegance. At any rate it's a useful standard well beyond math.\n",
    "\n",
    "Elegance can be a long-term bet, though. Laborious solutions will often have more prestige in the short term. They cost a lot of effort and they're hard to understand, both of which impress people, at least temporarily.\n",
    "\n",
    "Whereas some of the very best work will seem like it took comparatively little effort, because it was in a sense already there. It didn't have to be built, just seen. It's a very good sign when it's hard to say whether you're creating something or discovering it.\n",
    "\n",
    "When you're doing work that could be seen as either creation or discovery, err on the side of discovery. Try thinking of yourself as a mere conduit through which the ideas take their natural shape.\n",
    "\n",
    "(Strangely enough, one exception is the problem of choosing a problem to work on. This is usually seen as search, but in the best case it's more like creating something. In the best case you create the field in the process of exploring it.)\n",
    "\n",
    "Similarly, if you're trying to build a powerful tool, make it gratuitously unrestrictive. A powerful tool almost by definition will be used in ways you didn't expect, so err on the side of eliminating restrictions, even if you don't know what the benefit will be.\n",
    "\n",
    "Great work will often be tool-like in the sense of being something others build on. So it's a good sign if you're creating ideas that others could use, or exposing questions that others could answer. The best ideas have implications in many different areas.\n",
    "\n",
    "If you express your ideas in the most general form, they'll be truer than you intended.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "True by itself is not enough, of course. Great ideas have to be true and new. And it takes a certain amount of ability to see new ideas even once you've learned enough to get to one of the frontiers of knowledge.\n",
    "\n",
    "In English we give this ability names like originality, creativity, and imagination. And it seems reasonable to give it a separate name, because it does seem to some extent a separate skill. It's possible to have a great deal of ability in other respects — to have a great deal of what's often called \"technical ability\" — and yet not have much of this.\n",
    "\n",
    "I've never liked the term \"creative process.\" It seems misleading. Originality isn't a process, but a habit of mind. Original thinkers throw off new ideas about whatever they focus on, like an angle grinder throwing off sparks. They can't help it.\n",
    "\n",
    "If the thing they're focused on is something they don't understand very well, these new ideas might not be good. One of the most original thinkers I know decided to focus on dating after he got divorced. He knew roughly as much about dating as the average 15 year old, and the results were spectacularly colorful. But to see originality separated from expertise like that made its nature all the more clear.\n",
    "\n",
    "I don't know if it's possible to cultivate originality, but there are definitely ways to make the most of however much you have. For example, you're much more likely to have original ideas when you're working on something. Original ideas don't come from trying to have original ideas. They come from trying to build or understand something slightly too difficult. [15]\n",
    "\n",
    "Talking or writing about the things you're interested in is a good way to generate new ideas. When you try to put ideas into words, a missing idea creates a sort of vacuum that draws it out of you. Indeed, there's a kind of thinking that can only be done by writing.\n",
    "\n",
    "Changing your context can help. If you visit a new place, you'll often find you have new ideas there. The journey itself often dislodges them. But you may not have to go far to get this benefit. Sometimes it's enough just to go for a walk. [16]\n",
    "\n",
    "It also helps to travel in topic space. You'll have more new ideas if you explore lots of different topics, partly because it gives the angle grinder more surface area to work on, and partly because analogies are an especially fruitful source of new ideas.\n",
    "\n",
    "Don't divide your attention evenly between many topics though, or you'll spread yourself too thin. You want to distribute it according to something more like a power law. [17] Be professionally curious about a few topics and idly curious about many more.\n",
    "\n",
    "Curiosity and originality are closely related. Curiosity feeds originality by giving it new things to work on. But the relationship is closer than that. Curiosity is itself a kind of originality; it's roughly to questions what originality is to answers. And since questions at their best are a big component of answers, curiosity at its best is a creative force.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having new ideas is a strange game, because it usually consists of seeing things that were right under your nose. Once you've seen a new idea, it tends to seem obvious. Why did no one think of this before?\n",
    "\n",
    "When an idea seems simultaneously novel and obvious, it's probably a good one.\n",
    "\n",
    "Seeing something obvious sounds easy. And yet empirically having new ideas is hard. What's the source of this apparent contradiction? It's that seeing the new idea usually requires you to change the way you look at the world. We see the world through models that both help and constrain us. When you fix a broken model, new ideas become obvious. But noticing and fixing a broken model is hard. That's how new ideas can be both obvious and yet hard to discover: they're easy to see after you do something hard.\n",
    "\n",
    "One way to discover broken models is to be stricter than other people. Broken models of the world leave a trail of clues where they bash against reality. Most people don't want to see these clues. It would be an understatement to say that they're attached to their current model; it's what they think in; so they'll tend to ignore the trail of clues left by its breakage, however conspicuous it may seem in retrospect.\n",
    "\n",
    "To find new ideas you have to seize on signs of breakage instead of looking away. That's what Einstein did. He was able to see the wild implications of Maxwell's equations not so much because he was looking for new ideas as because he was stricter.\n",
    "\n",
    "The other thing you need is a willingness to break rules. Paradoxical as it sounds, if you want to fix your model of the world, it helps to be the sort of person who's comfortable breaking rules. From the point of view of the old model, which everyone including you initially shares, the new model usually breaks at least implicit rules.\n",
    "\n",
    "Few understand the degree of rule-breaking required, because new ideas seem much more conservative once they succeed. They seem perfectly reasonable once you're using the new model of the world they brought with them. But they didn't at the time; it took the greater part of a century for the heliocentric model to be generally accepted, even among astronomers, because it felt so wrong.\n",
    "\n",
    "Indeed, if you think about it, a good new idea has to seem bad to most people, or someone would have already explored it. So what you're looking for is ideas that seem crazy, but the right kind of crazy. How do you recognize these? You can't with certainty. Often ideas that seem bad are bad. But ideas that are the right kind of crazy tend to be exciting; they're rich in implications; whereas ideas that are merely bad tend to be depressing.\n",
    "\n",
    "There are two ways to be comfortable breaking rules: to enjoy breaking them, and to be indifferent to them. I call these two cases being aggressively and passively independent-minded.\n",
    "\n",
    "The aggressively independent-minded are the naughty ones. Rules don't merely fail to stop them; breaking rules gives them additional energy. For this sort of person, delight at the sheer audacity of a project sometimes supplies enough activation energy to get it started.\n",
    "\n",
    "The other way to break rules is not to care about them, or perhaps even to know they exist. This is why novices and outsiders often make new discoveries; their ignorance of a field's assumptions acts as a source of temporary passive independent-mindedness. Aspies also seem to have a kind of immunity to conventional beliefs. Several I know say that this helps them to have new ideas.\n",
    "\n",
    "Strictness plus rule-breaking sounds like a strange combination. In popular culture they're opposed. But popular culture has a broken model in this respect. It implicitly assumes that issues are trivial ones, and in trivial matters strictness and rule-breaking are opposed. But in questions that really matter, only rule-breakers can be truly strict.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "An overlooked idea often doesn't lose till the semifinals. You do see it, subconsciously, but then another part of your subconscious shoots it down because it would be too weird, too risky, too much work, too controversial. This suggests an exciting possibility: if you could turn off such filters, you could see more new ideas.\n",
    "\n",
    "One way to do that is to ask what would be good ideas for someone else to explore. Then your subconscious won't shoot them down to protect you.\n",
    "\n",
    "You could also discover overlooked ideas by working in the other direction: by starting from what's obscuring them. Every cherished but mistaken principle is surrounded by a dead zone of valuable ideas that are unexplored because they contradict it.\n",
    "\n",
    "Religions are collections of cherished but mistaken principles. So anything that can be described either literally or metaphorically as a religion will have valuable unexplored ideas in its shadow. Copernicus and Darwin both made discoveries of this type. [18]\n",
    "\n",
    "What are people in your field religious about, in the sense of being too attached to some principle that might not be as self-evident as they think? What becomes possible if you discard it?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "People show much more originality in solving problems than in deciding which problems to solve. Even the smartest can be surprisingly conservative when deciding what to work on. People who'd never dream of being fashionable in any other way get sucked into working on fashionable problems.\n",
    "\n",
    "One reason people are more conservative when choosing problems than solutions is that problems are bigger bets. A problem could occupy you for years, while exploring a solution might only take days. But even so I think most people are too conservative. They're not merely responding to risk, but to fashion as well. Unfashionable problems are undervalued.\n",
    "\n",
    "One of the most interesting kinds of unfashionable problem is the problem that people think has been fully explored, but hasn't. Great work often takes something that already exists and shows its latent potential. Durer and Watt both did this. So if you're interested in a field that others think is tapped out, don't let their skepticism deter you. People are often wrong about this.\n",
    "\n",
    "Working on an unfashionable problem can be very pleasing. There's no hype or hurry. Opportunists and critics are both occupied elsewhere. The existing work often has an old-school solidity. And there's a satisfying sense of economy in cultivating ideas that would otherwise be wasted.\n",
    "\n",
    "But the most common type of overlooked problem is not explicitly unfashionable in the sense of being out of fashion. It just doesn't seem to matter as much as it actually does. How do you find these? By being self-indulgent — by letting your curiosity have its way, and tuning out, at least temporarily, the little voice in your head that says you should only be working on \"important\" problems.\n",
    "\n",
    "You do need to work on important problems, but almost everyone is too conservative about what counts as one. And if there's an important but overlooked problem in your neighborhood, it's probably already on your subconscious radar screen. So try asking yourself: if you were going to take a break from \"serious\" work to work on something just because it would be really interesting, what would you do? The answer is probably more important than it seems.\n",
    "\n",
    "Originality in choosing problems seems to matter even more than originality in solving them. That's what distinguishes the people who discover whole new fields. So what might seem to be merely the initial step — deciding what to work on — is in a sense the key to the whole game.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Few grasp this. One of the biggest misconceptions about new ideas is about the ratio of question to answer in their composition. People think big ideas are answers, but often the real insight was in the question.\n",
    "\n",
    "Part of the reason we underrate questions is the way they're used in schools. In schools they tend to exist only briefly before being answered, like unstable particles. But a really good question can be much more than that. A really good question is a partial discovery. How do new species arise? Is the force that makes objects fall to earth the same as the one that keeps planets in their orbits? By even asking such questions you were already in excitingly novel territory.\n",
    "\n",
    "Unanswered questions can be uncomfortable things to carry around with you. But the more you're carrying, the greater the chance of noticing a solution — or perhaps even more excitingly, noticing that two unanswered questions are the same.\n",
    "\n",
    "Sometimes you carry a question for a long time. Great work often comes from returning to a question you first noticed years before — in your childhood, even — and couldn't stop thinking about. People talk a lot about the importance of keeping your youthful dreams alive, but it's just as important to keep your youthful questions alive. [19]\n",
    "\n",
    "This is one of the places where actual expertise differs most from the popular picture of it. In the popular picture, experts are certain. But actually the more puzzled you are, the better, so long as (a) the things you're puzzled about matter, and (b) no one else understands them either.\n",
    "\n",
    "Think about what's happening at the moment just before a new idea is discovered. Often someone with sufficient expertise is puzzled about something. Which means that originality consists partly of puzzlement — of confusion! You have to be comfortable enough with the world being full of puzzles that you're willing to see them, but not so comfortable that you don't want to solve them. [20]\n",
    "\n",
    "It's a great thing to be rich in unanswered questions. And this is one of those situations where the rich get richer, because the best way to acquire new questions is to try answering existing ones. Questions don't just lead to answers, but also to more questions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The best questions grow in the answering. You notice a thread protruding from the current paradigm and try pulling on it, and it just gets longer and longer. So don't require a question to be obviously big before you try answering it. You can rarely predict that. It's hard enough even to notice the thread, let alone to predict how much will unravel if you pull on it.\n",
    "\n",
    "It's better to be promiscuously curious — to pull a little bit on a lot of threads, and see what happens. Big things start small. The initial versions of big things were often just experiments, or side projects, or talks, which then grew into something bigger. So start lots of small things.\n",
    "\n",
    "Being prolific is underrated. The more different things you try, the greater the chance of discovering something new. Understand, though, that trying lots of things will mean trying lots of things that don't work. You can't have a lot of good ideas without also having a lot of bad ones. [21]\n",
    "\n",
    "Though it sounds more responsible to begin by studying everything that's been done before, you'll learn faster and have more fun by trying stuff. And you'll understand previous work better when you do look at it. So err on the side of starting. Which is easier when starting means starting small; those two ideas fit together like two puzzle pieces.\n",
    "\n",
    "How do you get from starting small to doing something great? By making successive versions. Great things are almost always made in successive versions. You start with something small and evolve it, and the final version is both cleverer and more ambitious than anything you could have planned.\n",
    "\n",
    "It's particularly useful to make successive versions when you're making something for people — to get an initial version in front of them quickly, and then evolve it based on their response.\n",
    "\n",
    "Begin by trying the simplest thing that could possibly work. Surprisingly often, it does. If it doesn't, this will at least get you started.\n",
    "\n",
    "Don't try to cram too much new stuff into any one version. There are names for doing this with the first version (taking too long to ship) and the second (the second system effect), but these are both merely instances of a more general principle.\n",
    "\n",
    "An early version of a new project will sometimes be dismissed as a toy. It's a good sign when people do this. That means it has everything a new idea needs except scale, and that tends to follow. [22]\n",
    "\n",
    "The alternative to starting with something small and evolving it is to plan in advance what you're going to do. And planning does usually seem the more responsible choice. It sounds more organized to say \"we're going to do x and then y and then z\" than \"we're going to try x and see what happens.\" And it is more organized; it just doesn't work as well.\n",
    "\n",
    "Planning per se isn't good. It's sometimes necessary, but it's a necessary evil — a response to unforgiving conditions. It's something you have to do because you're working with inflexible media, or because you need to coordinate the efforts of a lot of people. If you keep projects small and use flexible media, you don't have to plan as much, and your designs can evolve instead.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Take as much risk as you can afford. In an efficient market, risk is proportionate to reward, so don't look for certainty, but for a bet with high expected value. If you're not failing occasionally, you're probably being too conservative.\n",
    "\n",
    "Though conservatism is usually associated with the old, it's the young who tend to make this mistake. Inexperience makes them fear risk, but it's when you're young that you can afford the most.\n",
    "\n",
    "Even a project that fails can be valuable. In the process of working on it, you'll have crossed territory few others have seen, and encountered questions few others have asked. And there's probably no better source of questions than the ones you encounter in trying to do something slightly too hard.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use the advantages of youth when you have them, and the advantages of age once you have those. The advantages of youth are energy, time, optimism, and freedom. The advantages of age are knowledge, efficiency, money, and power. With effort you can acquire some of the latter when young and keep some of the former when old.\n",
    "\n",
    "The old also have the advantage of knowing which advantages they have. The young often have them without realizing it. The biggest is probably time. The young have no idea how rich they are in time. The best way to turn this time to advantage is to use it in slightly frivolous ways: to learn about something you don't need to know about, just out of curiosity, or to try building something just because it would be cool, or to become freakishly good at something.\n",
    "\n",
    "That \"slightly\" is an important qualification. Spend time lavishly when you're young, but don't simply waste it. There's a big difference between doing something you worry might be a waste of time and doing something you know for sure will be. The former is at least a bet, and possibly a better one than you think. [23]\n",
    "\n",
    "The most subtle advantage of youth, or more precisely of inexperience, is that you're seeing everything with fresh eyes. When your brain embraces an idea for the first time, sometimes the two don't fit together perfectly. Usually the problem is with your brain, but occasionally it's with the idea. A piece of it sticks out awkwardly and jabs you when you think about it. People who are used to the idea have learned to ignore it, but you have the opportunity not to. [24]\n",
    "\n",
    "So when you're learning about something for the first time, pay attention to things that seem wrong or missing. You'll be tempted to ignore them, since there's a 99% chance the problem is with you. And you may have to set aside your misgivings temporarily to keep progressing. But don't forget about them. When you've gotten further into the subject, come back and check if they're still there. If they're still viable in the light of your present knowledge, they probably represent an undiscovered idea.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "One of the most valuable kinds of knowledge you get from experience is to know what you don't have to worry about. The young know all the things that could matter, but not their relative importance. So they worry equally about everything, when they should worry much more about a few things and hardly at all about the rest.\n",
    "\n",
    "But what you don't know is only half the problem with inexperience. The other half is what you do know that ain't so. You arrive at adulthood with your head full of nonsense — bad habits you've acquired and false things you've been taught — and you won't be able to do great work till you clear away at least the nonsense in the way of whatever type of work you want to do.\n",
    "\n",
    "Much of the nonsense left in your head is left there by schools. We're so used to schools that we unconsciously treat going to school as identical with learning, but in fact schools have all sorts of strange qualities that warp our ideas about learning and thinking.\n",
    "\n",
    "For example, schools induce passivity. Since you were a small child, there was an authority at the front of the class telling all of you what you had to learn and then measuring whether you did. But neither classes nor tests are intrinsic to learning; they're just artifacts of the way schools are usually designed.\n",
    "\n",
    "The sooner you overcome this passivity, the better. If you're still in school, try thinking of your education as your project, and your teachers as working for you rather than vice versa. That may seem a stretch, but it's not merely some weird thought experiment. It's the truth, economically, and in the best case it's the truth intellectually as well. The best teachers don't want to be your bosses. They'd prefer it if you pushed ahead, using them as a source of advice, rather than being pulled by them through the material.\n",
    "\n",
    "Schools also give you a misleading impression of what work is like. In school they tell you what the problems are, and they're almost always soluble using no more than you've been taught so far. In real life you have to figure out what the problems are, and you often don't know if they're soluble at all.\n",
    "\n",
    "But perhaps the worst thing schools do to you is train you to win by hacking the test. You can't do great work by doing that. You can't trick God. So stop looking for that kind of shortcut. The way to beat the system is to focus on problems and solutions that others have overlooked, not to skimp on the work itself.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Don't think of yourself as dependent on some gatekeeper giving you a \"big break.\" Even if this were true, the best way to get it would be to focus on doing good work rather than chasing influential people.\n",
    "\n",
    "And don't take rejection by committees to heart. The qualities that impress admissions officers and prize committees are quite different from those required to do great work. The decisions of selection committees are only meaningful to the extent that they're part of a feedback loop, and very few are.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "People new to a field will often copy existing work. There's nothing inherently bad about that. There's no better way to learn how something works than by trying to reproduce it. Nor does copying necessarily make your work unoriginal. Originality is the presence of new ideas, not the absence of old ones.\n",
    "\n",
    "There's a good way to copy and a bad way. If you're going to copy something, do it openly instead of furtively, or worse still, unconsciously. This is what's meant by the famously misattributed phrase \"Great artists steal.\" The really dangerous kind of copying, the kind that gives copying a bad name, is the kind that's done without realizing it, because you're nothing more than a train running on tracks laid down by someone else. But at the other extreme, copying can be a sign of superiority rather than subordination. [25]\n",
    "\n",
    "In many fields it's almost inevitable that your early work will be in some sense based on other people's. Projects rarely arise in a vacuum. They're usually a reaction to previous work. When you're first starting out, you don't have any previous work; if you're going to react to something, it has to be someone else's. Once you're established, you can react to your own. But while the former gets called derivative and the latter doesn't, structurally the two cases are more similar than they seem.\n",
    "\n",
    "Oddly enough, the very novelty of the most novel ideas sometimes makes them seem at first to be more derivative than they are. New discoveries often have to be conceived initially as variations of existing things, even by their discoverers, because there isn't yet the conceptual vocabulary to express them.\n",
    "\n",
    "There are definitely some dangers to copying, though. One is that you'll tend to copy old things — things that were in their day at the frontier of knowledge, but no longer are.\n",
    "\n",
    "And when you do copy something, don't copy every feature of it. Some will make you ridiculous if you do. Don't copy the manner of an eminent 50 year old professor if you're 18, for example, or the idiom of a Renaissance poem hundreds of years later.\n",
    "\n",
    "Some of the features of things you admire are flaws they succeeded despite. Indeed, the features that are easiest to imitate are the most likely to be the flaws.\n",
    "\n",
    "This is particularly true for behavior. Some talented people are jerks, and this sometimes makes it seem to the inexperienced that being a jerk is part of being talented. It isn't; being talented is merely how they get away with it.\n",
    "\n",
    "One of the most powerful kinds of copying is to copy something from one field into another. History is so full of chance discoveries of this type that it's probably worth giving chance a hand by deliberately learning about other kinds of work. You can take ideas from quite distant fields if you let them be metaphors.\n",
    "\n",
    "Negative examples can be as inspiring as positive ones. In fact you can sometimes learn more from things done badly than from things done well; sometimes it only becomes clear what's needed when it's missing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "If a lot of the best people in your field are collected in one place, it's usually a good idea to visit for a while. It will increase your ambition, and also, by showing you that these people are human, increase your self-confidence. [26]\n",
    "\n",
    "If you're earnest you'll probably get a warmer welcome than you might expect. Most people who are very good at something are happy to talk about it with anyone who's genuinely interested. If they're really good at their work, then they probably have a hobbyist's interest in it, and hobbyists always want to talk about their hobbies.\n",
    "\n",
    "It may take some effort to find the people who are really good, though. Doing great work has such prestige that in some places, particularly universities, there's a polite fiction that everyone is engaged in it. And that is far from true. People within universities can't say so openly, but the quality of the work being done in different departments varies immensely. Some departments have people doing great work; others have in the past; others never have.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Seek out the best colleagues. There are a lot of projects that can't be done alone, and even if you're working on one that can be, it's good to have other people to encourage you and to bounce ideas off.\n",
    "\n",
    "Colleagues don't just affect your work, though; they also affect you. So work with people you want to become like, because you will.\n",
    "\n",
    "Quality is more important than quantity in colleagues. It's better to have one or two great ones than a building full of pretty good ones. In fact it's not merely better, but necessary, judging from history: the degree to which great work happens in clusters suggests that one's colleagues often make the difference between doing great work and not.\n",
    "\n",
    "How do you know when you have sufficiently good colleagues? In my experience, when you do, you know. Which means if you're unsure, you probably don't. But it may be possible to give a more concrete answer than that. Here's an attempt: sufficiently good colleagues offer surprising insights. They can see and do things that you can't. So if you have a handful of colleagues good enough to keep you on your toes in this sense, you're probably over the threshold.\n",
    "\n",
    "Most of us can benefit from collaborating with colleagues, but some projects require people on a larger scale, and starting one of those is not for everyone. If you want to run a project like that, you'll have to become a manager, and managing well takes aptitude and interest like any other kind of work. If you don't have them, there is no middle path: you must either force yourself to learn management as a second language, or avoid such projects. [27]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Husband your morale. It's the basis of everything when you're working on ambitious projects. You have to nurture and protect it like a living organism.\n",
    "\n",
    "Morale starts with your view of life. You're more likely to do great work if you're an optimist, and more likely to if you think of yourself as lucky than if you think of yourself as a victim.\n",
    "\n",
    "Indeed, work can to some extent protect you from your problems. If you choose work that's pure, its very difficulties will serve as a refuge from the difficulties of everyday life. If this is escapism, it's a very productive form of it, and one that has been used by some of the greatest minds in history.\n",
    "\n",
    "Morale compounds via work: high morale helps you do good work, which increases your morale and helps you do even better work. But this cycle also operates in the other direction: if you're not doing good work, that can demoralize you and make it even harder to. Since it matters so much for this cycle to be running in the right direction, it can be a good idea to switch to easier work when you're stuck, just so you start to get something done.\n",
    "\n",
    "One of the biggest mistakes ambitious people make is to allow setbacks to destroy their morale all at once, like a balloon bursting. You can inoculate yourself against this by explicitly considering setbacks a part of your process. Solving hard problems always involves some backtracking.\n",
    "\n",
    "Doing great work is a depth-first search whose root node is the desire to. So \"If at first you don't succeed, try, try again\" isn't quite right. It should be: If at first you don't succeed, either try again, or backtrack and then try again.\n",
    "\n",
    "\"Never give up\" is also not quite right. Obviously there are times when it's the right choice to eject. A more precise version would be: Never let setbacks panic you into backtracking more than you need to. Corollary: Never abandon the root node.\n",
    "\n",
    "It's not necessarily a bad sign if work is a struggle, any more than it's a bad sign to be out of breath while running. It depends how fast you're running. So learn to distinguish good pain from bad. Good pain is a sign of effort; bad pain is a sign of damage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "An audience is a critical component of morale. If you're a scholar, your audience may be your peers; in the arts, it may be an audience in the traditional sense. Either way it doesn't need to be big. The value of an audience doesn't grow anything like linearly with its size. Which is bad news if you're famous, but good news if you're just starting out, because it means a small but dedicated audience can be enough to sustain you. If a handful of people genuinely love what you're doing, that's enough.\n",
    "\n",
    "To the extent you can, avoid letting intermediaries come between you and your audience. In some types of work this is inevitable, but it's so liberating to escape it that you might be better off switching to an adjacent type if that will let you go direct. [28]\n",
    "\n",
    "The people you spend time with will also have a big effect on your morale. You'll find there are some who increase your energy and others who decrease it, and the effect someone has is not always what you'd expect. Seek out the people who increase your energy and avoid those who decrease it. Though of course if there's someone you need to take care of, that takes precedence.\n",
    "\n",
    "Don't marry someone who doesn't understand that you need to work, or sees your work as competition for your attention. If you're ambitious, you need to work; it's almost like a medical condition; so someone who won't let you work either doesn't understand you, or does and doesn't care.\n",
    "\n",
    "Ultimately morale is physical. You think with your body, so it's important to take care of it. That means exercising regularly, eating and sleeping well, and avoiding the more dangerous kinds of drugs. Running and walking are particularly good forms of exercise because they're good for thinking. [29]\n",
    "\n",
    "People who do great work are not necessarily happier than everyone else, but they're happier than they'd be if they didn't. In fact, if you're smart and ambitious, it's dangerous not to be productive. People who are smart and ambitious but don't achieve much tend to become bitter.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It's ok to want to impress other people, but choose the right people. The opinion of people you respect is signal. Fame, which is the opinion of a much larger group you might or might not respect, just adds noise.\n",
    "\n",
    "The prestige of a type of work is at best a trailing indicator and sometimes completely mistaken. If you do anything well enough, you'll make it prestigious. So the question to ask about a type of work is not how much prestige it has, but how well it could be done.\n",
    "\n",
    "Competition can be an effective motivator, but don't let it choose the problem for you; don't let yourself get drawn into chasing something just because others are. In fact, don't let competitors make you do anything much more specific than work harder.\n",
    "\n",
    "Curiosity is the best guide. Your curiosity never lies, and it knows more than you do about what's worth paying attention to.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notice how often that word has come up. If you asked an oracle the secret to doing great work and the oracle replied with a single word, my bet would be on \"curiosity.\"\n",
    "\n",
    "That doesn't translate directly to advice. It's not enough just to be curious, and you can't command curiosity anyway. But you can nurture it and let it drive you.\n",
    "\n",
    "Curiosity is the key to all four steps in doing great work: it will choose the field for you, get you to the frontier, cause you to notice the gaps in it, and drive you to explore them. The whole process is a kind of dance with curiosity.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Believe it or not, I tried to make this essay as short as I could. But its length at least means it acts as a filter. If you made it this far, you must be interested in doing great work. And if so you're already further along than you might realize, because the set of people willing to want to is small.\n",
    "\n",
    "The factors in doing great work are factors in the literal, mathematical sense, and they are: ability, interest, effort, and luck. Luck by definition you can't do anything about, so we can ignore that. And we can assume effort, if you do in fact want to do great work. So the problem boils down to ability and interest. Can you find a kind of work where your ability and interest will combine to yield an explosion of new ideas?\n",
    "\n",
    "Here there are grounds for optimism. There are so many different ways to do great work, and even more that are still undiscovered. Out of all those different types of work, the one you're most suited for is probably a pretty close match. Probably a comically close match. It's just a question of finding it, and how far into it your ability and interest can take you. And you can only answer that by trying.\n",
    "\n",
    "Many more people could try to do great work than do. What holds them back is a combination of modesty and fear. It seems presumptuous to try to be Newton or Shakespeare. It also seems hard; surely if you tried something like that, you'd fail. Presumably the calculation is rarely explicit. Few people consciously decide not to try to do great work. But that's what's going on subconsciously; they shy away from the question.\n",
    "\n",
    "So I'm going to pull a sneaky trick on you. Do you want to do great work, or not? Now you have to decide consciously. Sorry about that. I wouldn't have done it to a general audience. But we already know you're interested.\n",
    "\n",
    "Don't worry about being presumptuous. You don't have to tell anyone. And if it's too hard and you fail, so what? Lots of people have worse problems than that. In fact you'll be lucky if it's the worst problem you have.\n",
    "\n",
    "Yes, you'll have to work hard. But again, lots of people have to work hard. And if you're working on something you find very interesting, which you necessarily will if you're on the right path, the work will probably feel less burdensome than a lot of your peers'.\n",
    "\n",
    "The discoveries are out there, waiting to be made. Why not by you?\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pg=pg.split('.')\n",
    "rh=rh.split('.')\n",
    "#above .7 = semantically similar\n",
    "#below 0 = different subject different verb\n",
    "#below .3 similar subject\n",
    "#cs=computeSimilarity(pg, rh)\n",
    "\n",
    "\n",
    "# pge = encode(pg)\n",
    "# rhe = encode(rh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sorted_pge, indices = pge.sort()\n",
    "sorted_rhe,indices =  rhe.sort()\n",
    "\n",
    "#use indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68003089",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs\n",
    "\n",
    "def display_pair(pair):\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(rh[i], pg[j], pair['score']))\n",
    "    #print(\"{} \\t\\t  \\t\\t Score: {:.4f}\".format(pg[j] if len(rh[i]) > len(pg[j]) else rh[i], pair['score']))\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    display_pair(pairs[i])\n",
    "    \n",
    "    \n",
    "#you know they are similar enough -> how do you merge - merge by relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilarity(s1, s2):\n",
    "    return util.cos_sim(s1, s2)\n",
    "computeSimilarity(sorted_pge, sorted_rhe[:664])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fec22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 'i went to the grocery store. I found a box of tomatoes. it was cool.'\n",
    "\n",
    "p2 = 'i went to the grocery store. i dropped a box of tomatoes. it was cool.'\n",
    "\n",
    "computeSimilarity(p1, p2)\n",
    "\n",
    "\n",
    "#along with similarity -> compute how they are different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "one= 'i went to the mall with my cousins and ate subway'\n",
    "\n",
    "two = 'my cousins and i ate subway at the mall.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c554c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(word_tokenize(one)), pos_tag(word_tokenize(two)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec441de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "computeSimilarity('ate soup', 'love soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "computeSimilarity('ate a carrot', 'ate some carrots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8703e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "person1 = 'i want the government to add a railroad between montreal and kansas'\n",
    "person5 = 'i want the government to add a railroad between kansas and montreal'\n",
    "person2 = 'i want to build a registry for synthetic plants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6df128",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode([person1, person2], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "trythisone = 'why do you call it an xbox 360? because when you see it, you turn 360 degrees and walk away.'\n",
    "\n",
    "data = \"\"\"I used to play piano by ear, but now I use my hands.\n",
    "\n",
    "I'm reading a book about anti-gravity, and it's impossible to put down.\n",
    "\n",
    "The math book looked sad, so I asked what's the problem. It said it had too many problems.\n",
    "\n",
    "A bicycle can't stand on its own because it's two-tired.\n",
    "\n",
    "I told my friend 10 jokes to make him laugh, but no pun in ten did.\n",
    "\n",
    "Did you hear about the guy who lost his left side? He's all right now.\n",
    "\n",
    "I used to be a baker, but I couldn't make enough dough.\n",
    "\n",
    "When a clock is hungry, it goes back four seconds.\n",
    "\n",
    "I got a job at a bakery because I kneaded the dough.\n",
    "\n",
    "I'm friends with all electricians. We have good current connections.\"\"\".split('\\n')\n",
    "\n",
    "data2 = \"\"\"\n",
    "How do you throw a space party? You planet.\n",
    "\n",
    "How was Rome split in two? With a pair of Ceasars.\n",
    "\n",
    "Nope. Unintended.\n",
    "\n",
    "The shovel was a ground breaking invention, but everyone was blow away by the leaf blower.\n",
    "\n",
    "A scarecrow says, \"This job isn't for everyone, but hay, it's in my jeans.\"\n",
    "\n",
    "A Buddhist walks up to a hot dog stand and says \"Make me one with everything.\"\n",
    "\n",
    "Did you hear about the guy who lost the left side of his body? He's alright now.\n",
    "\n",
    "What do you call a girl with one leg that's shorter than the other? Ilene.\n",
    "\n",
    "The broom swept the nation away.\n",
    "\n",
    "I did a theatrical performance on puns. It was a play on words.\n",
    "\n",
    "What does a clock do when it's hungry? It goes back for seconds.\n",
    "\n",
    "What do you do with a dead chemist? You barium.\n",
    "\n",
    "I bet the person who created the door knocker won a Nobel prize.\n",
    "\n",
    "Towels can’t tell jokes. They have a dry sense of humor.\n",
    "\n",
    "Two birds are sitting on a perch and one says “Do you smell fish?”\n",
    "\n",
    "Did you hear about the cheese factory that exploded in france? There was nothing but des brie.\n",
    "\n",
    "Do you know sign language? You should learn it, it’s pretty handy.\n",
    "\n",
    "What do you call a beautiful pumpkin? GOURDgeous.\n",
    "\n",
    "Why did one banana spy on the other? Because she was appealing.\n",
    "\n",
    "What do you call a cow with no legs? Ground beef.\n",
    "\n",
    "What do you call a cow with two legs? Lean beef.\n",
    "\n",
    "What do you call a cow with all of its legs? High steaks.\n",
    "\n",
    "A cross eyed teacher couldn’t control his pupils.\n",
    "\n",
    "After the accident, the juggler didn’t have the balls to do it.\n",
    "\n",
    "I used to be afraid of hurdles, but I got over it.\n",
    "\n",
    "To write with a broken pencil is pointless.\n",
    "\n",
    "I read a book on anti-gravity. I couldn’t put it down.\n",
    "\n",
    "I couldn’t remember how to throw a boomerang but it came back to me.\n",
    "\n",
    "What did the buffalo say to his son? Bison.\n",
    "\n",
    "What should you do if you’re cold? Stand in the corner. It’s 90 degrees.\n",
    "\n",
    "How does Moses make coffee? Hebrews it.\n",
    "\n",
    "The energizer bunny went to jail. He was charged with battery.\n",
    "\n",
    "What did the alien say to the pitcher of water? Take me to your liter.\n",
    "\n",
    "What happens when you eat too many spaghettiOs? You have a vowel movement.\n",
    "\n",
    "The soldier who survived mustard gas and pepper spray was a seasoned veteran.\n",
    "\n",
    "Sausage puns are the wurst.\n",
    "\n",
    "What do you call a bear with no teeth? A gummy bear.\n",
    "\n",
    "How did Darth Vader know what luke was getting him for his birthday? He could sense his presence.\n",
    "\n",
    "Why shouldn’t you trust atoms? They make up everything.\n",
    "\n",
    "What’s the difference between a bench, a fish, and a bucket of glue? You can’t tune a bench but you can tuna fish. I bet you got stuck on the bucket of glue part.\n",
    "\n",
    "What’s it called when you have too many aliens? Extraterrestrials.\n",
    "\n",
    "Want to hear a pizza joke? Nevermind, it’s too cheesy.\n",
    "\n",
    "What do you call a fake noodle? An impasta.\n",
    "\n",
    "What do cows tell each other at bedtime? Dairy tales.\n",
    "\n",
    "Why can’t you take inventory in Afghanistan? Because of the tally ban.\n",
    "\n",
    "Why didn’t the lion win the race? Because he was racing a cheetah.\n",
    "\n",
    "Why did the man dig a hole in his neighbor’s backyard and fill it with water? Because he meant well.\n",
    "\n",
    "What happens to nitrogen when the sun comes up? It becomes daytrogen.\n",
    "\n",
    "What’s it called when you put a cow in an elevator? Raising the steaks.\n",
    "\n",
    "What’s america’s favorite soda? Mini soda.\n",
    "\n",
    "Why did the tomato turn red? Because it saw the salad dressing.\n",
    "\n",
    "What kind of car does a sheep drive? A lamborghini, but if that breaks down they drive their SuBAHHru.\n",
    "\n",
    "What do you call a spanish pig? Porque.\n",
    "\n",
    "What do you call a line of rabbits marching backwards? A receding hairline.\n",
    "\n",
    "Why don’t vampires go to barbecues? They don’t like steak.\n",
    "\n",
    "A cabbage and celery walk into a bar and the cabbage gets served first because he was a head.\n",
    "\n",
    "How do trees access the internet? They log on.\n",
    "\n",
    "Why should you never trust a train? They have loco motives.\n",
    "\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n",
    "def isPun(one, two):\n",
    "    return two in prouncing.rhymes(one)\n",
    "\n",
    "def isPunSentence(sentence):\n",
    "    tokens = sentence.split(' ')\n",
    "    hasNotFoundRhyme = False\n",
    "    for i in tokens:\n",
    "        for j in tokens:\n",
    "            if i ==j: continue\n",
    "            if isPun(one, two): hasNotFoundRhyme = True\n",
    "    return hasNotFoundRhyme\n",
    "\n",
    "\n",
    "data3 = 'What do you call a fake noodle? An impasta.'\n",
    "\n",
    "[correction(data) for data in data3.split(' ')]\n",
    "correction('impasta')\n",
    "#get the original source code to humor \n",
    "\n",
    "#anaylze humor + scene understaning in every transcript in modern family, seinfeld, parks+rec, south park\n",
    "\n",
    "#train LLM from most upvoted comments from hacker news, reddit and so on -> give tptacek+ patio11 personality + etc\n",
    "\n",
    "fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(text) :\n",
    "    summarizer = pipeline(\"summarization\", model=\"stevhliu/my_awesome_billsum_model\")\n",
    "    return summarizer(text)\n",
    "\n",
    "summarize('im going to go for a walk and type type tpye until text editor is cooler than pasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
